{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# 담당자별 리드 전환 예측 특화 대시보드 - AI/ML 성능 개선 버전\n",
        "# 플랫폼: Google Colab / Gradio 5.0+\n",
        "# 목표: 고성능 담당자별 리드 전환율 예측 및 최적 배정 시스템\n",
        "# ================================================================================\n",
        "\n",
        "# 1. Google Colab 환경 설정 및 라이브러리 자동 설치\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"필요한 패키지 자동 설치\"\"\"\n",
        "    packages = [\n",
        "        'gradio>=5.0.0',\n",
        "        'pandas',\n",
        "        'numpy',\n",
        "        'scikit-learn>=1.0.0',  # 버전 명시\n",
        "        'lightgbm',\n",
        "        'xgboost',\n",
        "        'catboost',  # 추가: 더 강력한 그래디언트 부스팅\n",
        "        'optuna>=3.0.0',  # 하이퍼파라미터 최적화 (버전 명시)\n",
        "        'plotly',\n",
        "        'seaborn',\n",
        "        'matplotlib',\n",
        "        'openpyxl',\n",
        "        'japanize-matplotlib',\n",
        "        'tensorflow',\n",
        "        'imbalanced-learn>=0.9.0',  # 추가: 클래스 불균형 처리 (버전 명시)\n",
        "        'feature-engine'  # 추가: 고급 피처 엔지니어링\n",
        "    ]\n",
        "\n",
        "    print(\"📦 필요한 패키지 설치 중...\")\n",
        "\n",
        "    # 먼저 pip 업그레이드\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # 기본 패키지 설치\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "            print(f\"✅ {package} 설치 완료\")\n",
        "        except:\n",
        "            print(f\"⚠️ {package} 설치 실패, 계속 진행...\")\n",
        "\n",
        "    # 시계열 패키지는 별도로 처리 (오류가 자주 발생)\n",
        "    print(\"\\n📈 시계열 분석 패키지 설치 중...\")\n",
        "\n",
        "    # statsmodels 설치 시도\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'statsmodels>=0.13.0'])\n",
        "        print(\"✅ statsmodels 설치 완료\")\n",
        "    except:\n",
        "        print(\"⚠️ statsmodels 설치 실패 - ARIMA 모델을 사용할 수 없습니다\")\n",
        "\n",
        "    # pmdarima 설치 시도 (의존성이 복잡해서 자주 실패함)\n",
        "    try:\n",
        "        # 먼저 의존성 설치\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'cython', 'numpy', 'scipy'])\n",
        "        # pmdarima 설치\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'pmdarima>=2.0.0'])\n",
        "        print(\"✅ pmdarima 설치 완료\")\n",
        "    except:\n",
        "        print(\"⚠️ pmdarima 설치 실패 - Auto ARIMA를 사용할 수 없습니다\")\n",
        "\n",
        "    # prophet 설치 시도\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'prophet>=1.1'])\n",
        "        print(\"✅ prophet 설치 완료\")\n",
        "    except:\n",
        "        print(\"⚠️ prophet 설치 실패 - Prophet 모델을 사용할 수 없습니다\")\n",
        "\n",
        "    # 한글 폰트 설치 (Colab용)\n",
        "    try:\n",
        "        print(\"\\n🎨 한글 폰트 설치 중...\")\n",
        "        subprocess.run(['apt-get', 'update', '-qq'], check=True, capture_output=True)\n",
        "        subprocess.run(['apt-get', 'install', '-qq', 'fonts-nanum*'], check=True, capture_output=True)\n",
        "        subprocess.run(['fc-cache', '-fv'], capture_output=True)\n",
        "    except:\n",
        "        print(\"⚠️ 한글 폰트 설치 실패, 기본 폰트 사용\")\n",
        "\n",
        "    print(\"\\n✅ 패키지 설치 완료!\")\n",
        "    print(\"💡 일부 시계열 패키지가 설치되지 않아도 기본 ML 모델은 정상 작동합니다.\")\n",
        "\n",
        "# 패키지 설치 실행\n",
        "install_packages()\n",
        "\n",
        "# 2. 라이브러리 임포트\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# 한글 폰트 설정\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "    japanize_matplotlib.japanize()\n",
        "except:\n",
        "    # 대체 폰트 설정\n",
        "    plt.rcParams['font.family'] = ['DejaVu Sans']\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# 머신러닝 라이브러리\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, TimeSeriesSplit\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, mean_squared_error\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, VarianceThreshold\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from datetime import datetime, timedelta\n",
        "import io\n",
        "import json\n",
        "import base64\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "\n",
        "# 추가 라이브러리\n",
        "try:\n",
        "    import catboost as cb\n",
        "    from catboost import CatBoostClassifier\n",
        "    CATBOOST_AVAILABLE = True\n",
        "except:\n",
        "    print(\"⚠️ CatBoost를 사용할 수 없습니다.\")\n",
        "    CATBOOST_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except:\n",
        "    print(\"⚠️ Optuna를 사용할 수 없습니다.\")\n",
        "    OPTUNA_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE, ADASYN\n",
        "    from imblearn.under_sampling import RandomUnderSampler\n",
        "    from imblearn.combine import SMOTEENN\n",
        "    IMBALANCED_AVAILABLE = True\n",
        "except:\n",
        "    print(\"⚠️ Imbalanced-learn을 사용할 수 없습니다.\")\n",
        "    IMBALANCED_AVAILABLE = False\n",
        "\n",
        "# 시계열 모델 라이브러리\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "    TENSORFLOW_AVAILABLE = True\n",
        "    print(\"✅ TensorFlow 로드 성공\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ TensorFlow를 사용할 수 없습니다. LSTM 모델은 비활성화됩니다. (오류: {str(e)})\")\n",
        "    TENSORFLOW_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    from statsmodels.tsa.stattools import adfuller\n",
        "    import pmdarima as pm\n",
        "    STATSMODELS_AVAILABLE = True\n",
        "    print(\"✅ Statsmodels/pmdarima 로드 성공\")\n",
        "except ImportError as e:\n",
        "    print(f\"⚠️ Statsmodels를 사용할 수 없습니다. ARIMA 모델은 비활성화됩니다.\")\n",
        "    print(f\"   원인: {str(e)}\")\n",
        "    print(\"   해결방법: !pip install statsmodels pmdarima\")\n",
        "    STATSMODELS_AVAILABLE = False\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Statsmodels 로드 중 예상치 못한 오류: {str(e)}\")\n",
        "    STATSMODELS_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    PROPHET_AVAILABLE = True\n",
        "    print(\"✅ Prophet 로드 성공\")\n",
        "except Exception as e:\n",
        "    print(f\"⚠️ Prophet을 사용할 수 없습니다. (오류: {str(e)})\")\n",
        "    PROPHET_AVAILABLE = False\n",
        "\n",
        "# ================================================================================\n",
        "# 3. 전역 변수 및 상태 관리\n",
        "# ================================================================================\n",
        "\n",
        "class AppState:\n",
        "    \"\"\"애플리케이션 상태 관리 클래스\"\"\"\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.processed_data = None\n",
        "        self.best_model = None\n",
        "        self.best_model_name = None\n",
        "        self.feature_names = None\n",
        "        self.encoders = None\n",
        "        self.model_results = {}\n",
        "        self.manager_performance = None\n",
        "        self.prediction_results = None\n",
        "        self.feature_importance = None\n",
        "        self.is_data_loaded = False\n",
        "        self.is_preprocessed = False\n",
        "        self.is_model_trained = False\n",
        "        self.time_series_models = {}  # 시계열 모델 저장\n",
        "        self.ensemble_model = None  # 앙상블 모델\n",
        "        self.feature_selector = None  # 피처 선택기\n",
        "        self.scaler = None  # 스케일러\n",
        "\n",
        "app_state = AppState()\n",
        "\n",
        "# ================================================================================\n",
        "# 4. 샘플 데이터 생성 함수\n",
        "# ================================================================================\n",
        "\n",
        "def create_sample_data() -> pd.DataFrame:\n",
        "    \"\"\"tst_atalk.xlsx와 동일한 구조의 샘플 데이터 생성\"\"\"\n",
        "    np.random.seed(42)\n",
        "    n_samples = 500\n",
        "\n",
        "    # 담당자 목록 (실제 데이터와 동일)\n",
        "    managers = [\n",
        "        '배제경(sv5203)', '예신해(sv0027)', '양은서(sv5200)',\n",
        "        '김태연(sv0026)', '윤석한(sv5202)', '정지웅(sv0025)',\n",
        "        '박온설아(sv0024)', None  # None은 미배정\n",
        "    ]\n",
        "\n",
        "    # 판매처 목록\n",
        "    channels = ['G마켓', 'CJ몰', '11번가', 'SSG', '옥션', '네이버', '쿠팡']\n",
        "\n",
        "    # 상태 목록\n",
        "    statuses = ['승인완료', '1회 접촉', '2회 접촉', '3회 접촉', '접촉실패', '취소완료', '접수완료']\n",
        "    status_weights = [0.25, 0.15, 0.20, 0.10, 0.10, 0.05, 0.15]\n",
        "\n",
        "    # 데이터 생성\n",
        "    data = {\n",
        "        '공유': ['공용'] * n_samples,\n",
        "        '이름': [f'고객_{np.random.randint(1000, 9999)}' for _ in range(n_samples)],\n",
        "        '고객번호': [f'452036_{i}' for i in range(n_samples)],\n",
        "        '성별': np.random.choice(['남자', '여자'], n_samples, p=[0.4, 0.6]),\n",
        "        '유형': np.random.choice(['개인', '법인'], n_samples, p=[0.9, 0.1]),\n",
        "        '생일구분': ['양력'] * n_samples,\n",
        "        '혼인여부': np.random.choice(['미혼', '기혼'], n_samples, p=[0.4, 0.6]),\n",
        "        'TEL': [f'10{np.random.randint(10000000, 99999999)}' for _ in range(n_samples)],\n",
        "        '메모': ['LG정수기렌탈 상담 문의 ' * np.random.randint(1, 5) for _ in range(n_samples)],\n",
        "        '상태': np.random.choice(statuses, n_samples, p=status_weights),\n",
        "        '마케팅활용동의': np.random.choice(['동의', '미동의'], n_samples, p=[0.7, 0.3]),\n",
        "        '이메일수신동의': np.random.choice(['동의', '미동의'], n_samples, p=[0.6, 0.4]),\n",
        "        '문자수신동의': np.random.choice(['동의', '미동의'], n_samples, p=[0.65, 0.35]),\n",
        "        '담당자': np.random.choice(managers, n_samples, p=[0.2, 0.17, 0.16, 0.15, 0.15, 0.13, 0.03, 0.01]),\n",
        "        '등록일자': pd.date_range(start='2024-01-01', periods=n_samples, freq='H'),\n",
        "        '판매처': np.random.choice(channels, n_samples),\n",
        "        '등록자': np.random.choice(['양은서', '김민수', '이지은'], n_samples),\n",
        "        '등록일시': pd.date_range(start='2024-01-01', periods=n_samples, freq='H')\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # 담당자별로 다른 승인율 적용\n",
        "    for idx, row in df.iterrows():\n",
        "        if pd.notna(row['담당자']):\n",
        "            if '배제경' in row['담당자']:\n",
        "                if np.random.random() < 0.35:\n",
        "                    df.at[idx, '상태'] = '승인완료'\n",
        "            elif '예신해' in row['담당자']:\n",
        "                if np.random.random() < 0.32:\n",
        "                    df.at[idx, '상태'] = '승인완료'\n",
        "            elif '김태연' in row['담당자']:\n",
        "                if np.random.random() < 0.30:\n",
        "                    df.at[idx, '상태'] = '승인완료'\n",
        "\n",
        "    return df\n",
        "\n",
        "# ================================================================================\n",
        "# 5. 고급 피처 엔지니어링 함수\n",
        "# ================================================================================\n",
        "\n",
        "def advanced_feature_engineering(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"고급 피처 엔지니어링\"\"\"\n",
        "\n",
        "    # 담당자별 과거 성과 통계\n",
        "    if '담당자명' in data.columns:\n",
        "        manager_stats = data.groupby('담당자명').agg({\n",
        "            'is_approved': ['mean', 'sum', 'count'],\n",
        "            '접촉횟수': ['mean', 'std'],\n",
        "            '메모_길이': 'mean'\n",
        "        }).round(4)\n",
        "\n",
        "        manager_stats.columns = [\n",
        "            '담당자_승인율', '담당자_총승인수', '담당자_총리드수',\n",
        "            '담당자_평균접촉', '담당자_접촉편차', '담당자_평균메모'\n",
        "        ]\n",
        "\n",
        "        # 담당자 통계 병합\n",
        "        data = data.merge(manager_stats, left_on='담당자명', right_index=True, how='left')\n",
        "\n",
        "        # 담당자 경험 지표\n",
        "        data['담당자_경험지수'] = data['담당자_총리드수'] / data['담당자_총리드수'].max()\n",
        "        data['담당자_효율성'] = data['담당자_승인율'] / (data['담당자_평균접촉'] + 1)\n",
        "\n",
        "    # 시간대별 패턴\n",
        "    if '등록일자' in data.columns and pd.api.types.is_datetime64_any_dtype(data['등록일자']):\n",
        "        # 시간대별 특성\n",
        "        data['시간대'] = pd.cut(data['등록_시간'],\n",
        "                               bins=[0, 6, 12, 18, 24],\n",
        "                               labels=['새벽', '오전', '오후', '저녁'])\n",
        "\n",
        "        # 주말 여부\n",
        "        data['주말여부'] = (data['등록_요일'] >= 5).astype(int)\n",
        "\n",
        "        # 월초/월말 구분\n",
        "        data['월초'] = (data['등록_일'] <= 10).astype(int)\n",
        "        data['월말'] = (data['등록_일'] >= 21).astype(int)\n",
        "\n",
        "        # 분기\n",
        "        data['분기'] = data['등록일자'].dt.quarter\n",
        "\n",
        "    # 판매처별 특성\n",
        "    if '판매처' in data.columns:\n",
        "        channel_stats = data.groupby('판매처')['is_approved'].agg(['mean', 'count'])\n",
        "        channel_stats.columns = ['판매처_평균승인율', '판매처_빈도']\n",
        "        data = data.merge(channel_stats, left_on='판매처', right_index=True, how='left')\n",
        "\n",
        "    # 고객 특성 조합\n",
        "    if all(col in data.columns for col in ['성별', '혼인여부', '유형']):\n",
        "        data['고객프로파일'] = data['성별'] + '_' + data['혼인여부'] + '_' + data['유형']\n",
        "\n",
        "        # 프로파일별 승인율\n",
        "        profile_stats = data.groupby('고객프로파일')['is_approved'].mean()\n",
        "        data['프로파일_승인율'] = data['고객프로파일'].map(profile_stats)\n",
        "\n",
        "    # 동의 점수\n",
        "    consent_cols = ['마케팅활용동의_num', '이메일수신동의_num', '문자수신동의_num']\n",
        "    if all(col in data.columns for col in consent_cols):\n",
        "        data['동의점수'] = data[consent_cols].sum(axis=1)\n",
        "        data['완전동의'] = (data['동의점수'] == 3).astype(int)\n",
        "\n",
        "    # 메모 관련 고급 피처\n",
        "    if '메모' in data.columns:\n",
        "        # 특정 키워드 포함 여부\n",
        "        keywords = ['정수기', '렌탈', '상담', '문의', '견적', '설치']\n",
        "        for keyword in keywords:\n",
        "            data[f'메모_{keyword}_포함'] = data['메모'].str.contains(keyword, na=False).astype(int)\n",
        "\n",
        "        # 메모 품질 점수\n",
        "        data['메모_품질점수'] = (\n",
        "            data['메모_길이'] / data['메모_길이'].max() * 0.3 +\n",
        "            data['메모_단어수'] / data['메모_단어수'].max() * 0.3 +\n",
        "            data[[f'메모_{kw}_포함' for kw in keywords]].sum(axis=1) / len(keywords) * 0.4\n",
        "        )\n",
        "\n",
        "    # 상호작용 피처\n",
        "    if '담당자_승인율' in data.columns and '판매처_평균승인율' in data.columns:\n",
        "        data['담당자X판매처_시너지'] = data['담당자_승인율'] * data['판매처_평균승인율']\n",
        "\n",
        "    if '접촉횟수' in data.columns and '메모_길이' in data.columns:\n",
        "        data['접촉X메모_상호작용'] = data['접촉횟수'] * np.log1p(data['메모_길이'])\n",
        "\n",
        "    # 이상치 플래그\n",
        "    numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
        "    for col in numerical_cols:\n",
        "        if col not in ['is_approved', 'is_approved_binary']:\n",
        "            Q1 = data[col].quantile(0.25)\n",
        "            Q3 = data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower = Q1 - 1.5 * IQR\n",
        "            upper = Q3 + 1.5 * IQR\n",
        "            data[f'{col}_이상치'] = ((data[col] < lower) | (data[col] > upper)).astype(int)\n",
        "\n",
        "    return data\n",
        "\n",
        "# ================================================================================\n",
        "# 6. 데이터 처리 함수 (개선된 버전)\n",
        "# ================================================================================\n",
        "\n",
        "def load_data(file) -> Tuple[pd.DataFrame, str]:\n",
        "    \"\"\"데이터 로드 및 초기 분석\"\"\"\n",
        "    try:\n",
        "        if file is None:\n",
        "            # 샘플 데이터 사용\n",
        "            df = create_sample_data()\n",
        "            info_text = \"📌 샘플 데이터를 사용합니다.\\n\"\n",
        "        else:\n",
        "            # 파일 읽기\n",
        "            filename = file.name if hasattr(file, 'name') else 'uploaded_file'\n",
        "\n",
        "            try:\n",
        "                if filename.endswith('.csv'):\n",
        "                    df = pd.read_csv(file, encoding='utf-8')\n",
        "                elif filename.endswith(('.xlsx', '.xls')):\n",
        "                    df = pd.read_excel(file)\n",
        "                else:\n",
        "                    return None, \"❌ 지원되지 않는 파일 형식입니다. CSV 또는 Excel 파일을 업로드해주세요.\"\n",
        "            except Exception as e:\n",
        "                return None, f\"❌ 파일 읽기 오류: {str(e)}\"\n",
        "\n",
        "        # 필수 컬럼 확인\n",
        "        required_columns = ['상태', '담당자']\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "        if missing_columns:\n",
        "            return None, f\"❌ 필수 컬럼이 없습니다: {', '.join(missing_columns)}\"\n",
        "\n",
        "        # 데이터 기본 정보 분석\n",
        "        total_rows = len(df)\n",
        "\n",
        "        # 상태별 분포 분석\n",
        "        status_dist = df['상태'].value_counts().to_dict()\n",
        "        approval_count = df[df['상태'] == '승인완료'].shape[0]\n",
        "        approval_rate = (approval_count / total_rows * 100) if total_rows > 0 else 0\n",
        "\n",
        "        # 담당자별 분포 분석\n",
        "        manager_dist = df['담당자'].value_counts().head(10).to_dict()\n",
        "\n",
        "        # 판매처별 분포 분석\n",
        "        channel_dist = {}\n",
        "        if '판매처' in df.columns:\n",
        "            channel_dist = df['판매처'].value_counts().head(10).to_dict()\n",
        "\n",
        "        info_text = f\"\"\"✅ 데이터 로딩 성공!\n",
        "\n",
        "📊 데이터 개요:\n",
        "- 전체 리드 수: {total_rows:,}개\n",
        "- 승인완료: {approval_count}건 ({approval_rate:.1f}%)\n",
        "- 컬럼 수: {len(df.columns)}개\n",
        "\n",
        "📈 상태별 분포:\n",
        "{chr(10).join([f'- {status}: {count}건' for status, count in list(status_dist.items())[:5]])}\n",
        "\n",
        "👥 상위 담당자 (리드 수):\n",
        "{chr(10).join([f'- {manager}: {count}건' for manager, count in list(manager_dist.items())[:5]])}\n",
        "\n",
        "🏪 주요 판매처:\n",
        "{chr(10).join([f'- {channel}: {count}건' for channel, count in list(channel_dist.items())[:3]])}\n",
        "\n",
        "✅ 데이터 로드 완료! 이제 [전처리 실행] 버튼을 클릭하세요.\n",
        "\"\"\"\n",
        "\n",
        "        app_state.data = df\n",
        "        app_state.is_data_loaded = True\n",
        "        return df, info_text\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ 데이터 로딩 중 오류 발생: {str(e)}\"\n",
        "\n",
        "def preprocess_for_prediction(df: pd.DataFrame = None) -> Tuple[pd.DataFrame, str]:\n",
        "    \"\"\"리드 전환 예측을 위한 고급 데이터 전처리\"\"\"\n",
        "    try:\n",
        "        if df is None:\n",
        "            if app_state.data is None:\n",
        "                return None, \"❌ 먼저 데이터를 로드해주세요.\"\n",
        "            df = app_state.data\n",
        "\n",
        "        data = df.copy()\n",
        "\n",
        "        # 타겟 변수 생성\n",
        "        data['is_approved'] = (data['상태'] == '승인완료').astype(int)\n",
        "\n",
        "        # 담당자 정보 정제\n",
        "        data['담당자'] = data['담당자'].fillna('미배정')\n",
        "        data['담당자명'] = data['담당자'].str.extract(r'([^(]+)')[0].str.strip()\n",
        "        data['담당자명'] = data['담당자명'].fillna('미배정')\n",
        "\n",
        "        # 날짜 처리\n",
        "        if '등록일자' in data.columns:\n",
        "            data['등록일자'] = pd.to_datetime(data['등록일자'], errors='coerce')\n",
        "            data['등록_년'] = data['등록일자'].dt.year\n",
        "            data['등록_월'] = data['등록일자'].dt.month\n",
        "            data['등록_일'] = data['등록일자'].dt.day\n",
        "            data['등록_요일'] = data['등록일자'].dt.dayofweek\n",
        "            data['등록_시간'] = data['등록일자'].dt.hour\n",
        "        else:\n",
        "            # 기본값 설정\n",
        "            data['등록_년'] = 2024\n",
        "            data['등록_월'] = 1\n",
        "            data['등록_일'] = 1\n",
        "            data['등록_요일'] = 0\n",
        "            data['등록_시간'] = 9\n",
        "\n",
        "        # 접촉 횟수 추출\n",
        "        data['접촉횟수'] = 0\n",
        "        contact_pattern = r'(\\d+)회 접촉'\n",
        "        contact_matches = data['상태'].str.extract(contact_pattern)\n",
        "        data.loc[contact_matches[0].notna(), '접촉횟수'] = contact_matches[0].fillna(0).astype(int)\n",
        "\n",
        "        # 메모 길이 계산\n",
        "        if '메모' in data.columns:\n",
        "            data['메모_길이'] = data['메모'].fillna('').str.len()\n",
        "            data['메모_단어수'] = data['메모'].fillna('').str.split().str.len()\n",
        "        else:\n",
        "            data['메모_길이'] = 50\n",
        "            data['메모_단어수'] = 10\n",
        "\n",
        "        # 동의 정보 수치화\n",
        "        consent_cols = ['마케팅활용동의', '이메일수신동의', '문자수신동의']\n",
        "        for col in consent_cols:\n",
        "            if col in data.columns:\n",
        "                data[f'{col}_num'] = (data[col] == '동의').astype(int)\n",
        "            else:\n",
        "                data[f'{col}_num'] = 1  # 기본값\n",
        "\n",
        "        # 고급 피처 엔지니어링 적용\n",
        "        data = advanced_feature_engineering(data)\n",
        "\n",
        "        # 담당자별 성과 통계 계산\n",
        "        manager_stats = data[data['담당자명'] != '미배정'].groupby('담당자명').agg({\n",
        "            'is_approved': ['count', 'sum', 'mean'],\n",
        "            '접촉횟수': 'mean'\n",
        "        }).round(3)\n",
        "\n",
        "        if len(manager_stats) > 0:\n",
        "            manager_stats.columns = ['총_리드수', '승인완료수', '승인완료율', '평균_접촉횟수']\n",
        "            manager_stats = manager_stats.reset_index()\n",
        "            manager_stats = manager_stats.sort_values('승인완료율', ascending=False)\n",
        "        else:\n",
        "            manager_stats = pd.DataFrame()\n",
        "\n",
        "        # 전처리 결과 요약\n",
        "        feature_count = len([col for col in data.columns if col not in df.columns])\n",
        "\n",
        "        result_text = f\"\"\"✅ 고급 데이터 전처리 완료!\n",
        "\n",
        "📊 타겟 변수 분포:\n",
        "- 승인완료: {data['is_approved'].sum():,}건 ({data['is_approved'].mean():.1%})\n",
        "- 미승인: {(1-data['is_approved']).sum():,}건\n",
        "\n",
        "🔧 피처 엔지니어링:\n",
        "- 생성된 신규 피처: {feature_count}개\n",
        "- 담당자별 성과 지표 추가\n",
        "- 시간대별 패턴 추출\n",
        "- 고객 프로파일 분석\n",
        "- 상호작용 피처 생성\n",
        "\n",
        "👥 담당자별 성과 (상위 5명):\n",
        "{manager_stats.head().to_string(index=False) if len(manager_stats) > 0 else '담당자 데이터 없음'}\n",
        "\n",
        "📈 주요 피처 생성:\n",
        "- 담당자 경험 및 효율성 지표\n",
        "- 시간대별 패턴 (주말, 시간대, 월초/월말)\n",
        "- 판매처별 성과 지표\n",
        "- 고객 프로파일별 승인율\n",
        "- 메모 품질 점수\n",
        "- 이상치 탐지 플래그\n",
        "\n",
        "✅ 전처리 완료! 이제 다른 탭에서 분석을 진행하세요.\n",
        "\"\"\"\n",
        "\n",
        "        app_state.processed_data = data\n",
        "        app_state.manager_performance = manager_stats\n",
        "        app_state.is_preprocessed = True\n",
        "        return data, result_text\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"❌ 전처리 중 오류 발생: {str(e)}\\n\\n상세 오류:\\n{type(e).__name__}: {str(e)}\"\n",
        "\n",
        "# ================================================================================\n",
        "# 7. 담당자별 성과 분석 및 시각화 (기존 유지)\n",
        "# ================================================================================\n",
        "\n",
        "def create_manager_performance_dashboard() -> Tuple[List[go.Figure], str]:\n",
        "    \"\"\"담당자별 성과 대시보드 생성\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_preprocessed or app_state.processed_data is None:\n",
        "            return [], \"❌ 먼저 데이터를 로드하고 전처리를 실행해주세요.\"\n",
        "\n",
        "        data = app_state.processed_data\n",
        "        plots = []\n",
        "\n",
        "        # 1. 담당자별 승인완료율 및 처리량\n",
        "        manager_stats = data[data['담당자명'] != '미배정'].groupby('담당자명').agg({\n",
        "            'is_approved': ['count', 'sum', 'mean']\n",
        "        }).round(3)\n",
        "\n",
        "        if len(manager_stats) == 0:\n",
        "            return [], \"❌ 담당자 데이터가 없습니다.\"\n",
        "\n",
        "        manager_stats.columns = ['총_리드수', '승인완료수', '승인완료율']\n",
        "        manager_stats = manager_stats.reset_index()\n",
        "        manager_stats = manager_stats[manager_stats['총_리드수'] >= 5]  # 5건 이상만 표시\n",
        "        manager_stats = manager_stats.sort_values('승인완료율', ascending=False)\n",
        "\n",
        "        # 그래프 1: 담당자별 성과 매트릭스\n",
        "        fig1 = px.scatter(manager_stats,\n",
        "                         x='총_리드수',\n",
        "                         y='승인완료율',\n",
        "                         size='승인완료수',\n",
        "                         text='담당자명',\n",
        "                         color='승인완료율',\n",
        "                         title='담당자별 성과 매트릭스 (리드 처리량 vs 승인완료율)',\n",
        "                         color_continuous_scale='RdYlGn')\n",
        "\n",
        "        fig1.update_traces(textposition='top center', textfont_size=10)\n",
        "        fig1.update_layout(\n",
        "            height=500,\n",
        "            xaxis_title='총 리드 처리수',\n",
        "            yaxis_title='승인완료율',\n",
        "            yaxis_tickformat='.0%'\n",
        "        )\n",
        "\n",
        "        # 평균선 추가\n",
        "        avg_approval_rate = data['is_approved'].mean()\n",
        "        fig1.add_hline(y=avg_approval_rate, line_dash=\"dash\", line_color=\"gray\",\n",
        "                       annotation_text=f\"전체 평균: {avg_approval_rate:.1%}\")\n",
        "\n",
        "        plots.append(fig1)\n",
        "\n",
        "        # 그래프 2: 담당자별 승인완료율 순위\n",
        "        fig2 = go.Figure()\n",
        "\n",
        "        # 상위 10명\n",
        "        top_managers = manager_stats.head(10)\n",
        "        fig2.add_trace(go.Bar(\n",
        "            x=top_managers['담당자명'],\n",
        "            y=top_managers['승인완료율'],\n",
        "            text=top_managers['승인완료율'].apply(lambda x: f'{x:.1%}'),\n",
        "            textposition='outside',\n",
        "            name='승인완료율',\n",
        "            marker_color='lightgreen'\n",
        "        ))\n",
        "\n",
        "        fig2.update_layout(\n",
        "            title='담당자별 승인완료율 TOP 10',\n",
        "            xaxis_title='담당자',\n",
        "            yaxis_title='승인완료율',\n",
        "            yaxis_tickformat='.0%',\n",
        "            height=400\n",
        "        )\n",
        "\n",
        "        plots.append(fig2)\n",
        "\n",
        "        # 그래프 3: 담당자별 일일 처리 패턴\n",
        "        if '등록일자' in data.columns and pd.api.types.is_datetime64_any_dtype(data['등록일자']):\n",
        "            daily_stats = data.groupby(['담당자명', pd.Grouper(key='등록일자', freq='D')]).agg({\n",
        "                'is_approved': ['count', 'mean']\n",
        "            }).reset_index()\n",
        "            daily_stats.columns = ['담당자명', '날짜', '처리건수', '승인완료율']\n",
        "\n",
        "            # 상위 5명 담당자만 표시\n",
        "            top_5_managers = manager_stats.head(5)['담당자명'].tolist()\n",
        "            daily_top = daily_stats[daily_stats['담당자명'].isin(top_5_managers)]\n",
        "\n",
        "            if len(daily_top) > 0:\n",
        "                fig3 = px.line(daily_top,\n",
        "                              x='날짜',\n",
        "                              y='승인완료율',\n",
        "                              color='담당자명',\n",
        "                              title='상위 5명 담당자의 일별 승인완료율 추이',\n",
        "                              markers=True)\n",
        "\n",
        "                fig3.update_layout(\n",
        "                    height=400,\n",
        "                    yaxis_tickformat='.0%',\n",
        "                    hovermode='x unified'\n",
        "                )\n",
        "\n",
        "                plots.append(fig3)\n",
        "\n",
        "        # 그래프 4: 담당자별 접촉 효율성\n",
        "        contact_stats = data[data['담당자명'] != '미배정'].groupby('담당자명').agg({\n",
        "            '접촉횟수': 'mean',\n",
        "            'is_approved': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        contact_stats = contact_stats[contact_stats['접촉횟수'] > 0]\n",
        "\n",
        "        if len(contact_stats) > 0:\n",
        "            contact_stats['효율성'] = contact_stats['is_approved'] / (contact_stats['접촉횟수'] + 1)  # +1 to avoid division by zero\n",
        "            contact_stats = contact_stats.sort_values('효율성', ascending=False).head(15)\n",
        "\n",
        "            fig4 = go.Figure()\n",
        "            fig4.add_trace(go.Bar(\n",
        "                x=contact_stats['담당자명'],\n",
        "                y=contact_stats['효율성'],\n",
        "                text=contact_stats['효율성'].apply(lambda x: f'{x:.3f}'),\n",
        "                textposition='outside',\n",
        "                name='접촉 효율성',\n",
        "                marker_color='lightcoral'\n",
        "            ))\n",
        "\n",
        "            fig4.update_layout(\n",
        "                title='담당자별 접촉 효율성 (승인율/평균접촉횟수)',\n",
        "                xaxis_title='담당자',\n",
        "                yaxis_title='효율성 지수',\n",
        "                height=400\n",
        "            )\n",
        "\n",
        "            plots.append(fig4)\n",
        "\n",
        "        success_message = \"✅ 성과 분석 완료!\"\n",
        "        return plots, success_message\n",
        "\n",
        "    except Exception as e:\n",
        "        return [], f\"❌ 성과 분석 중 오류 발생: {str(e)}\"\n",
        "\n",
        "# ================================================================================\n",
        "# 8. 하이퍼파라미터 최적화\n",
        "# ================================================================================\n",
        "\n",
        "def optimize_hyperparameters(X_train, y_train, model_type='xgboost'):\n",
        "    \"\"\"Optuna를 사용한 하이퍼파라미터 최적화 (오류 처리 강화)\"\"\"\n",
        "    if not OPTUNA_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        def objective(trial):\n",
        "            try:\n",
        "                if model_type == 'xgboost':\n",
        "                    params = {\n",
        "                        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "                        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "                        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "                        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "                        'gamma': trial.suggest_float('gamma', 0, 3),\n",
        "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
        "                        'random_state': 42,\n",
        "                        'use_label_encoder': False,\n",
        "                        'eval_metric': 'logloss'\n",
        "                    }\n",
        "                    model = xgb.XGBClassifier(**params)\n",
        "\n",
        "                elif model_type == 'lightgbm':\n",
        "                    params = {\n",
        "                        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "                        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "                        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
        "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
        "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 5),\n",
        "                        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
        "                        'random_state': 42,\n",
        "                        'verbose': -1\n",
        "                    }\n",
        "                    model = lgb.LGBMClassifier(**params)\n",
        "\n",
        "                elif model_type == 'catboost':\n",
        "                    if not CATBOOST_AVAILABLE:\n",
        "                        return 0\n",
        "                    params = {\n",
        "                        'iterations': trial.suggest_int('iterations', 50, 150),\n",
        "                        'depth': trial.suggest_int('depth', 3, 8),\n",
        "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "                        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 5),\n",
        "                        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 0.5),\n",
        "                        'random_strength': trial.suggest_float('random_strength', 0, 0.5),\n",
        "                        'random_state': 42,\n",
        "                        'verbose': False\n",
        "                    }\n",
        "                    model = CatBoostClassifier(**params)\n",
        "\n",
        "                # 간단한 교차 검증 (시계열 분할 대신 일반 분할 사용)\n",
        "                if len(X_train) < 100:\n",
        "                    # 데이터가 적은 경우 단순 학습/검증 분할\n",
        "                    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "                        X_train, y_train, test_size=0.2, random_state=42\n",
        "                    )\n",
        "                    model.fit(X_tr, y_tr)\n",
        "                    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "                    score = roc_auc_score(y_val, y_pred_proba)\n",
        "                else:\n",
        "                    # 충분한 데이터가 있는 경우 교차 검증\n",
        "                    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "                    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
        "                    score = scores.mean()\n",
        "\n",
        "                return score\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Trial 실패: {str(e)}\")\n",
        "                return 0.0\n",
        "\n",
        "        # 최적화 수행 (시도 횟수 줄임)\n",
        "        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "        study.optimize(objective, n_trials=10, show_progress_bar=False, catch=(Exception,))\n",
        "\n",
        "        # 완료된 trial이 있는지 확인\n",
        "        if len(study.trials) == 0 or study.best_trial is None:\n",
        "            print(f\"{model_type} 최적화 실패 - 기본 파라미터 사용\")\n",
        "            return None\n",
        "\n",
        "        return study.best_params\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"하이퍼파라미터 최적화 중 오류: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# ================================================================================\n",
        "# 9. 개선된 머신러닝 모델 학습\n",
        "# ================================================================================\n",
        "\n",
        "def handle_class_imbalance(X_train, y_train):\n",
        "    \"\"\"클래스 불균형 처리 (안전한 버전)\"\"\"\n",
        "    if not IMBALANCED_AVAILABLE:\n",
        "        return X_train, y_train\n",
        "\n",
        "    try:\n",
        "        # 클래스 비율 확인\n",
        "        unique, counts = np.unique(y_train, return_counts=True)\n",
        "        min_class_count = min(counts)\n",
        "\n",
        "        # 소수 클래스가 너무 적으면 SMOTE 사용 불가\n",
        "        if min_class_count < 6:\n",
        "            print(\"소수 클래스 샘플이 너무 적어 불균형 처리를 건너뜁니다.\")\n",
        "            return X_train, y_train\n",
        "\n",
        "        # SMOTE만 사용 (SMOTEENN은 때때로 불안정함)\n",
        "        smote = SMOTE(random_state=42, k_neighbors=min(5, min_class_count-1))\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "        print(f\"클래스 불균형 처리 완료: {len(X_train)} → {len(X_resampled)}\")\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"클래스 불균형 처리 중 오류: {str(e)}\")\n",
        "        # 실패 시 원본 반환\n",
        "        return X_train, y_train\n",
        "\n",
        "def select_best_features(X_train, y_train, X_test, feature_names, k=20):\n",
        "    \"\"\"최적 피처 선택 (안전한 버전)\"\"\"\n",
        "    try:\n",
        "        # 피처 수가 k보다 적으면 모든 피처 사용\n",
        "        if X_train.shape[1] <= k:\n",
        "            return X_train, X_test, feature_names, None\n",
        "\n",
        "        # 분산이 0인 피처 제거\n",
        "        var_selector = VarianceThreshold(threshold=0.01)\n",
        "        X_train_var = var_selector.fit_transform(X_train)\n",
        "        X_test_var = var_selector.transform(X_test)\n",
        "        selected_features_var = [feature_names[i] for i in var_selector.get_support(indices=True)]\n",
        "\n",
        "        # 피처가 너무 많이 제거되었다면 원본 사용\n",
        "        if len(selected_features_var) < 5:\n",
        "            return X_train, X_test, feature_names, None\n",
        "\n",
        "        # 상호 정보량 기반 피처 선택\n",
        "        selector = SelectKBest(score_func=mutual_info_classif, k=min(k, len(selected_features_var)))\n",
        "        selector.fit(X_train_var, y_train)\n",
        "\n",
        "        # 선택된 피처 인덱스\n",
        "        selected_indices = selector.get_support(indices=True)\n",
        "        final_features = [selected_features_var[i] for i in selected_indices]\n",
        "\n",
        "        # 변환\n",
        "        X_train_selected = selector.transform(X_train_var)\n",
        "        X_test_selected = selector.transform(X_test_var)\n",
        "\n",
        "        print(f\"피처 선택 완료: {X_train.shape[1]} → {X_train_selected.shape[1]}\")\n",
        "\n",
        "        return X_train_selected, X_test_selected, final_features, selector\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"피처 선택 중 오류: {str(e)}\")\n",
        "        return X_train, X_test, feature_names, None\n",
        "\n",
        "def build_advanced_lstm_model(input_shape: Tuple[int, int]) -> keras.Model:\n",
        "    \"\"\"개선된 LSTM 모델 구축\"\"\"\n",
        "    if not TENSORFLOW_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.LSTM(128, return_sequences=True, input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.LSTM(64, return_sequences=True),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.LSTM(32, return_sequences=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'AUC', keras.metrics.Precision(), keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_prophet_for_manager(manager_data: pd.DataFrame) -> Any:\n",
        "    \"\"\"Prophet 모델 학습\"\"\"\n",
        "    if not PROPHET_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Prophet 형식으로 데이터 준비\n",
        "        prophet_data = manager_data[['날짜', '승인율']].rename(\n",
        "            columns={'날짜': 'ds', '승인율': 'y'}\n",
        "        )\n",
        "\n",
        "        # 모델 학습\n",
        "        model = Prophet(\n",
        "            changepoint_prior_scale=0.05,\n",
        "            seasonality_prior_scale=10,\n",
        "            holidays_prior_scale=10,\n",
        "            daily_seasonality=False,\n",
        "            weekly_seasonality=True,\n",
        "            yearly_seasonality=False\n",
        "        )\n",
        "\n",
        "        model.fit(prophet_data)\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Prophet 학습 오류: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def train_prediction_model_with_data(filtered_data: pd.DataFrame = None) -> Tuple[Dict, str]:\n",
        "    \"\"\"개선된 리드 전환 예측 모델 학습\"\"\"\n",
        "    try:\n",
        "        if filtered_data is None:\n",
        "            filtered_data = app_state.processed_data\n",
        "\n",
        "        if filtered_data is None or len(filtered_data) == 0:\n",
        "            return {}, \"❌ 학습할 데이터가 없습니다.\"\n",
        "\n",
        "        data = filtered_data\n",
        "\n",
        "        # 타겟 변수 확인\n",
        "        if 'is_approved' not in data.columns:\n",
        "            return {}, \"❌ 타겟 변수(is_approved)가 없습니다.\"\n",
        "\n",
        "        # 피처 준비\n",
        "        feature_cols = []\n",
        "\n",
        "        # 수치형 피처 (확장된 버전)\n",
        "        numerical_features = [\n",
        "            '접촉횟수', '메모_길이', '메모_단어수',\n",
        "            '등록_월', '등록_일', '등록_요일', '등록_시간',\n",
        "            '담당자_승인율', '담당자_총승인수', '담당자_총리드수',\n",
        "            '담당자_평균접촉', '담당자_경험지수', '담당자_효율성',\n",
        "            '판매처_평균승인율', '판매처_빈도', '프로파일_승인율',\n",
        "            '동의점수', '완전동의', '메모_품질점수',\n",
        "            '담당자X판매처_시너지', '접촉X메모_상호작용'\n",
        "        ]\n",
        "\n",
        "        # 범주형 피처\n",
        "        categorical_features = ['담당자명', '판매처', '성별', '유형', '시간대', '고객프로파일']\n",
        "\n",
        "        # 동의 관련 피처\n",
        "        consent_features = ['마케팅활용동의_num', '이메일수신동의_num', '문자수신동의_num']\n",
        "\n",
        "        # 키워드 피처\n",
        "        keyword_features = [col for col in data.columns if col.startswith('메모_') and col.endswith('_포함')]\n",
        "\n",
        "        # 이상치 피처\n",
        "        outlier_features = [col for col in data.columns if col.endswith('_이상치')]\n",
        "\n",
        "        # 사용 가능한 피처만 선택\n",
        "        all_features = numerical_features + consent_features + keyword_features + outlier_features\n",
        "        for col in all_features:\n",
        "            if col in data.columns:\n",
        "                feature_cols.append(col)\n",
        "\n",
        "        if len(feature_cols) == 0:\n",
        "            return {}, \"❌ 사용 가능한 피처가 없습니다.\"\n",
        "\n",
        "        # 범주형 변수 인코딩\n",
        "        encoded_data = data.copy()\n",
        "        encoders = {}\n",
        "\n",
        "        for col in categorical_features:\n",
        "            if col in data.columns:\n",
        "                try:\n",
        "                    encoded_data[col] = encoded_data[col].fillna('Unknown')\n",
        "                    le = LabelEncoder()\n",
        "                    encoded_data[f'{col}_encoded'] = le.fit_transform(encoded_data[col].astype(str))\n",
        "                    encoders[col] = le\n",
        "                    feature_cols.append(f'{col}_encoded')\n",
        "                except Exception as e:\n",
        "                    print(f\"⚠️ {col} 인코딩 실패: {str(e)}\")\n",
        "\n",
        "        # 훈련 데이터 준비\n",
        "        X = encoded_data[feature_cols].fillna(0)\n",
        "        y = encoded_data['is_approved']\n",
        "\n",
        "        # 데이터 검증\n",
        "        if len(X) < 50:\n",
        "            return {}, f\"❌ 학습 데이터가 너무 적습니다. (현재: {len(X)}건, 최소: 50건)\"\n",
        "\n",
        "        # 스케일링\n",
        "        scaler = RobustScaler()  # 이상치에 강한 스케일러\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        app_state.scaler = scaler\n",
        "\n",
        "        # 데이터 분할\n",
        "        try:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        "            )\n",
        "        except:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_scaled, y, test_size=0.2, random_state=42\n",
        "            )\n",
        "\n",
        "        # 클래스 불균형 처리\n",
        "        X_train_balanced, y_train_balanced = handle_class_imbalance(X_train, y_train)\n",
        "\n",
        "        # 피처 선택\n",
        "        X_train_selected, X_test_selected, selected_features, feature_selector = select_best_features(\n",
        "            X_train_balanced, y_train_balanced, X_test, feature_cols\n",
        "        )\n",
        "        app_state.feature_selector = feature_selector\n",
        "\n",
        "        # 모델 정의\n",
        "        models = {\n",
        "            'Random Forest': RandomForestClassifier(\n",
        "                n_estimators=100, random_state=42, max_depth=10,\n",
        "                min_samples_split=5, min_samples_leaf=2,\n",
        "                class_weight='balanced'\n",
        "            ),\n",
        "            'Gradient Boosting': GradientBoostingClassifier(\n",
        "                n_estimators=100, random_state=42, max_depth=5,\n",
        "                learning_rate=0.1, subsample=0.8\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # 하이퍼파라미터 최적화 시도 (선택적)\n",
        "        optimization_attempted = False\n",
        "        if OPTUNA_AVAILABLE and len(X_train_selected) >= 100:  # 충분한 데이터가 있을 때만\n",
        "            try:\n",
        "                print(\"하이퍼파라미터 최적화 시도 중...\")\n",
        "\n",
        "                # XGBoost 최적화\n",
        "                xgb_params = optimize_hyperparameters(X_train_selected, y_train_balanced, 'xgboost')\n",
        "                if xgb_params:\n",
        "                    models['XGBoost (Optimized)'] = xgb.XGBClassifier(**xgb_params)\n",
        "                    optimization_attempted = True\n",
        "\n",
        "                # LightGBM 최적화\n",
        "                lgb_params = optimize_hyperparameters(X_train_selected, y_train_balanced, 'lightgbm')\n",
        "                if lgb_params:\n",
        "                    models['LightGBM (Optimized)'] = lgb.LGBMClassifier(**lgb_params)\n",
        "                    optimization_attempted = True\n",
        "\n",
        "                # CatBoost 최적화\n",
        "                if CATBOOST_AVAILABLE:\n",
        "                    cat_params = optimize_hyperparameters(X_train_selected, y_train_balanced, 'catboost')\n",
        "                    if cat_params:\n",
        "                        models['CatBoost (Optimized)'] = CatBoostClassifier(**cat_params)\n",
        "                        optimization_attempted = True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"최적화 중 오류 발생: {str(e)}\")\n",
        "                optimization_attempted = False\n",
        "\n",
        "        # 기본 모델 추가 (최적화 실패 시 또는 항상 포함)\n",
        "        if not optimization_attempted or True:  # 항상 기본 모델도 포함\n",
        "            models['XGBoost'] = xgb.XGBClassifier(\n",
        "                n_estimators=100, random_state=42, max_depth=6,\n",
        "                learning_rate=0.1, use_label_encoder=False, eval_metric='logloss'\n",
        "            )\n",
        "            models['LightGBM'] = lgb.LGBMClassifier(\n",
        "                n_estimators=100, random_state=42, max_depth=6,\n",
        "                learning_rate=0.1, verbose=-1\n",
        "            )\n",
        "            if CATBOOST_AVAILABLE:\n",
        "                models['CatBoost'] = CatBoostClassifier(\n",
        "                    iterations=100, random_state=42, depth=6,\n",
        "                    learning_rate=0.1, verbose=False\n",
        "                )\n",
        "\n",
        "        # 시계열 모델 추가 (선택적 - 사용 가능한 모델만)\n",
        "        time_series_models = {}\n",
        "        time_series_attempted = 0\n",
        "\n",
        "        # 시계열 데이터 준비\n",
        "        if '등록일자' in data.columns:\n",
        "            ts_data = prepare_time_series_data(data)\n",
        "\n",
        "            if len(ts_data) > 0:\n",
        "                # 담당자별 시계열 모델 학습\n",
        "                for manager in ts_data['담당자'].unique()[:5]:  # 상위 5명만\n",
        "                    manager_ts = ts_data[ts_data['담당자'] == manager]\n",
        "\n",
        "                    # LSTM 모델 (TensorFlow 필요)\n",
        "                    if TENSORFLOW_AVAILABLE and len(manager_ts) >= 30:\n",
        "                        try:\n",
        "                            lstm_model, lstm_scaler = train_lstm_for_manager(manager_ts)\n",
        "                            if lstm_model:\n",
        "                                time_series_models[f'LSTM_{manager}'] = {\n",
        "                                    'model': lstm_model,\n",
        "                                    'scaler': lstm_scaler,\n",
        "                                    'type': 'lstm'\n",
        "                                }\n",
        "                                time_series_attempted += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"LSTM 모델 학습 실패 ({manager}): {str(e)}\")\n",
        "\n",
        "                    # ARIMA 모델 (statsmodels 필요)\n",
        "                    if STATSMODELS_AVAILABLE and len(manager_ts) >= 30:\n",
        "                        try:\n",
        "                            arima_model = train_arima_for_manager(manager_ts)\n",
        "                            if arima_model:\n",
        "                                time_series_models[f'ARIMA_{manager}'] = {\n",
        "                                    'model': arima_model,\n",
        "                                    'type': 'arima'\n",
        "                                }\n",
        "                                time_series_attempted += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"ARIMA 모델 학습 실패 ({manager}): {str(e)}\")\n",
        "\n",
        "                    # Prophet 모델 (prophet 필요)\n",
        "                    if PROPHET_AVAILABLE and len(manager_ts) >= 30:\n",
        "                        try:\n",
        "                            prophet_model = train_prophet_for_manager(manager_ts)\n",
        "                            if prophet_model:\n",
        "                                time_series_models[f'Prophet_{manager}'] = {\n",
        "                                    'model': prophet_model,\n",
        "                                    'type': 'prophet'\n",
        "                                }\n",
        "                                time_series_attempted += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"Prophet 모델 학습 실패 ({manager}): {str(e)}\")\n",
        "\n",
        "        results = {}\n",
        "        best_score = -1\n",
        "        best_model = None\n",
        "        best_model_name = None\n",
        "        ensemble_models = []\n",
        "\n",
        "        result_text = f\"🤖 고급 모델 학습 결과 (학습 데이터: {len(X)}건):\\n\" + \"=\"*50 + \"\\n\\n\"\n",
        "\n",
        "        # 모델 학습 및 평가\n",
        "        result_text += \"📊 머신러닝 모델 성능:\\n\"\n",
        "        for name, model in models.items():\n",
        "            try:\n",
        "                model.fit(X_train_selected, y_train_balanced)\n",
        "                y_pred = model.predict(X_test_selected)\n",
        "                y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "                # 다양한 메트릭 계산\n",
        "                roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "                f1 = f1_score(y_test, y_pred)\n",
        "                precision = precision_score(y_test, y_pred)\n",
        "                recall = recall_score(y_test, y_pred)\n",
        "\n",
        "                results[name] = {\n",
        "                    'model': model,\n",
        "                    'roc_auc': roc_auc,\n",
        "                    'f1_score': f1,\n",
        "                    'precision': precision,\n",
        "                    'recall': recall,\n",
        "                    'predictions': y_pred_proba,\n",
        "                    'y_test': y_test,\n",
        "                    'type': 'ml'\n",
        "                }\n",
        "\n",
        "                result_text += f\"  - {name}:\\n\"\n",
        "                result_text += f\"    • ROC-AUC: {roc_auc:.4f}\\n\"\n",
        "                result_text += f\"    • F1-Score: {f1:.4f}\\n\"\n",
        "                result_text += f\"    • Precision: {precision:.4f}\\n\"\n",
        "                result_text += f\"    • Recall: {recall:.4f}\\n\"\n",
        "\n",
        "                if roc_auc > best_score:\n",
        "                    best_score = roc_auc\n",
        "                    best_model = model\n",
        "                    best_model_name = name\n",
        "\n",
        "                # 앙상블에 포함할 모델 선택 (ROC-AUC > 0.6)\n",
        "                if roc_auc > 0.6:\n",
        "                    ensemble_models.append((name, model))\n",
        "\n",
        "            except Exception as e:\n",
        "                result_text += f\"  ❌ {name} 학습 실패: {str(e)}\\n\"\n",
        "\n",
        "        # 앙상블 모델 생성 (3개 이상의 모델이 성공한 경우)\n",
        "        if len(ensemble_models) >= 2:  # 기준을 3개에서 2개로 낮춤\n",
        "            try:\n",
        "                voting_clf = VotingClassifier(\n",
        "                    estimators=ensemble_models,\n",
        "                    voting='soft'\n",
        "                )\n",
        "                voting_clf.fit(X_train_selected, y_train_balanced)\n",
        "                y_pred_ensemble = voting_clf.predict_proba(X_test_selected)[:, 1]\n",
        "                ensemble_auc = roc_auc_score(y_test, y_pred_ensemble)\n",
        "\n",
        "                results['Ensemble'] = {\n",
        "                    'model': voting_clf,\n",
        "                    'roc_auc': ensemble_auc,\n",
        "                    'predictions': y_pred_ensemble,\n",
        "                    'y_test': y_test,\n",
        "                    'type': 'ensemble'\n",
        "                }\n",
        "\n",
        "                result_text += f\"\\n🎯 앙상블 모델 (상위 {len(ensemble_models)}개 결합):\\n\"\n",
        "                result_text += f\"  - ROC-AUC: {ensemble_auc:.4f}\\n\"\n",
        "\n",
        "                if ensemble_auc > best_score:\n",
        "                    best_score = ensemble_auc\n",
        "                    best_model = voting_clf\n",
        "                    best_model_name = 'Ensemble'\n",
        "                    app_state.ensemble_model = voting_clf\n",
        "\n",
        "            except Exception as e:\n",
        "                result_text += f\"\\n⚠️ 앙상블 생성 실패: {str(e)}\\n\"\n",
        "\n",
        "        # 시계열 모델 결과 추가\n",
        "        if time_series_models:\n",
        "            result_text += \"\\n📈 시계열 전문 모델:\\n\"\n",
        "            for name, model_info in time_series_models.items():\n",
        "                result_text += f\"  - {name}: 학습 완료\\n\"\n",
        "                results[name] = model_info\n",
        "\n",
        "        if best_model is None:\n",
        "            return {}, \"❌ 모든 모델 학습에 실패했습니다.\"\n",
        "\n",
        "        result_text += f\"\\n🏆 최고 성능 모델: {best_model_name} (ROC-AUC: {best_score:.4f})\\n\"\n",
        "\n",
        "        # 피처 중요도\n",
        "        if hasattr(best_model, 'feature_importances_'):\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': selected_features,\n",
        "                'importance': best_model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False).head(10)\n",
        "\n",
        "            result_text += \"\\n📊 상위 10개 중요 피처:\\n\"\n",
        "            for _, row in feature_importance.iterrows():\n",
        "                result_text += f\"  - {row['feature']}: {row['importance']:.4f}\\n\"\n",
        "\n",
        "        # 시계열 모델 사용 가능 여부\n",
        "        if time_series_models:\n",
        "            result_text += f\"\\n🔮 시계열 모델 {len(time_series_models)}개 추가 학습 완료!\"\n",
        "            result_text += \"\\n   (사용 가능: \"\n",
        "            model_types = set([info['type'] for info in time_series_models.values()])\n",
        "            result_text += \", \".join([t.upper() for t in model_types]) + \")\"\n",
        "        else:\n",
        "            result_text += \"\\n📊 시계열 모델은 사용할 수 없지만, ML 모델로 충분한 예측이 가능합니다.\"\n",
        "\n",
        "        result_text += \"\\n\\n✅ 고급 모델 학습 완료!\"\n",
        "\n",
        "        # 상태 저장\n",
        "        app_state.best_model = best_model\n",
        "        app_state.best_model_name = best_model_name\n",
        "        app_state.feature_names = selected_features\n",
        "        app_state.encoders = encoders\n",
        "        app_state.model_results = results\n",
        "        app_state.time_series_models = time_series_models if time_series_models else {}\n",
        "        app_state.is_model_trained = True\n",
        "\n",
        "        # 담당자별 성과 재계산 (필터링된 데이터 기준)\n",
        "        manager_stats = data[data['담당자명'] != '미배정'].groupby('담당자명').agg({\n",
        "            'is_approved': ['count', 'sum', 'mean'],\n",
        "            '접촉횟수': 'mean'\n",
        "        }).round(3)\n",
        "\n",
        "        if len(manager_stats) > 0:\n",
        "            manager_stats.columns = ['총_리드수', '승인완료수', '승인완료율', '평균_접촉횟수']\n",
        "            manager_stats = manager_stats.reset_index()\n",
        "            app_state.manager_performance = manager_stats\n",
        "\n",
        "        return results, result_text\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        error_message = f\"❌ 모델 학습 중 오류 발생:\\n{str(e)}\\n\\n\"\n",
        "\n",
        "        # 더 자세한 오류 정보 제공\n",
        "        if \"No trials are completed\" in str(e):\n",
        "            error_message += \"💡 하이퍼파라미터 최적화에 실패했습니다. 기본 모델로 재시도 중...\\n\"\n",
        "\n",
        "            # 기본 모델로 재시도\n",
        "            try:\n",
        "                # 간단한 모델로 재시도\n",
        "                simple_model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)\n",
        "                simple_model.fit(X_train[:, :min(10, X_train.shape[1])], y_train)  # 피처 수 제한\n",
        "\n",
        "                app_state.best_model = simple_model\n",
        "                app_state.best_model_name = \"Random Forest (Basic)\"\n",
        "                app_state.is_model_trained = True\n",
        "\n",
        "                return {\"Random Forest (Basic)\": {'model': simple_model}}, \"✅ 기본 모델로 학습 완료!\"\n",
        "\n",
        "            except Exception as e2:\n",
        "                error_message += f\"\\n기본 모델 학습도 실패: {str(e2)}\"\n",
        "\n",
        "        return {}, error_message\n",
        "\n",
        "# ================================================================================\n",
        "# 10. 나머지 함수들 (기존 코드 재사용)\n",
        "# ================================================================================\n",
        "\n",
        "# 기존 코드의 나머지 함수들을 그대로 포함\n",
        "# - prepare_time_series_data\n",
        "# - build_lstm_model (advanced 버전으로 대체됨)\n",
        "# - train_lstm_for_manager\n",
        "# - train_arima_for_manager\n",
        "# - filter_data_by_date\n",
        "# - create_time_series_prediction\n",
        "# - train_prediction_model\n",
        "# - predict_manager_performance\n",
        "# - optimize_lead_assignment\n",
        "# - create_gradio_interface\n",
        "\n",
        "def prepare_time_series_data(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"시계열 모델을 위한 데이터 준비\"\"\"\n",
        "    try:\n",
        "        if '등록일자' not in data.columns:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # 일별 승인율 집계\n",
        "        daily_stats = data.groupby([pd.Grouper(key='등록일자', freq='D'), '담당자명']).agg({\n",
        "            'is_approved': ['count', 'sum', 'mean']\n",
        "        }).reset_index()\n",
        "\n",
        "        daily_stats.columns = ['날짜', '담당자', '리드수', '승인수', '승인율']\n",
        "        daily_stats = daily_stats[daily_stats['리드수'] > 0]  # 리드가 있는 날만\n",
        "\n",
        "        # 시계열 피처 추가\n",
        "        daily_stats['요일'] = daily_stats['날짜'].dt.dayofweek\n",
        "        daily_stats['월'] = daily_stats['날짜'].dt.month\n",
        "        daily_stats['분기'] = daily_stats['날짜'].dt.quarter\n",
        "\n",
        "        return daily_stats\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"시계열 데이터 준비 오류: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def train_lstm_for_manager(manager_data: pd.DataFrame, sequence_length: int = 7) -> Tuple[keras.Model, StandardScaler]:\n",
        "    \"\"\"담당자별 LSTM 모델 학습 (개선된 버전)\"\"\"\n",
        "    if not TENSORFLOW_AVAILABLE:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        # 데이터 준비\n",
        "        data = manager_data.sort_values('날짜')\n",
        "\n",
        "        # 특성과 타겟 분리\n",
        "        features = ['리드수', '승인수', '요일', '월']\n",
        "        X = data[features].values\n",
        "        y = data['승인율'].values\n",
        "\n",
        "        # 정규화\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        # 시퀀스 생성\n",
        "        X_seq, y_seq = [], []\n",
        "        for i in range(len(X_scaled) - sequence_length):\n",
        "            X_seq.append(X_scaled[i:i+sequence_length])\n",
        "            y_seq.append(y[i+sequence_length])\n",
        "\n",
        "        X_seq = np.array(X_seq)\n",
        "        y_seq = np.array(y_seq)\n",
        "\n",
        "        if len(X_seq) < 10:  # 데이터가 너무 적으면 학습 불가\n",
        "            return None, None\n",
        "\n",
        "        # 모델 구축 및 학습\n",
        "        model = build_advanced_lstm_model((sequence_length, len(features)))\n",
        "\n",
        "        # 콜백 설정\n",
        "        early_stop = EarlyStopping(\n",
        "            monitor='loss',\n",
        "            patience=20,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        reduce_lr = ReduceLROnPlateau(\n",
        "            monitor='loss',\n",
        "            factor=0.5,\n",
        "            patience=10,\n",
        "            min_lr=0.0001\n",
        "        )\n",
        "\n",
        "        # 학습\n",
        "        model.fit(\n",
        "            X_seq, y_seq,\n",
        "            epochs=100,\n",
        "            batch_size=16,\n",
        "            verbose=0,\n",
        "            callbacks=[early_stop, reduce_lr],\n",
        "            validation_split=0.2\n",
        "        )\n",
        "\n",
        "        return model, scaler\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"LSTM 학습 오류: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def train_arima_for_manager(manager_data: pd.DataFrame) -> Any:\n",
        "    \"\"\"담당자별 ARIMA 모델 학습\"\"\"\n",
        "    if not STATSMODELS_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # 시계열 데이터 준비\n",
        "        ts_data = manager_data.set_index('날짜')['승인율']\n",
        "        ts_data = ts_data.asfreq('D').ffill()  # 일별 주기로 변환\n",
        "\n",
        "        if len(ts_data) < 30:  # 데이터가 너무 적으면 학습 불가\n",
        "            return None\n",
        "\n",
        "        # Auto ARIMA로 최적 파라미터 찾기\n",
        "        try:\n",
        "            model = pm.auto_arima(\n",
        "                ts_data,\n",
        "                seasonal=True,\n",
        "                m=7,  # 주간 계절성\n",
        "                stepwise=True,\n",
        "                suppress_warnings=True,\n",
        "                error_action='ignore',\n",
        "                max_p=3,\n",
        "                max_q=3,\n",
        "                max_order=5,\n",
        "                trace=False,  # 진행 상황 출력 안함\n",
        "                n_jobs=1  # 단일 스레드 사용\n",
        "            )\n",
        "        except:\n",
        "            # Auto ARIMA 실패 시 단순 ARIMA 시도\n",
        "            from statsmodels.tsa.arima.model import ARIMA\n",
        "            model = ARIMA(ts_data, order=(1,1,1))\n",
        "            model = model.fit()\n",
        "\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ARIMA 학습 오류 ({manager_data['담당자'].iloc[0] if len(manager_data) > 0 else '알 수 없음'}): {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def filter_data_by_date(start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.DataFrame:\n",
        "    \"\"\"지정된 날짜 범위의 데이터만 필터링\"\"\"\n",
        "    try:\n",
        "        if app_state.processed_data is None:\n",
        "            return None\n",
        "\n",
        "        data = app_state.processed_data.copy()\n",
        "\n",
        "        # 날짜 컬럼이 있는 경우만 필터링\n",
        "        if '등록일자' in data.columns:\n",
        "            # 날짜 형식 확인 및 변환\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['등록일자']):\n",
        "                data['등록일자'] = pd.to_datetime(data['등록일자'], errors='coerce')\n",
        "\n",
        "            # 날짜 범위로 필터링\n",
        "            mask = (data['등록일자'] >= start_date) & (data['등록일자'] <= end_date)\n",
        "            filtered_data = data[mask]\n",
        "\n",
        "            print(f\"날짜 필터링: {start_date.date()} ~ {end_date.date()}\")\n",
        "            print(f\"필터링 전: {len(data)}건 → 필터링 후: {len(filtered_data)}건\")\n",
        "\n",
        "            return filtered_data\n",
        "        else:\n",
        "            # 날짜 컬럼이 없으면 전체 데이터 반환\n",
        "            return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"날짜 필터링 오류: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def create_time_series_prediction(start_date: pd.Timestamp, days: int) -> go.Figure:\n",
        "    \"\"\"시계열 예측 그래프 생성 (개선된 버전)\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_model_trained or app_state.manager_performance is None:\n",
        "            return None\n",
        "\n",
        "        # 예측 날짜 범위 생성\n",
        "        date_range = pd.date_range(start=start_date, periods=days, freq='D')\n",
        "\n",
        "        # 담당자별 예측 데이터 생성\n",
        "        predictions_by_date = []\n",
        "\n",
        "        # 각 담당자의 일일 평균 리드 수 계산\n",
        "        manager_daily_leads = {}\n",
        "        for _, manager_row in app_state.manager_performance.head(5).iterrows():\n",
        "            manager = manager_row['담당자명']\n",
        "            daily_avg = manager_row['총_리드수'] / 30\n",
        "            manager_daily_leads[manager] = daily_avg\n",
        "\n",
        "        # 시계열 모델 사용 가능 여부 확인\n",
        "        use_time_series = len(app_state.time_series_models) > 0\n",
        "\n",
        "        for date in date_range:\n",
        "            for _, manager_row in app_state.manager_performance.head(5).iterrows():\n",
        "                manager = manager_row['담당자명']\n",
        "\n",
        "                # 시계열 모델 우선 사용\n",
        "                pred_proba = None\n",
        "                model_used = \"ML\"\n",
        "                confidence = 0.8  # 기본 신뢰도\n",
        "\n",
        "                # Prophet 모델 확인 (최우선)\n",
        "                prophet_key = f'Prophet_{manager}'\n",
        "                if use_time_series and prophet_key in app_state.time_series_models:\n",
        "                    try:\n",
        "                        prophet_model = app_state.time_series_models[prophet_key]['model']\n",
        "                        future = prophet_model.make_future_dataframe(periods=1)\n",
        "                        forecast = prophet_model.predict(future)\n",
        "                        pred_proba = forecast['yhat'].iloc[-1]\n",
        "                        pred_proba = max(0, min(1, pred_proba))\n",
        "                        model_used = \"Prophet\"\n",
        "                        confidence = 0.9\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # LSTM 모델 확인\n",
        "                lstm_key = f'LSTM_{manager}'\n",
        "                if pred_proba is None and use_time_series and lstm_key in app_state.time_series_models:\n",
        "                    try:\n",
        "                        lstm_info = app_state.time_series_models[lstm_key]\n",
        "                        lstm_model = lstm_info['model']\n",
        "                        lstm_scaler = lstm_info['scaler']\n",
        "\n",
        "                        # 최근 7일 데이터 준비 (시뮬레이션)\n",
        "                        recent_features = np.array([\n",
        "                            [manager_daily_leads[manager],\n",
        "                             manager_daily_leads[manager] * manager_row['승인완료율'],\n",
        "                             date.dayofweek,\n",
        "                             date.month]\n",
        "                        ])\n",
        "\n",
        "                        recent_scaled = lstm_scaler.transform(recent_features)\n",
        "                        sequence = np.tile(recent_scaled, (7, 1)).reshape(1, 7, -1)\n",
        "\n",
        "                        pred_proba = lstm_model.predict(sequence)[0, 0]\n",
        "                        model_used = \"LSTM\"\n",
        "                        confidence = 0.85\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # ARIMA 모델 확인\n",
        "                arima_key = f'ARIMA_{manager}'\n",
        "                if pred_proba is None and use_time_series and arima_key in app_state.time_series_models:\n",
        "                    try:\n",
        "                        arima_model = app_state.time_series_models[arima_key]['model']\n",
        "                        # ARIMA 예측 (1일 앞)\n",
        "                        forecast = arima_model.forecast(steps=1)\n",
        "                        pred_proba = forecast[0]\n",
        "                        pred_proba = max(0, min(1, pred_proba))  # 0-1 범위로 제한\n",
        "                        model_used = \"ARIMA\"\n",
        "                        confidence = 0.8\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # 기본 ML 모델 사용\n",
        "                if pred_proba is None:\n",
        "                    # 더 많은 피처 사용\n",
        "                    sample_data = app_state.processed_data[\n",
        "                        app_state.processed_data['담당자명'] == manager\n",
        "                    ].mean(numeric_only=True).to_dict()\n",
        "\n",
        "                    # 날짜 관련 피처 업데이트\n",
        "                    sample_data.update({\n",
        "                        '등록_월': date.month,\n",
        "                        '등록_일': date.day,\n",
        "                        '등록_요일': date.dayofweek,\n",
        "                        '등록_시간': 14,\n",
        "                        '담당자명': manager\n",
        "                    })\n",
        "\n",
        "                    sample_df = pd.DataFrame([sample_data])\n",
        "\n",
        "                    # 인코딩\n",
        "                    for col, encoder in app_state.encoders.items():\n",
        "                        if col in sample_df.columns:\n",
        "                            try:\n",
        "                                sample_df[f'{col}_encoded'] = encoder.transform(sample_df[col])\n",
        "                            except:\n",
        "                                sample_df[f'{col}_encoded'] = 0\n",
        "\n",
        "                    # 피처 선택 및 스케일링\n",
        "                    try:\n",
        "                        X_pred = sample_df[app_state.feature_names].fillna(0)\n",
        "                        if app_state.scaler:\n",
        "                            X_pred = app_state.scaler.transform(X_pred)\n",
        "                        if app_state.feature_selector:\n",
        "                            X_pred = app_state.feature_selector.transform(X_pred)\n",
        "\n",
        "                        pred_proba = app_state.best_model.predict_proba(X_pred)[0, 1]\n",
        "                        confidence = 0.7\n",
        "                    except:\n",
        "                        pred_proba = manager_row['승인완료율']\n",
        "                        confidence = 0.6\n",
        "\n",
        "                # 예상 승인수 계산\n",
        "                daily_leads = manager_daily_leads[manager]\n",
        "                expected_approvals = daily_leads * pred_proba\n",
        "\n",
        "                # 신뢰 구간 계산\n",
        "                std_dev = expected_approvals * 0.1 * (1 - confidence)\n",
        "                lower_bound = max(0, expected_approvals - 1.96 * std_dev)\n",
        "                upper_bound = expected_approvals + 1.96 * std_dev\n",
        "\n",
        "                predictions_by_date.append({\n",
        "                    '날짜': date,\n",
        "                    '담당자': manager,\n",
        "                    '예상_승인수': expected_approvals,\n",
        "                    '예상_승인율': pred_proba,\n",
        "                    '예상_리드수': daily_leads,\n",
        "                    '모델': model_used,\n",
        "                    '신뢰도': confidence,\n",
        "                    '하한': lower_bound,\n",
        "                    '상한': upper_bound\n",
        "                })\n",
        "\n",
        "        # DataFrame 변환\n",
        "        pred_df = pd.DataFrame(predictions_by_date)\n",
        "\n",
        "        # 시계열 그래프 생성\n",
        "        fig = make_subplots(\n",
        "            rows=4, cols=1,\n",
        "            subplot_titles=(\n",
        "                f'{days}일간 담당자별 예상 승인수 (95% 신뢰구간)',\n",
        "                '일별 전체 예상 승인수',\n",
        "                '모델별 예측 기여도',\n",
        "                '예측 신뢰도 분포'\n",
        "            ),\n",
        "            row_heights=[0.4, 0.25, 0.15, 0.2],\n",
        "            vertical_spacing=0.12\n",
        "        )\n",
        "\n",
        "        # 1. 담당자별 예상 승인수 추이 (신뢰구간 포함)\n",
        "        for manager in pred_df['담당자'].unique():\n",
        "            manager_data = pred_df[pred_df['담당자'] == manager]\n",
        "\n",
        "            # 주 추세선\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=manager_data['날짜'],\n",
        "                    y=manager_data['예상_승인수'],\n",
        "                    name=f\"{manager}\",\n",
        "                    mode='lines+markers',\n",
        "                    hovertemplate='%{y:.1f}건<br>승인율: %{customdata:.1%}',\n",
        "                    customdata=manager_data['예상_승인율']\n",
        "                ),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "            # 신뢰구간\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=manager_data['날짜'].tolist() + manager_data['날짜'].tolist()[::-1],\n",
        "                    y=manager_data['상한'].tolist() + manager_data['하한'].tolist()[::-1],\n",
        "                    fill='toself',\n",
        "                    fillcolor=f'rgba(0,100,200,0.1)',\n",
        "                    line=dict(color='rgba(255,255,255,0)'),\n",
        "                    hoverinfo=\"skip\",\n",
        "                    showlegend=False,\n",
        "                    name=f'{manager}_신뢰구간'\n",
        "                ),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "        # 2. 전체 예상 승인수\n",
        "        daily_total = pred_df.groupby('날짜').agg({\n",
        "            '예상_승인수': 'sum',\n",
        "            '하한': 'sum',\n",
        "            '상한': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=daily_total['날짜'],\n",
        "                y=daily_total['예상_승인수'],\n",
        "                name='전체 승인수',\n",
        "                marker_color='lightblue',\n",
        "                hovertemplate='%{y:.0f}건',\n",
        "                error_y=dict(\n",
        "                    type='data',\n",
        "                    symmetric=False,\n",
        "                    array=daily_total['상한'] - daily_total['예상_승인수'],\n",
        "                    arrayminus=daily_total['예상_승인수'] - daily_total['하한']\n",
        "                ),\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # 3. 모델별 사용 비율\n",
        "        model_counts = pred_df['모델'].value_counts()\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=model_counts.index,\n",
        "                y=model_counts.values,\n",
        "                name='모델 사용 횟수',\n",
        "                marker_color=['darkgreen' if 'Prophet' in x else\n",
        "                             'green' if 'LSTM' in x else\n",
        "                             'orange' if 'ARIMA' in x else\n",
        "                             'blue'\n",
        "                             for x in model_counts.index],\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=3, col=1\n",
        "        )\n",
        "\n",
        "        # 4. 신뢰도 분포\n",
        "        confidence_by_model = pred_df.groupby('모델')['신뢰도'].mean().sort_values(ascending=False)\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=confidence_by_model.index,\n",
        "                y=confidence_by_model.values,\n",
        "                name='평균 신뢰도',\n",
        "                marker_color='lightcoral',\n",
        "                text=confidence_by_model.values.round(2),\n",
        "                textposition='outside',\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=4, col=1\n",
        "        )\n",
        "\n",
        "        # 레이아웃 설정\n",
        "        fig.update_layout(\n",
        "            height=1000,\n",
        "            showlegend=True,\n",
        "            legend=dict(\n",
        "                orientation=\"h\",\n",
        "                yanchor=\"bottom\",\n",
        "                y=1.02,\n",
        "                xanchor=\"right\",\n",
        "                x=1\n",
        "            ),\n",
        "            title_text=f\"고급 AI 시계열 예측 결과 (Prophet/LSTM/ARIMA/ML 앙상블)\"\n",
        "        )\n",
        "\n",
        "        # Y축 설정\n",
        "        fig.update_yaxes(title_text=\"예상 승인수 (건)\", row=1, col=1)\n",
        "        fig.update_yaxes(title_text=\"전체 승인수 (건)\", row=2, col=1)\n",
        "        fig.update_yaxes(title_text=\"예측 횟수\", row=3, col=1)\n",
        "        fig.update_yaxes(title_text=\"신뢰도\", row=4, col=1)\n",
        "        fig.update_xaxes(title_text=\"날짜\", row=2, col=1)\n",
        "\n",
        "        # 주말 구분선 추가\n",
        "        for date in date_range:\n",
        "            if date.dayofweek in [5, 6]:\n",
        "                for row in [1, 2]:\n",
        "                    fig.add_vrect(\n",
        "                        x0=date,\n",
        "                        x1=date + pd.Timedelta(days=1),\n",
        "                        fillcolor=\"LightGray\",\n",
        "                        opacity=0.2,\n",
        "                        layer=\"below\",\n",
        "                        line_width=0,\n",
        "                        row=row, col=1\n",
        "                    )\n",
        "\n",
        "        # 평균선 추가\n",
        "        avg_total = daily_total['예상_승인수'].mean()\n",
        "        fig.add_hline(\n",
        "            y=avg_total,\n",
        "            line_dash=\"dash\",\n",
        "            line_color=\"red\",\n",
        "            annotation_text=f\"일 평균: {avg_total:.0f}건\",\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # 예측 요약 정보\n",
        "        total_expected = daily_total['예상_승인수'].sum()\n",
        "        model_usage = \", \".join([f\"{model}: {count}회\" for model, count in model_counts.items()])\n",
        "        avg_confidence = pred_df['신뢰도'].mean()\n",
        "\n",
        "        fig.add_annotation(\n",
        "            text=f\"<b>예측 기간 총 예상 승인수: {total_expected:,.0f}건</b><br>\" +\n",
        "                 f\"모델 사용: {model_usage}<br>\" +\n",
        "                 f\"평균 예측 신뢰도: {avg_confidence:.1%}\",\n",
        "            xref=\"paper\", yref=\"paper\",\n",
        "            x=0.5, y=-0.15,\n",
        "            showarrow=False,\n",
        "            font=dict(size=14)\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"시계열 예측 그래프 생성 오류: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def train_prediction_model() -> Tuple[Dict, str]:\n",
        "    \"\"\"리드 전환 예측 모델 학습 (시계열 모델 포함)\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_preprocessed or app_state.processed_data is None:\n",
        "            return {}, \"❌ 먼저 데이터를 전처리해주세요.\"\n",
        "\n",
        "        # train_prediction_model_with_data 함수 호출\n",
        "        return train_prediction_model_with_data(app_state.processed_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        return {}, f\"❌ 모델 학습 중 오류 발생:\\n{str(e)}\\n\\n상세 오류:\\n{error_details}\"\n",
        "\n",
        "def predict_manager_performance(prediction_date: pd.Timestamp = None, prediction_days: int = 30) -> pd.DataFrame:\n",
        "    \"\"\"담당자별 예상 승인율 예측 (날짜 기반)\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_model_trained or app_state.best_model is None:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        if app_state.manager_performance is None or len(app_state.manager_performance) == 0:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # 예측 날짜 설정\n",
        "        if prediction_date is None:\n",
        "            prediction_date = pd.Timestamp.now()\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        # 각 담당자별로 예측\n",
        "        for _, manager_row in app_state.manager_performance.iterrows():\n",
        "            manager = manager_row['담당자명']\n",
        "\n",
        "            if manager == '미배정':\n",
        "                continue\n",
        "\n",
        "            # 담당자의 평균 특성 사용\n",
        "            manager_data = app_state.processed_data[app_state.processed_data['담당자명'] == manager]\n",
        "\n",
        "            if len(manager_data) == 0:\n",
        "                continue\n",
        "\n",
        "            # 예측 기간 동안의 평균 승인율 계산\n",
        "            daily_predictions = []\n",
        "\n",
        "            for days_ahead in range(0, prediction_days, 7):  # 주 단위로 샘플링\n",
        "                future_date = prediction_date + pd.Timedelta(days=days_ahead)\n",
        "\n",
        "                # 예측 데이터 준비 (더 많은 피처 사용)\n",
        "                sample_data = manager_data.mean(numeric_only=True).to_dict()\n",
        "\n",
        "                # 날짜 관련 피처 업데이트\n",
        "                sample_data.update({\n",
        "                    '등록_월': future_date.month,\n",
        "                    '등록_일': future_date.day,\n",
        "                    '등록_요일': future_date.dayofweek,\n",
        "                    '등록_시간': 14,\n",
        "                    '담당자명': manager\n",
        "                })\n",
        "\n",
        "                # DataFrame으로 변환\n",
        "                sample_df = pd.DataFrame([sample_data])\n",
        "\n",
        "                # 인코딩\n",
        "                for col, encoder in app_state.encoders.items():\n",
        "                    if col in sample_df.columns:\n",
        "                        try:\n",
        "                            sample_df[f'{col}_encoded'] = encoder.transform(sample_df[col])\n",
        "                        except:\n",
        "                            sample_df[f'{col}_encoded'] = 0\n",
        "\n",
        "                # 피처 선택 및 스케일링\n",
        "                try:\n",
        "                    X_pred = sample_df[app_state.feature_names].fillna(0)\n",
        "                    if app_state.scaler:\n",
        "                        X_pred = app_state.scaler.transform(X_pred)\n",
        "                    if app_state.feature_selector:\n",
        "                        X_pred = app_state.feature_selector.transform(X_pred)\n",
        "\n",
        "                    pred_proba = app_state.best_model.predict_proba(X_pred)[0, 1]\n",
        "                    daily_predictions.append(pred_proba)\n",
        "                except:\n",
        "                    daily_predictions.append(0.5)\n",
        "\n",
        "            # 평균 예측 승인율 계산\n",
        "            avg_pred_proba = np.mean(daily_predictions) if daily_predictions else 0.5\n",
        "\n",
        "            # 현재 승인건수 계산\n",
        "            current_approval_count = int(manager_row['승인완료수'])\n",
        "            total_leads = int(manager_row['총_리드수'])\n",
        "\n",
        "            # 예측 기간 동안의 예상 리드수 (일일 평균 * 예측 일수)\n",
        "            daily_avg_leads = total_leads / 30  # 한 달 기준\n",
        "            expected_leads = int(daily_avg_leads * prediction_days)\n",
        "\n",
        "            # 예측 승인건수 계산\n",
        "            predicted_approval_count = int(avg_pred_proba * expected_leads)\n",
        "\n",
        "            predictions.append({\n",
        "                '담당자': manager,\n",
        "                '총리드수': total_leads,\n",
        "                '평균접촉횟수': round(manager_row['평균_접촉횟수'], 1),\n",
        "                '현재 승인건': current_approval_count,\n",
        "                '현재 승인율': f\"{manager_row['승인완료율']:.1%}\",\n",
        "                '예측 승인건': predicted_approval_count,\n",
        "                '예측 승인율': f\"{avg_pred_proba:.1%}\",\n",
        "                '예측 정확도': f\"{(1 - abs(avg_pred_proba - manager_row['승인완료율'])):.1%}\"\n",
        "            })\n",
        "\n",
        "        if len(predictions) == 0:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # 결과 정리\n",
        "        result_df = pd.DataFrame(predictions)\n",
        "\n",
        "        # 예측 승인율 기준으로 정렬\n",
        "        result_df['sort_key'] = result_df['예측 승인율'].str.rstrip('%').astype(float)\n",
        "        result_df = result_df.sort_values('sort_key', ascending=False).drop('sort_key', axis=1)\n",
        "\n",
        "        # 예측 기간 정보 추가 (첫 행에만 표시)\n",
        "        if len(result_df) > 0:\n",
        "            result_df.loc[result_df.index[0], '예측기간'] = f\"{prediction_date.strftime('%Y-%m-%d')} ~ {(prediction_date + pd.Timedelta(days=prediction_days)).strftime('%Y-%m-%d')}\"\n",
        "            # 나머지 행은 빈 문자열\n",
        "            result_df.loc[result_df.index[1:], '예측기간'] = ''\n",
        "\n",
        "        return result_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"예측 중 오류: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ================================================================================\n",
        "# 11. 리드 배정 최적화 (개선된 버전)\n",
        "# ================================================================================\n",
        "\n",
        "def optimize_lead_assignment(channel, gender, type_, memo_len, marketing, email, sms) -> Tuple[str, str, go.Figure]:\n",
        "    \"\"\"신규 리드에 대한 최적 담당자 추천 (개선된 버전)\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_model_trained or app_state.best_model is None:\n",
        "            return \"\", \"❌ 먼저 모델을 학습시켜주세요.\", None\n",
        "\n",
        "        if app_state.manager_performance is None or len(app_state.manager_performance) == 0:\n",
        "            return \"\", \"❌ 담당자 데이터가 없습니다.\", None\n",
        "\n",
        "        # 신규 리드 정보 (확장된 피처)\n",
        "        current_datetime = datetime.now()\n",
        "\n",
        "        # 기본 피처\n",
        "        new_lead = {\n",
        "            '판매처': channel,\n",
        "            '성별': gender,\n",
        "            '유형': type_,\n",
        "            '메모_길이': memo_len,\n",
        "            '메모_단어수': memo_len // 5,\n",
        "            '마케팅활용동의_num': int(marketing),\n",
        "            '이메일수신동의_num': int(email),\n",
        "            '문자수신동의_num': int(sms),\n",
        "            '접촉횟수': 0,\n",
        "            '등록_월': current_datetime.month,\n",
        "            '등록_일': current_datetime.day,\n",
        "            '등록_요일': current_datetime.weekday(),\n",
        "            '등록_시간': current_datetime.hour,\n",
        "            '동의점수': int(marketing) + int(email) + int(sms),\n",
        "            '완전동의': int(marketing and email and sms),\n",
        "            '주말여부': int(current_datetime.weekday() >= 5),\n",
        "            '월초': int(current_datetime.day <= 10),\n",
        "            '월말': int(current_datetime.day >= 21),\n",
        "            '분기': (current_datetime.month - 1) // 3 + 1\n",
        "        }\n",
        "\n",
        "        # 메모 품질 점수 계산\n",
        "        new_lead['메모_품질점수'] = (\n",
        "            new_lead['메모_길이'] / 500 * 0.3 +  # 최대 500자 기준\n",
        "            new_lead['메모_단어수'] / 100 * 0.3 +  # 최대 100단어 기준\n",
        "            0.4  # 키워드 포함 여부 (가정)\n",
        "        )\n",
        "\n",
        "        # 고객 프로파일\n",
        "        new_lead['고객프로파일'] = f\"{gender}_{type_}\"\n",
        "\n",
        "        # 각 담당자별 예상 승인확률 계산\n",
        "        predictions = []\n",
        "\n",
        "        for _, manager_row in app_state.manager_performance.head(10).iterrows():\n",
        "            manager = manager_row['담당자명']\n",
        "\n",
        "            if manager == '미배정':\n",
        "                continue\n",
        "\n",
        "            # 예측 데이터 준비\n",
        "            pred_data = new_lead.copy()\n",
        "            pred_data['담당자명'] = manager\n",
        "\n",
        "            # 담당자 관련 피처 추가\n",
        "            pred_data['담당자_승인율'] = manager_row['승인완료율']\n",
        "            pred_data['담당자_총승인수'] = manager_row['승인완료수']\n",
        "            pred_data['담당자_총리드수'] = manager_row['총_리드수']\n",
        "            pred_data['담당자_평균접촉'] = manager_row['평균_접촉횟수']\n",
        "            pred_data['담당자_경험지수'] = manager_row['총_리드수'] / app_state.manager_performance['총_리드수'].max()\n",
        "            pred_data['담당자_효율성'] = manager_row['승인완료율'] / (manager_row['평균_접촉횟수'] + 1)\n",
        "\n",
        "            # 판매처 관련 피처 (전체 평균 사용)\n",
        "            channel_stats = app_state.processed_data.groupby('판매처')['is_approved'].mean()\n",
        "            pred_data['판매처_평균승인율'] = channel_stats.get(channel, channel_stats.mean())\n",
        "\n",
        "            # 상호작용 피처\n",
        "            pred_data['담당자X판매처_시너지'] = pred_data['담당자_승인율'] * pred_data['판매처_평균승인율']\n",
        "\n",
        "            # DataFrame으로 변환\n",
        "            pred_df = pd.DataFrame([pred_data])\n",
        "\n",
        "            # 인코딩\n",
        "            for col, encoder in app_state.encoders.items():\n",
        "                if col in pred_df.columns:\n",
        "                    try:\n",
        "                        pred_df[f'{col}_encoded'] = encoder.transform(pred_df[col])\n",
        "                    except:\n",
        "                        pred_df[f'{col}_encoded'] = 0\n",
        "\n",
        "            # 예측\n",
        "            try:\n",
        "                X_pred = pred_df[app_state.feature_names].fillna(0)\n",
        "\n",
        "                # 스케일링\n",
        "                if app_state.scaler:\n",
        "                    X_pred = app_state.scaler.transform(X_pred)\n",
        "\n",
        "                # 피처 선택\n",
        "                if app_state.feature_selector:\n",
        "                    X_pred = app_state.feature_selector.transform(X_pred)\n",
        "\n",
        "                # 예측\n",
        "                if app_state.ensemble_model:\n",
        "                    # 앙상블 모델 우선 사용\n",
        "                    pred_proba = app_state.ensemble_model.predict_proba(X_pred)[0, 1]\n",
        "                else:\n",
        "                    pred_proba = app_state.best_model.predict_proba(X_pred)[0, 1]\n",
        "\n",
        "            except:\n",
        "                pred_proba = 0.5\n",
        "\n",
        "            # 워크로드 고려 (현재 리드수가 많은 담당자는 페널티)\n",
        "            workload_penalty = 1 - (manager_row['총_리드수'] / app_state.manager_performance['총_리드수'].max()) * 0.1\n",
        "            adjusted_proba = pred_proba * workload_penalty\n",
        "\n",
        "            predictions.append({\n",
        "                '담당자': manager,\n",
        "                '예상_승인확률': pred_proba,\n",
        "                '조정_승인확률': adjusted_proba,\n",
        "                '과거_승인율': manager_row['승인완료율'],\n",
        "                '현재_리드수': manager_row['총_리드수'],\n",
        "                '평균_접촉횟수': manager_row['평균_접촉횟수'],\n",
        "                '담당자_효율성': pred_data['담당자_효율성'],\n",
        "                '종합점수': adjusted_proba * 0.6 + manager_row['승인완료율'] * 0.3 + pred_data['담당자_효율성'] * 0.1\n",
        "            })\n",
        "\n",
        "        if len(predictions) == 0:\n",
        "            return \"\", \"❌ 예측할 수 있는 담당자가 없습니다.\", None\n",
        "\n",
        "        # 결과 정렬\n",
        "        pred_df = pd.DataFrame(predictions).sort_values('종합점수', ascending=False)\n",
        "\n",
        "        # 최적 담당자 선택\n",
        "        best_manager = pred_df.iloc[0]['담당자']\n",
        "        best_prob = pred_df.iloc[0]['예상_승인확률']\n",
        "        best_adjusted_prob = pred_df.iloc[0]['조정_승인확률']\n",
        "\n",
        "        # 시각화 (개선된 버전)\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=(\n",
        "                '담당자별 예상 승인확률',\n",
        "                '종합 점수 (워크로드 고려)',\n",
        "                '담당자 효율성 지표',\n",
        "                '추천 근거 분석'\n",
        "            ),\n",
        "            specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "                   [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
        "        )\n",
        "\n",
        "        # 상위 5명만 표시\n",
        "        top_5 = pred_df.head(5)\n",
        "\n",
        "        # 1. 예상 승인확률\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=top_5['담당자'],\n",
        "                y=top_5['예상_승인확률'],\n",
        "                name='예상 승인확률',\n",
        "                marker_color='lightblue',\n",
        "                text=top_5['예상_승인확률'].apply(lambda x: f'{x:.1%}'),\n",
        "                textposition='outside'\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # 과거 승인율 추가\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=top_5['담당자'],\n",
        "                y=top_5['과거_승인율'],\n",
        "                name='과거 평균',\n",
        "                marker_color='lightgreen',\n",
        "                text=top_5['과거_승인율'].apply(lambda x: f'{x:.1%}'),\n",
        "                textposition='outside'\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # 2. 종합 점수\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=top_5['담당자'],\n",
        "                y=top_5['종합점수'],\n",
        "                name='종합 점수',\n",
        "                marker_color='orange',\n",
        "                text=top_5['종합점수'].apply(lambda x: f'{x:.3f}'),\n",
        "                textposition='outside',\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "        # 3. 효율성 vs 워크로드\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=top_5['현재_리드수'],\n",
        "                y=top_5['담당자_효율성'],\n",
        "                mode='markers+text',\n",
        "                marker=dict(\n",
        "                    size=top_5['예상_승인확률'] * 50,\n",
        "                    color=top_5['종합점수'],\n",
        "                    colorscale='RdYlGn',\n",
        "                    showscale=True\n",
        "                ),\n",
        "                text=top_5['담당자'],\n",
        "                textposition='top center',\n",
        "                name='효율성',\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # 4. 추천 근거 요약\n",
        "        factors = ['예상 승인률', '과거 성과', '효율성', '워크로드']\n",
        "        best_factors = [\n",
        "            pred_df.iloc[0]['예상_승인확률'],\n",
        "            pred_df.iloc[0]['과거_승인율'],\n",
        "            pred_df.iloc[0]['담당자_효율성'],\n",
        "            1 - pred_df.iloc[0]['현재_리드수'] / pred_df['현재_리드수'].max()\n",
        "        ]\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=factors,\n",
        "                y=best_factors,\n",
        "                name='평가 지표',\n",
        "                marker_color=['blue', 'green', 'orange', 'red'],\n",
        "                text=[f'{v:.2f}' for v in best_factors],\n",
        "                textposition='outside',\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=2, col=2\n",
        "        )\n",
        "\n",
        "        # 레이아웃 설정\n",
        "        fig.update_layout(\n",
        "            height=800,\n",
        "            showlegend=True,\n",
        "            title_text=f'AI 기반 최적 담당자 추천: {best_manager}'\n",
        "        )\n",
        "\n",
        "        fig.update_xaxes(title_text=\"담당자\", row=1, col=1)\n",
        "        fig.update_xaxes(title_text=\"담당자\", row=1, col=2)\n",
        "        fig.update_xaxes(title_text=\"현재 리드수\", row=2, col=1)\n",
        "        fig.update_xaxes(title_text=\"평가 요소\", row=2, col=2)\n",
        "\n",
        "        fig.update_yaxes(title_text=\"확률\", row=1, col=1)\n",
        "        fig.update_yaxes(title_text=\"점수\", row=1, col=2)\n",
        "        fig.update_yaxes(title_text=\"효율성 지수\", row=2, col=1)\n",
        "        fig.update_yaxes(title_text=\"지표값\", row=2, col=2)\n",
        "\n",
        "        # 추천 이유 생성 (더 상세한 버전)\n",
        "        recommendation_text = f\"\"\"🎯 최적 담당자 추천: {best_manager}\n",
        "\n",
        "📊 추천 근거:\n",
        "- 예상 승인 확률: {best_prob:.1%} (조정 후: {best_adjusted_prob:.1%})\n",
        "- 과거 평균 승인율: {pred_df.iloc[0]['과거_승인율']:.1%}\n",
        "- 현재 처리 중인 리드: {int(pred_df.iloc[0]['현재_리드수'])}건\n",
        "- 평균 접촉 횟수: {pred_df.iloc[0]['평균_접촉횟수']:.1f}회\n",
        "- 담당자 효율성: {pred_df.iloc[0]['담당자_효율성']:.3f}\n",
        "\n",
        "💡 추천 이유:\n",
        "1. 이 담당자는 유사한 프로파일의 리드에서 높은 성과를 보였습니다.\n",
        "2. 현재 워크로드가 적절한 수준으로 추가 리드 처리가 가능합니다.\n",
        "3. 효율성 지표가 우수하여 적은 접촉으로도 높은 전환율을 달성합니다.\n",
        "4. AI 모델이 이 리드의 특성과 담당자의 강점이 매치된다고 예측합니다.\n",
        "\n",
        "📈 대안 담당자:\n",
        "\"\"\"\n",
        "\n",
        "        for i in range(1, min(3, len(pred_df))):\n",
        "            alt = pred_df.iloc[i]\n",
        "            recommendation_text += f\"\\n{i+1}. {alt['담당자']} (예상: {alt['예상_승인확률']:.1%}, 종합: {alt['종합점수']:.3f})\"\n",
        "\n",
        "        # 리드 특성 요약\n",
        "        recommendation_text += f\"\"\"\n",
        "\n",
        "📋 리드 특성 요약:\n",
        "- 판매처: {channel}\n",
        "- 고객 프로파일: {gender} / {type_}\n",
        "- 동의 점수: {new_lead['동의점수']}/3\n",
        "- 예상 메모 품질: {new_lead['메모_품질점수']:.2f}\n",
        "- 시간대 특성: {'주말' if new_lead['주말여부'] else '평일'}, {current_datetime.hour}시\n",
        "\"\"\"\n",
        "\n",
        "        return best_manager, recommendation_text, fig\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"\", f\"❌ 예측 중 오류 발생: {str(e)}\", None\n",
        "\n",
        "# ================================================================================\n",
        "# 12. Gradio 인터페이스 구성 (기존 유지)\n",
        "# ================================================================================\n",
        "\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Gradio 인터페이스 생성\"\"\"\n",
        "\n",
        "    # CSS 스타일\n",
        "    custom_css = \"\"\"\n",
        "    .gradio-container {\n",
        "        font-family: 'Noto Sans KR', -apple-system, BlinkMacSystemFont, sans-serif !important;\n",
        "    }\n",
        "    .gr-button-primary {\n",
        "        background-color: #2563eb !important;\n",
        "        color: white !important;\n",
        "    }\n",
        "    .gr-button-primary:hover {\n",
        "        background-color: #1d4ed8 !important;\n",
        "    }\n",
        "    .error-text {\n",
        "        color: #dc2626 !important;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .success-text {\n",
        "        color: #16a34a !important;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"담당자별 리드 전환 예측 시스템\", theme=gr.themes.Soft(), css=custom_css) as app:\n",
        "\n",
        "        # 헤더\n",
        "        gr.Markdown(\"\"\"\n",
        "        # 🎯 담당자별 리드 전환 예측 시스템\n",
        "\n",
        "        ### 📊 AI 기반 리드 배정 최적화 및 성과 예측 플랫폼\n",
        "\n",
        "        ---\n",
        "        \"\"\")\n",
        "\n",
        "        # 메인 탭\n",
        "        with gr.Tabs():\n",
        "\n",
        "            # 1. 데이터 업로드 및 전처리\n",
        "            with gr.Tab(\"📁 데이터 관리\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        file_input = gr.File(\n",
        "                            label=\"엑셀 파일 업로드 (tst_atalk.xlsx)\",\n",
        "                            file_types=[\".xlsx\", \".xls\", \".csv\"],\n",
        "                            type=\"filepath\"\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            upload_btn = gr.Button(\"📤 데이터 로드\", variant=\"primary\")\n",
        "                            sample_btn = gr.Button(\"🎲 샘플 데이터 사용\", variant=\"secondary\")\n",
        "\n",
        "                        preprocess_btn = gr.Button(\"🔧 전처리 실행\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        data_info = gr.Textbox(\n",
        "                            label=\"데이터 분석 결과\",\n",
        "                            lines=20,\n",
        "                            interactive=False\n",
        "                        )\n",
        "\n",
        "                # 이벤트 핸들러\n",
        "                upload_btn.click(\n",
        "                    fn=load_data,\n",
        "                    inputs=[file_input],\n",
        "                    outputs=[gr.State(), data_info]\n",
        "                )\n",
        "\n",
        "                sample_btn.click(\n",
        "                    fn=lambda: load_data(None),\n",
        "                    outputs=[gr.State(), data_info]\n",
        "                )\n",
        "\n",
        "                preprocess_btn.click(\n",
        "                    fn=preprocess_for_prediction,\n",
        "                    outputs=[gr.State(), data_info]\n",
        "                )\n",
        "\n",
        "            # 2. 담당자 성과 분석\n",
        "            with gr.Tab(\"👥 담당자 성과 분석\"):\n",
        "                analyze_btn = gr.Button(\"📊 성과 분석 실행\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                status_text = gr.Textbox(label=\"상태\", interactive=False, visible=True)\n",
        "\n",
        "                with gr.Row():\n",
        "                    perf_plot1 = gr.Plot(label=\"성과 매트릭스\")\n",
        "                    perf_plot2 = gr.Plot(label=\"승인율 순위\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    perf_plot3 = gr.Plot(label=\"일별 추이\")\n",
        "                    perf_plot4 = gr.Plot(label=\"접촉 효율성\")\n",
        "\n",
        "                def analyze_performance():\n",
        "                    plots, message = create_manager_performance_dashboard()\n",
        "                    if len(plots) >= 4:\n",
        "                        return message, plots[0], plots[1], plots[2], plots[3]\n",
        "                    elif len(plots) == 3:\n",
        "                        return message, plots[0], plots[1], plots[2], None\n",
        "                    elif len(plots) == 2:\n",
        "                        return message, plots[0], plots[1], None, None\n",
        "                    elif len(plots) == 1:\n",
        "                        return message, plots[0], None, None, None\n",
        "                    else:\n",
        "                        return message, None, None, None, None\n",
        "\n",
        "                analyze_btn.click(\n",
        "                    fn=analyze_performance,\n",
        "                    outputs=[status_text, perf_plot1, perf_plot2, perf_plot3, perf_plot4]\n",
        "                )\n",
        "\n",
        "            # 3. 예측 모델 학습\n",
        "            with gr.Tab(\"🤖 AI 모델 학습\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.Markdown(\"### 📅 학습 기간 설정\")\n",
        "\n",
        "                        # 날짜 선택 컴포넌트\n",
        "                        with gr.Row():\n",
        "                            train_start_date = gr.Textbox(\n",
        "                                label=\"학습 시작일\",\n",
        "                                value=\"2024-01-01\",\n",
        "                                info=\"YYYY-MM-DD 형식\"\n",
        "                            )\n",
        "                            train_end_date = gr.Textbox(\n",
        "                                label=\"학습 종료일\",\n",
        "                                value=datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "                                info=\"YYYY-MM-DD 형식\"\n",
        "                            )\n",
        "\n",
        "                        gr.Markdown(\"### 🔮 예측 기간 설정\")\n",
        "\n",
        "                        with gr.Row():\n",
        "                            predict_start_date = gr.Textbox(\n",
        "                                label=\"예측 시작일\",\n",
        "                                value=datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "                                info=\"YYYY-MM-DD 형식\"\n",
        "                            )\n",
        "                            predict_days = gr.Slider(\n",
        "                                label=\"예측 일수\",\n",
        "                                minimum=1,\n",
        "                                maximum=90,\n",
        "                                value=30,\n",
        "                                step=1,\n",
        "                                info=\"며칠 후까지 예측할지 설정\"\n",
        "                            )\n",
        "\n",
        "                        train_btn = gr.Button(\"🚀 모델 학습 및 예측 시작\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                        model_info = gr.Textbox(\n",
        "                            label=\"모델 학습 결과\",\n",
        "                            lines=15,\n",
        "                            interactive=False\n",
        "                        )\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        with gr.Tabs():\n",
        "                            with gr.Tab(\"📈 담당자별 예상 성과\"):\n",
        "                                prediction_table = gr.Dataframe(\n",
        "                                    label=\"담당자별 예측 결과\",\n",
        "                                    interactive=False\n",
        "                                )\n",
        "\n",
        "                            with gr.Tab(\"📊 시계열 예측\"):\n",
        "                                time_series_plot = gr.Plot(\n",
        "                                    label=\"기간별 예측 추이\"\n",
        "                                )\n",
        "\n",
        "                def train_and_predict_with_dates(start_date, end_date, pred_start, pred_days):\n",
        "                    try:\n",
        "                        # 날짜 형식 검증\n",
        "                        start = pd.to_datetime(start_date)\n",
        "                        end = pd.to_datetime(end_date)\n",
        "                        pred_start_dt = pd.to_datetime(pred_start)\n",
        "\n",
        "                        if start > end:\n",
        "                            return \"❌ 시작일이 종료일보다 늦습니다.\", pd.DataFrame(), None\n",
        "\n",
        "                        # 지정된 기간의 데이터만 필터링\n",
        "                        filtered_data = filter_data_by_date(start, end)\n",
        "\n",
        "                        if filtered_data is None or len(filtered_data) == 0:\n",
        "                            return \"❌ 선택한 기간에 데이터가 없습니다.\", pd.DataFrame(), None\n",
        "\n",
        "                        # 모델 학습\n",
        "                        results, text = train_prediction_model_with_data(filtered_data)\n",
        "\n",
        "                        if app_state.is_model_trained:\n",
        "                            # 지정된 날짜 기준으로 성과 예측\n",
        "                            pred_df = predict_manager_performance(pred_start_dt, pred_days)\n",
        "\n",
        "                            # 시계열 예측\n",
        "                            time_series_fig = create_time_series_prediction(pred_start_dt, pred_days)\n",
        "\n",
        "                            # 학습 정보 추가\n",
        "                            text += f\"\\n\\n📅 학습 기간: {start.date()} ~ {end.date()}\"\n",
        "                            text += f\"\\n🔮 예측 기간: {pred_start_dt.date()} ~ {(pred_start_dt + pd.Timedelta(days=pred_days)).date()}\"\n",
        "                            text += f\"\\n📊 예측 일수: {pred_days}일\"\n",
        "\n",
        "                            return text, pred_df, time_series_fig\n",
        "\n",
        "                        return text, pd.DataFrame(), None\n",
        "\n",
        "                    except Exception as e:\n",
        "                        return f\"❌ 오류 발생: {str(e)}\", pd.DataFrame(), None\n",
        "\n",
        "                train_btn.click(\n",
        "                    fn=train_and_predict_with_dates,\n",
        "                    inputs=[train_start_date, train_end_date, predict_start_date, predict_days],\n",
        "                    outputs=[model_info, prediction_table, time_series_plot]\n",
        "                )\n",
        "\n",
        "            # 4. 리드 배정 최적화\n",
        "            with gr.Tab(\"🎯 리드 배정 최적화\"):\n",
        "                gr.Markdown(\"### 신규 리드 정보 입력\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        channel_input = gr.Dropdown(\n",
        "                            label=\"판매처\",\n",
        "                            choices=['G마켓', 'CJ몰', '11번가', 'SSG', '옥션', '네이버', '쿠팡', '기타'],\n",
        "                            value=\"G마켓\"\n",
        "                        )\n",
        "                        gender_input = gr.Radio(\n",
        "                            label=\"성별\",\n",
        "                            choices=[\"남자\", \"여자\"],\n",
        "                            value=\"여자\"\n",
        "                        )\n",
        "                        type_input = gr.Radio(\n",
        "                            label=\"유형\",\n",
        "                            choices=[\"개인\", \"법인\"],\n",
        "                            value=\"개인\"\n",
        "                        )\n",
        "                        memo_length = gr.Slider(\n",
        "                            label=\"메모 길이\",\n",
        "                            minimum=0,\n",
        "                            maximum=500,\n",
        "                            value=100,\n",
        "                            step=10\n",
        "                        )\n",
        "                        marketing_consent = gr.Checkbox(label=\"마케팅 동의\", value=True)\n",
        "                        email_consent = gr.Checkbox(label=\"이메일 수신 동의\", value=True)\n",
        "                        sms_consent = gr.Checkbox(label=\"문자 수신 동의\", value=True)\n",
        "\n",
        "                        assign_btn = gr.Button(\"🎯 최적 담당자 찾기\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                    with gr.Column():\n",
        "                        best_manager = gr.Textbox(\n",
        "                            label=\"추천 담당자\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "                        recommendation = gr.Textbox(\n",
        "                            label=\"추천 상세 정보\",\n",
        "                            lines=15,\n",
        "                            interactive=False\n",
        "                        )\n",
        "                        comparison_plot = gr.Plot(label=\"담당자별 예상 성과\")\n",
        "\n",
        "                assign_btn.click(\n",
        "                    fn=optimize_lead_assignment,\n",
        "                    inputs=[channel_input, gender_input, type_input, memo_length,\n",
        "                           marketing_consent, email_consent, sms_consent],\n",
        "                    outputs=[best_manager, recommendation, comparison_plot]\n",
        "                )\n",
        "\n",
        "        # 푸터\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "\n",
        "        ### 💡 사용 가이드\n",
        "\n",
        "        1. **데이터 업로드**: tst_atalk.xlsx 파일을 업로드하거나 샘플 데이터를 사용합니다.\n",
        "        2. **전처리 실행**: 데이터를 분석에 적합한 형태로 변환합니다.\n",
        "        3. **성과 분석**: 담당자별 현재 성과를 다각도로 분석합니다.\n",
        "        4. **모델 학습**: AI 모델을 학습시켜 담당자별 예상 성과를 예측합니다.\n",
        "        5. **리드 배정**: 신규 리드에 대해 최적의 담당자를 추천받습니다.\n",
        "\n",
        "        ---\n",
        "\n",
        "        © 2024 Lead Conversion Prediction System. All rights reserved.\n",
        "        \"\"\")\n",
        "\n",
        "    return app\n",
        "\n",
        "# ================================================================================\n",
        "# 13. 메인 실행\n",
        "# ================================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"🚀 담당자별 리드 전환 예측 시스템 시작 중...\")\n",
        "    print(\"📌 샘플 데이터로 빠르게 시작하려면 [샘플 데이터 사용] 버튼을 클릭하세요!\")\n",
        "\n",
        "    # 사용 가능한 모델 확인\n",
        "    print(\"\\n📊 사용 가능한 모델:\")\n",
        "    print(f\"- 기본 ML 모델: ✅ (Random Forest, XGBoost, LightGBM 등)\")\n",
        "    print(f\"- LSTM (시계열): {'✅' if TENSORFLOW_AVAILABLE else '❌ (TensorFlow 필요)'}\")\n",
        "    print(f\"- ARIMA (시계열): {'✅' if STATSMODELS_AVAILABLE else '❌ (statsmodels/pmdarima 필요)'}\")\n",
        "    print(f\"- Prophet (시계열): {'✅' if PROPHET_AVAILABLE else '❌ (prophet 필요)'}\")\n",
        "    print(f\"- CatBoost: {'✅' if CATBOOST_AVAILABLE else '❌ (catboost 필요)'}\")\n",
        "    print(f\"- 하이퍼파라미터 최적화: {'✅' if OPTUNA_AVAILABLE else '❌ (optuna 필요)'}\")\n",
        "    print(f\"- 클래스 불균형 처리: {'✅' if IMBALANCED_AVAILABLE else '❌ (imbalanced-learn 필요)'}\")\n",
        "\n",
        "    print(\"\\n💡 시계열 모델이 없어도 기본 ML 모델만으로 충분한 성능을 얻을 수 있습니다.\")\n",
        "\n",
        "    # Gradio 앱 생성 및 실행\n",
        "    app = create_gradio_interface()\n",
        "\n",
        "    # 실행\n",
        "    app.launch(\n",
        "        share=True,  # 공유 링크 생성\n",
        "        debug=False,\n",
        "        quiet=False\n",
        "    )\n",
        "\n",
        "    print(\"✅ 시스템이 성공적으로 시작되었습니다!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KqBIyIvlp1F6",
        "outputId": "c0d13567-cc66-4dd3-a463-9a12427f42d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📦 필요한 패키지 설치 중...\n",
            "✅ gradio>=5.0.0 설치 완료\n",
            "✅ pandas 설치 완료\n",
            "✅ numpy 설치 완료\n",
            "✅ scikit-learn>=1.0.0 설치 완료\n",
            "✅ lightgbm 설치 완료\n",
            "✅ xgboost 설치 완료\n",
            "✅ catboost 설치 완료\n",
            "✅ optuna>=3.0.0 설치 완료\n",
            "✅ plotly 설치 완료\n",
            "✅ seaborn 설치 완료\n",
            "✅ matplotlib 설치 완료\n",
            "✅ openpyxl 설치 완료\n",
            "✅ japanize-matplotlib 설치 완료\n",
            "✅ tensorflow 설치 완료\n",
            "✅ imbalanced-learn>=0.9.0 설치 완료\n",
            "✅ feature-engine 설치 완료\n",
            "\n",
            "📈 시계열 분석 패키지 설치 중...\n",
            "✅ statsmodels 설치 완료\n",
            "✅ pmdarima 설치 완료\n",
            "✅ prophet 설치 완료\n",
            "\n",
            "🎨 한글 폰트 설치 중...\n",
            "\n",
            "✅ 패키지 설치 완료!\n",
            "💡 일부 시계열 패키지가 설치되지 않아도 기본 ML 모델은 정상 작동합니다.\n",
            "✅ TensorFlow 로드 성공\n",
            "⚠️ Statsmodels 로드 중 예상치 못한 오류: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
            "✅ Prophet 로드 성공\n",
            "🚀 담당자별 리드 전환 예측 시스템 시작 중...\n",
            "📌 샘플 데이터로 빠르게 시작하려면 [샘플 데이터 사용] 버튼을 클릭하세요!\n",
            "\n",
            "📊 사용 가능한 모델:\n",
            "- 기본 ML 모델: ✅ (Random Forest, XGBoost, LightGBM 등)\n",
            "- LSTM (시계열): ✅\n",
            "- ARIMA (시계열): ❌ (statsmodels/pmdarima 필요)\n",
            "- Prophet (시계열): ✅\n",
            "- CatBoost: ✅\n",
            "- 하이퍼파라미터 최적화: ✅\n",
            "- 클래스 불균형 처리: ✅\n",
            "\n",
            "💡 시계열 모델이 없어도 기본 ML 모델만으로 충분한 성능을 얻을 수 있습니다.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4867b283602f7d2d86.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4867b283602f7d2d86.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ 시스템이 성공적으로 시작되었습니다!\n"
          ]
        }
      ]
    }
  ]
}