{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# ================================================================================\n",
        "# ë‹´ë‹¹ìë³„ ë¦¬ë“œ ì „í™˜ ì˜ˆì¸¡ íŠ¹í™” ëŒ€ì‹œë³´ë“œ - AI/ML ì„±ëŠ¥ ê°œì„  ë²„ì „\n",
        "# í”Œë«í¼: Google Colab / Gradio 5.0+\n",
        "# ëª©í‘œ: ê³ ì„±ëŠ¥ ë‹´ë‹¹ìë³„ ë¦¬ë“œ ì „í™˜ìœ¨ ì˜ˆì¸¡ ë° ìµœì  ë°°ì • ì‹œìŠ¤í…œ\n",
        "# ================================================================================\n",
        "\n",
        "# 1. Google Colab í™˜ê²½ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ìë™ ì„¤ì¹˜\n",
        "import subprocess\n",
        "import sys\n",
        "import os\n",
        "\n",
        "def install_packages():\n",
        "    \"\"\"í•„ìš”í•œ íŒ¨í‚¤ì§€ ìë™ ì„¤ì¹˜\"\"\"\n",
        "    packages = [\n",
        "        'gradio>=5.0.0',\n",
        "        'pandas',\n",
        "        'numpy',\n",
        "        'scikit-learn>=1.0.0',  # ë²„ì „ ëª…ì‹œ\n",
        "        'lightgbm',\n",
        "        'xgboost',\n",
        "        'catboost',  # ì¶”ê°€: ë” ê°•ë ¥í•œ ê·¸ë˜ë””ì–¸íŠ¸ ë¶€ìŠ¤íŒ…\n",
        "        'optuna>=3.0.0',  # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ë²„ì „ ëª…ì‹œ)\n",
        "        'plotly',\n",
        "        'seaborn',\n",
        "        'matplotlib',\n",
        "        'openpyxl',\n",
        "        'japanize-matplotlib',\n",
        "        'tensorflow',\n",
        "        'imbalanced-learn>=0.9.0',  # ì¶”ê°€: í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (ë²„ì „ ëª…ì‹œ)\n",
        "        'feature-engine'  # ì¶”ê°€: ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\n",
        "    ]\n",
        "\n",
        "    print(\"ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n",
        "\n",
        "    # ë¨¼ì € pip ì—…ê·¸ë ˆì´ë“œ\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '--upgrade', 'pip'])\n",
        "    except:\n",
        "        pass\n",
        "\n",
        "    # ê¸°ë³¸ íŒ¨í‚¤ì§€ ì„¤ì¹˜\n",
        "    for package in packages:\n",
        "        try:\n",
        "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', package])\n",
        "            print(f\"âœ… {package} ì„¤ì¹˜ ì™„ë£Œ\")\n",
        "        except:\n",
        "            print(f\"âš ï¸ {package} ì„¤ì¹˜ ì‹¤íŒ¨, ê³„ì† ì§„í–‰...\")\n",
        "\n",
        "    # ì‹œê³„ì—´ íŒ¨í‚¤ì§€ëŠ” ë³„ë„ë¡œ ì²˜ë¦¬ (ì˜¤ë¥˜ê°€ ìì£¼ ë°œìƒ)\n",
        "    print(\"\\nğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\")\n",
        "\n",
        "    # statsmodels ì„¤ì¹˜ ì‹œë„\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'statsmodels>=0.13.0'])\n",
        "        print(\"âœ… statsmodels ì„¤ì¹˜ ì™„ë£Œ\")\n",
        "    except:\n",
        "        print(\"âš ï¸ statsmodels ì„¤ì¹˜ ì‹¤íŒ¨ - ARIMA ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
        "\n",
        "    # pmdarima ì„¤ì¹˜ ì‹œë„ (ì˜ì¡´ì„±ì´ ë³µì¡í•´ì„œ ìì£¼ ì‹¤íŒ¨í•¨)\n",
        "    try:\n",
        "        # ë¨¼ì € ì˜ì¡´ì„± ì„¤ì¹˜\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'cython', 'numpy', 'scipy'])\n",
        "        # pmdarima ì„¤ì¹˜\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'pmdarima>=2.0.0'])\n",
        "        print(\"âœ… pmdarima ì„¤ì¹˜ ì™„ë£Œ\")\n",
        "    except:\n",
        "        print(\"âš ï¸ pmdarima ì„¤ì¹˜ ì‹¤íŒ¨ - Auto ARIMAë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
        "\n",
        "    # prophet ì„¤ì¹˜ ì‹œë„\n",
        "    try:\n",
        "        subprocess.check_call([sys.executable, '-m', 'pip', 'install', '-q', 'prophet>=1.1'])\n",
        "        print(\"âœ… prophet ì„¤ì¹˜ ì™„ë£Œ\")\n",
        "    except:\n",
        "        print(\"âš ï¸ prophet ì„¤ì¹˜ ì‹¤íŒ¨ - Prophet ëª¨ë¸ì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤\")\n",
        "\n",
        "    # í•œê¸€ í°íŠ¸ ì„¤ì¹˜ (Colabìš©)\n",
        "    try:\n",
        "        print(\"\\nğŸ¨ í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì¤‘...\")\n",
        "        subprocess.run(['apt-get', 'update', '-qq'], check=True, capture_output=True)\n",
        "        subprocess.run(['apt-get', 'install', '-qq', 'fonts-nanum*'], check=True, capture_output=True)\n",
        "        subprocess.run(['fc-cache', '-fv'], capture_output=True)\n",
        "    except:\n",
        "        print(\"âš ï¸ í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì‹¤íŒ¨, ê¸°ë³¸ í°íŠ¸ ì‚¬ìš©\")\n",
        "\n",
        "    print(\"\\nâœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\")\n",
        "    print(\"ğŸ’¡ ì¼ë¶€ ì‹œê³„ì—´ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ë„ ê¸°ë³¸ ML ëª¨ë¸ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.\")\n",
        "\n",
        "# íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì‹¤í–‰\n",
        "install_packages()\n",
        "\n",
        "# 2. ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸\n",
        "import gradio as gr\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import plotly.express as px\n",
        "import plotly.graph_objects as go\n",
        "from plotly.subplots import make_subplots\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# í•œê¸€ í°íŠ¸ ì„¤ì •\n",
        "try:\n",
        "    import japanize_matplotlib\n",
        "    japanize_matplotlib.japanize()\n",
        "except:\n",
        "    # ëŒ€ì²´ í°íŠ¸ ì„¤ì •\n",
        "    plt.rcParams['font.family'] = ['DejaVu Sans']\n",
        "    plt.rcParams['axes.unicode_minus'] = False\n",
        "\n",
        "# ë¨¸ì‹ ëŸ¬ë‹ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, TimeSeriesSplit\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler, RobustScaler\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, VotingClassifier\n",
        "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score, roc_curve\n",
        "from sklearn.metrics import precision_recall_curve, average_precision_score, mean_squared_error\n",
        "from sklearn.metrics import f1_score, precision_score, recall_score\n",
        "from sklearn.decomposition import PCA\n",
        "from sklearn.feature_selection import SelectKBest, f_classif, mutual_info_classif, VarianceThreshold\n",
        "import xgboost as xgb\n",
        "import lightgbm as lgb\n",
        "from datetime import datetime, timedelta\n",
        "import io\n",
        "import json\n",
        "import base64\n",
        "from typing import Dict, List, Tuple, Optional, Any\n",
        "\n",
        "# ì¶”ê°€ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "try:\n",
        "    import catboost as cb\n",
        "    from catboost import CatBoostClassifier\n",
        "    CATBOOST_AVAILABLE = True\n",
        "except:\n",
        "    print(\"âš ï¸ CatBoostë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    CATBOOST_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    import optuna\n",
        "    OPTUNA_AVAILABLE = True\n",
        "except:\n",
        "    print(\"âš ï¸ Optunaë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    OPTUNA_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from imblearn.over_sampling import SMOTE, ADASYN\n",
        "    from imblearn.under_sampling import RandomUnderSampler\n",
        "    from imblearn.combine import SMOTEENN\n",
        "    IMBALANCED_AVAILABLE = True\n",
        "except:\n",
        "    print(\"âš ï¸ Imbalanced-learnì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.\")\n",
        "    IMBALANCED_AVAILABLE = False\n",
        "\n",
        "# ì‹œê³„ì—´ ëª¨ë¸ ë¼ì´ë¸ŒëŸ¬ë¦¬\n",
        "try:\n",
        "    import tensorflow as tf\n",
        "    from tensorflow import keras\n",
        "    from tensorflow.keras import layers\n",
        "    from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
        "    TENSORFLOW_AVAILABLE = True\n",
        "    print(\"âœ… TensorFlow ë¡œë“œ ì„±ê³µ\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ TensorFlowë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. LSTM ëª¨ë¸ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤. (ì˜¤ë¥˜: {str(e)})\")\n",
        "    TENSORFLOW_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from statsmodels.tsa.arima.model import ARIMA\n",
        "    from statsmodels.tsa.stattools import adfuller\n",
        "    import pmdarima as pm\n",
        "    STATSMODELS_AVAILABLE = True\n",
        "    print(\"âœ… Statsmodels/pmdarima ë¡œë“œ ì„±ê³µ\")\n",
        "except ImportError as e:\n",
        "    print(f\"âš ï¸ Statsmodelsë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. ARIMA ëª¨ë¸ì€ ë¹„í™œì„±í™”ë©ë‹ˆë‹¤.\")\n",
        "    print(f\"   ì›ì¸: {str(e)}\")\n",
        "    print(\"   í•´ê²°ë°©ë²•: !pip install statsmodels pmdarima\")\n",
        "    STATSMODELS_AVAILABLE = False\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Statsmodels ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {str(e)}\")\n",
        "    STATSMODELS_AVAILABLE = False\n",
        "\n",
        "try:\n",
        "    from prophet import Prophet\n",
        "    PROPHET_AVAILABLE = True\n",
        "    print(\"âœ… Prophet ë¡œë“œ ì„±ê³µ\")\n",
        "except Exception as e:\n",
        "    print(f\"âš ï¸ Prophetì„ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤. (ì˜¤ë¥˜: {str(e)})\")\n",
        "    PROPHET_AVAILABLE = False\n",
        "\n",
        "# ================================================================================\n",
        "# 3. ì „ì—­ ë³€ìˆ˜ ë° ìƒíƒœ ê´€ë¦¬\n",
        "# ================================================================================\n",
        "\n",
        "class AppState:\n",
        "    \"\"\"ì• í”Œë¦¬ì¼€ì´ì…˜ ìƒíƒœ ê´€ë¦¬ í´ë˜ìŠ¤\"\"\"\n",
        "    def __init__(self):\n",
        "        self.data = None\n",
        "        self.processed_data = None\n",
        "        self.best_model = None\n",
        "        self.best_model_name = None\n",
        "        self.feature_names = None\n",
        "        self.encoders = None\n",
        "        self.model_results = {}\n",
        "        self.manager_performance = None\n",
        "        self.prediction_results = None\n",
        "        self.feature_importance = None\n",
        "        self.is_data_loaded = False\n",
        "        self.is_preprocessed = False\n",
        "        self.is_model_trained = False\n",
        "        self.time_series_models = {}  # ì‹œê³„ì—´ ëª¨ë¸ ì €ì¥\n",
        "        self.ensemble_model = None  # ì•™ìƒë¸” ëª¨ë¸\n",
        "        self.feature_selector = None  # í”¼ì²˜ ì„ íƒê¸°\n",
        "        self.scaler = None  # ìŠ¤ì¼€ì¼ëŸ¬\n",
        "\n",
        "app_state = AppState()\n",
        "\n",
        "# ================================================================================\n",
        "# 4. ìƒ˜í”Œ ë°ì´í„° ìƒì„± í•¨ìˆ˜\n",
        "# ================================================================================\n",
        "\n",
        "def create_sample_data() -> pd.DataFrame:\n",
        "    \"\"\"tst_atalk.xlsxì™€ ë™ì¼í•œ êµ¬ì¡°ì˜ ìƒ˜í”Œ ë°ì´í„° ìƒì„±\"\"\"\n",
        "    np.random.seed(42)\n",
        "    n_samples = 500\n",
        "\n",
        "    # ë‹´ë‹¹ì ëª©ë¡ (ì‹¤ì œ ë°ì´í„°ì™€ ë™ì¼)\n",
        "    managers = [\n",
        "        'ë°°ì œê²½(sv5203)', 'ì˜ˆì‹ í•´(sv0027)', 'ì–‘ì€ì„œ(sv5200)',\n",
        "        'ê¹€íƒœì—°(sv0026)', 'ìœ¤ì„í•œ(sv5202)', 'ì •ì§€ì›…(sv0025)',\n",
        "        'ë°•ì˜¨ì„¤ì•„(sv0024)', None  # Noneì€ ë¯¸ë°°ì •\n",
        "    ]\n",
        "\n",
        "    # íŒë§¤ì²˜ ëª©ë¡\n",
        "    channels = ['Gë§ˆì¼“', 'CJëª°', '11ë²ˆê°€', 'SSG', 'ì˜¥ì…˜', 'ë„¤ì´ë²„', 'ì¿ íŒ¡']\n",
        "\n",
        "    # ìƒíƒœ ëª©ë¡\n",
        "    statuses = ['ìŠ¹ì¸ì™„ë£Œ', '1íšŒ ì ‘ì´‰', '2íšŒ ì ‘ì´‰', '3íšŒ ì ‘ì´‰', 'ì ‘ì´‰ì‹¤íŒ¨', 'ì·¨ì†Œì™„ë£Œ', 'ì ‘ìˆ˜ì™„ë£Œ']\n",
        "    status_weights = [0.25, 0.15, 0.20, 0.10, 0.10, 0.05, 0.15]\n",
        "\n",
        "    # ë°ì´í„° ìƒì„±\n",
        "    data = {\n",
        "        'ê³µìœ ': ['ê³µìš©'] * n_samples,\n",
        "        'ì´ë¦„': [f'ê³ ê°_{np.random.randint(1000, 9999)}' for _ in range(n_samples)],\n",
        "        'ê³ ê°ë²ˆí˜¸': [f'452036_{i}' for i in range(n_samples)],\n",
        "        'ì„±ë³„': np.random.choice(['ë‚¨ì', 'ì—¬ì'], n_samples, p=[0.4, 0.6]),\n",
        "        'ìœ í˜•': np.random.choice(['ê°œì¸', 'ë²•ì¸'], n_samples, p=[0.9, 0.1]),\n",
        "        'ìƒì¼êµ¬ë¶„': ['ì–‘ë ¥'] * n_samples,\n",
        "        'í˜¼ì¸ì—¬ë¶€': np.random.choice(['ë¯¸í˜¼', 'ê¸°í˜¼'], n_samples, p=[0.4, 0.6]),\n",
        "        'TEL': [f'10{np.random.randint(10000000, 99999999)}' for _ in range(n_samples)],\n",
        "        'ë©”ëª¨': ['LGì •ìˆ˜ê¸°ë Œíƒˆ ìƒë‹´ ë¬¸ì˜ ' * np.random.randint(1, 5) for _ in range(n_samples)],\n",
        "        'ìƒíƒœ': np.random.choice(statuses, n_samples, p=status_weights),\n",
        "        'ë§ˆì¼€íŒ…í™œìš©ë™ì˜': np.random.choice(['ë™ì˜', 'ë¯¸ë™ì˜'], n_samples, p=[0.7, 0.3]),\n",
        "        'ì´ë©”ì¼ìˆ˜ì‹ ë™ì˜': np.random.choice(['ë™ì˜', 'ë¯¸ë™ì˜'], n_samples, p=[0.6, 0.4]),\n",
        "        'ë¬¸ììˆ˜ì‹ ë™ì˜': np.random.choice(['ë™ì˜', 'ë¯¸ë™ì˜'], n_samples, p=[0.65, 0.35]),\n",
        "        'ë‹´ë‹¹ì': np.random.choice(managers, n_samples, p=[0.2, 0.17, 0.16, 0.15, 0.15, 0.13, 0.03, 0.01]),\n",
        "        'ë“±ë¡ì¼ì': pd.date_range(start='2024-01-01', periods=n_samples, freq='H'),\n",
        "        'íŒë§¤ì²˜': np.random.choice(channels, n_samples),\n",
        "        'ë“±ë¡ì': np.random.choice(['ì–‘ì€ì„œ', 'ê¹€ë¯¼ìˆ˜', 'ì´ì§€ì€'], n_samples),\n",
        "        'ë“±ë¡ì¼ì‹œ': pd.date_range(start='2024-01-01', periods=n_samples, freq='H')\n",
        "    }\n",
        "\n",
        "    df = pd.DataFrame(data)\n",
        "\n",
        "    # ë‹´ë‹¹ìë³„ë¡œ ë‹¤ë¥¸ ìŠ¹ì¸ìœ¨ ì ìš©\n",
        "    for idx, row in df.iterrows():\n",
        "        if pd.notna(row['ë‹´ë‹¹ì']):\n",
        "            if 'ë°°ì œê²½' in row['ë‹´ë‹¹ì']:\n",
        "                if np.random.random() < 0.35:\n",
        "                    df.at[idx, 'ìƒíƒœ'] = 'ìŠ¹ì¸ì™„ë£Œ'\n",
        "            elif 'ì˜ˆì‹ í•´' in row['ë‹´ë‹¹ì']:\n",
        "                if np.random.random() < 0.32:\n",
        "                    df.at[idx, 'ìƒíƒœ'] = 'ìŠ¹ì¸ì™„ë£Œ'\n",
        "            elif 'ê¹€íƒœì—°' in row['ë‹´ë‹¹ì']:\n",
        "                if np.random.random() < 0.30:\n",
        "                    df.at[idx, 'ìƒíƒœ'] = 'ìŠ¹ì¸ì™„ë£Œ'\n",
        "\n",
        "    return df\n",
        "\n",
        "# ================================================================================\n",
        "# 5. ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ í•¨ìˆ˜\n",
        "# ================================================================================\n",
        "\n",
        "def advanced_feature_engineering(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§\"\"\"\n",
        "\n",
        "    # ë‹´ë‹¹ìë³„ ê³¼ê±° ì„±ê³¼ í†µê³„\n",
        "    if 'ë‹´ë‹¹ìëª…' in data.columns:\n",
        "        manager_stats = data.groupby('ë‹´ë‹¹ìëª…').agg({\n",
        "            'is_approved': ['mean', 'sum', 'count'],\n",
        "            'ì ‘ì´‰íšŸìˆ˜': ['mean', 'std'],\n",
        "            'ë©”ëª¨_ê¸¸ì´': 'mean'\n",
        "        }).round(4)\n",
        "\n",
        "        manager_stats.columns = [\n",
        "            'ë‹´ë‹¹ì_ìŠ¹ì¸ìœ¨', 'ë‹´ë‹¹ì_ì´ìŠ¹ì¸ìˆ˜', 'ë‹´ë‹¹ì_ì´ë¦¬ë“œìˆ˜',\n",
        "            'ë‹´ë‹¹ì_í‰ê· ì ‘ì´‰', 'ë‹´ë‹¹ì_ì ‘ì´‰í¸ì°¨', 'ë‹´ë‹¹ì_í‰ê· ë©”ëª¨'\n",
        "        ]\n",
        "\n",
        "        # ë‹´ë‹¹ì í†µê³„ ë³‘í•©\n",
        "        data = data.merge(manager_stats, left_on='ë‹´ë‹¹ìëª…', right_index=True, how='left')\n",
        "\n",
        "        # ë‹´ë‹¹ì ê²½í—˜ ì§€í‘œ\n",
        "        data['ë‹´ë‹¹ì_ê²½í—˜ì§€ìˆ˜'] = data['ë‹´ë‹¹ì_ì´ë¦¬ë“œìˆ˜'] / data['ë‹´ë‹¹ì_ì´ë¦¬ë“œìˆ˜'].max()\n",
        "        data['ë‹´ë‹¹ì_íš¨ìœ¨ì„±'] = data['ë‹´ë‹¹ì_ìŠ¹ì¸ìœ¨'] / (data['ë‹´ë‹¹ì_í‰ê· ì ‘ì´‰'] + 1)\n",
        "\n",
        "    # ì‹œê°„ëŒ€ë³„ íŒ¨í„´\n",
        "    if 'ë“±ë¡ì¼ì' in data.columns and pd.api.types.is_datetime64_any_dtype(data['ë“±ë¡ì¼ì']):\n",
        "        # ì‹œê°„ëŒ€ë³„ íŠ¹ì„±\n",
        "        data['ì‹œê°„ëŒ€'] = pd.cut(data['ë“±ë¡_ì‹œê°„'],\n",
        "                               bins=[0, 6, 12, 18, 24],\n",
        "                               labels=['ìƒˆë²½', 'ì˜¤ì „', 'ì˜¤í›„', 'ì €ë…'])\n",
        "\n",
        "        # ì£¼ë§ ì—¬ë¶€\n",
        "        data['ì£¼ë§ì—¬ë¶€'] = (data['ë“±ë¡_ìš”ì¼'] >= 5).astype(int)\n",
        "\n",
        "        # ì›”ì´ˆ/ì›”ë§ êµ¬ë¶„\n",
        "        data['ì›”ì´ˆ'] = (data['ë“±ë¡_ì¼'] <= 10).astype(int)\n",
        "        data['ì›”ë§'] = (data['ë“±ë¡_ì¼'] >= 21).astype(int)\n",
        "\n",
        "        # ë¶„ê¸°\n",
        "        data['ë¶„ê¸°'] = data['ë“±ë¡ì¼ì'].dt.quarter\n",
        "\n",
        "    # íŒë§¤ì²˜ë³„ íŠ¹ì„±\n",
        "    if 'íŒë§¤ì²˜' in data.columns:\n",
        "        channel_stats = data.groupby('íŒë§¤ì²˜')['is_approved'].agg(['mean', 'count'])\n",
        "        channel_stats.columns = ['íŒë§¤ì²˜_í‰ê· ìŠ¹ì¸ìœ¨', 'íŒë§¤ì²˜_ë¹ˆë„']\n",
        "        data = data.merge(channel_stats, left_on='íŒë§¤ì²˜', right_index=True, how='left')\n",
        "\n",
        "    # ê³ ê° íŠ¹ì„± ì¡°í•©\n",
        "    if all(col in data.columns for col in ['ì„±ë³„', 'í˜¼ì¸ì—¬ë¶€', 'ìœ í˜•']):\n",
        "        data['ê³ ê°í”„ë¡œíŒŒì¼'] = data['ì„±ë³„'] + '_' + data['í˜¼ì¸ì—¬ë¶€'] + '_' + data['ìœ í˜•']\n",
        "\n",
        "        # í”„ë¡œíŒŒì¼ë³„ ìŠ¹ì¸ìœ¨\n",
        "        profile_stats = data.groupby('ê³ ê°í”„ë¡œíŒŒì¼')['is_approved'].mean()\n",
        "        data['í”„ë¡œíŒŒì¼_ìŠ¹ì¸ìœ¨'] = data['ê³ ê°í”„ë¡œíŒŒì¼'].map(profile_stats)\n",
        "\n",
        "    # ë™ì˜ ì ìˆ˜\n",
        "    consent_cols = ['ë§ˆì¼€íŒ…í™œìš©ë™ì˜_num', 'ì´ë©”ì¼ìˆ˜ì‹ ë™ì˜_num', 'ë¬¸ììˆ˜ì‹ ë™ì˜_num']\n",
        "    if all(col in data.columns for col in consent_cols):\n",
        "        data['ë™ì˜ì ìˆ˜'] = data[consent_cols].sum(axis=1)\n",
        "        data['ì™„ì „ë™ì˜'] = (data['ë™ì˜ì ìˆ˜'] == 3).astype(int)\n",
        "\n",
        "    # ë©”ëª¨ ê´€ë ¨ ê³ ê¸‰ í”¼ì²˜\n",
        "    if 'ë©”ëª¨' in data.columns:\n",
        "        # íŠ¹ì • í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€\n",
        "        keywords = ['ì •ìˆ˜ê¸°', 'ë Œíƒˆ', 'ìƒë‹´', 'ë¬¸ì˜', 'ê²¬ì ', 'ì„¤ì¹˜']\n",
        "        for keyword in keywords:\n",
        "            data[f'ë©”ëª¨_{keyword}_í¬í•¨'] = data['ë©”ëª¨'].str.contains(keyword, na=False).astype(int)\n",
        "\n",
        "        # ë©”ëª¨ í’ˆì§ˆ ì ìˆ˜\n",
        "        data['ë©”ëª¨_í’ˆì§ˆì ìˆ˜'] = (\n",
        "            data['ë©”ëª¨_ê¸¸ì´'] / data['ë©”ëª¨_ê¸¸ì´'].max() * 0.3 +\n",
        "            data['ë©”ëª¨_ë‹¨ì–´ìˆ˜'] / data['ë©”ëª¨_ë‹¨ì–´ìˆ˜'].max() * 0.3 +\n",
        "            data[[f'ë©”ëª¨_{kw}_í¬í•¨' for kw in keywords]].sum(axis=1) / len(keywords) * 0.4\n",
        "        )\n",
        "\n",
        "    # ìƒí˜¸ì‘ìš© í”¼ì²˜\n",
        "    if 'ë‹´ë‹¹ì_ìŠ¹ì¸ìœ¨' in data.columns and 'íŒë§¤ì²˜_í‰ê· ìŠ¹ì¸ìœ¨' in data.columns:\n",
        "        data['ë‹´ë‹¹ìXíŒë§¤ì²˜_ì‹œë„ˆì§€'] = data['ë‹´ë‹¹ì_ìŠ¹ì¸ìœ¨'] * data['íŒë§¤ì²˜_í‰ê· ìŠ¹ì¸ìœ¨']\n",
        "\n",
        "    if 'ì ‘ì´‰íšŸìˆ˜' in data.columns and 'ë©”ëª¨_ê¸¸ì´' in data.columns:\n",
        "        data['ì ‘ì´‰Xë©”ëª¨_ìƒí˜¸ì‘ìš©'] = data['ì ‘ì´‰íšŸìˆ˜'] * np.log1p(data['ë©”ëª¨_ê¸¸ì´'])\n",
        "\n",
        "    # ì´ìƒì¹˜ í”Œë˜ê·¸\n",
        "    numerical_cols = data.select_dtypes(include=[np.number]).columns\n",
        "    for col in numerical_cols:\n",
        "        if col not in ['is_approved', 'is_approved_binary']:\n",
        "            Q1 = data[col].quantile(0.25)\n",
        "            Q3 = data[col].quantile(0.75)\n",
        "            IQR = Q3 - Q1\n",
        "            lower = Q1 - 1.5 * IQR\n",
        "            upper = Q3 + 1.5 * IQR\n",
        "            data[f'{col}_ì´ìƒì¹˜'] = ((data[col] < lower) | (data[col] > upper)).astype(int)\n",
        "\n",
        "    return data\n",
        "\n",
        "# ================================================================================\n",
        "# 6. ë°ì´í„° ì²˜ë¦¬ í•¨ìˆ˜ (ê°œì„ ëœ ë²„ì „)\n",
        "# ================================================================================\n",
        "\n",
        "def load_data(file) -> Tuple[pd.DataFrame, str]:\n",
        "    \"\"\"ë°ì´í„° ë¡œë“œ ë° ì´ˆê¸° ë¶„ì„\"\"\"\n",
        "    try:\n",
        "        if file is None:\n",
        "            # ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©\n",
        "            df = create_sample_data()\n",
        "            info_text = \"ğŸ“Œ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\\n\"\n",
        "        else:\n",
        "            # íŒŒì¼ ì½ê¸°\n",
        "            filename = file.name if hasattr(file, 'name') else 'uploaded_file'\n",
        "\n",
        "            try:\n",
        "                if filename.endswith('.csv'):\n",
        "                    df = pd.read_csv(file, encoding='utf-8')\n",
        "                elif filename.endswith(('.xlsx', '.xls')):\n",
        "                    df = pd.read_excel(file)\n",
        "                else:\n",
        "                    return None, \"âŒ ì§€ì›ë˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤. CSV ë˜ëŠ” Excel íŒŒì¼ì„ ì—…ë¡œë“œí•´ì£¼ì„¸ìš”.\"\n",
        "            except Exception as e:\n",
        "                return None, f\"âŒ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {str(e)}\"\n",
        "\n",
        "        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸\n",
        "        required_columns = ['ìƒíƒœ', 'ë‹´ë‹¹ì']\n",
        "        missing_columns = [col for col in required_columns if col not in df.columns]\n",
        "\n",
        "        if missing_columns:\n",
        "            return None, f\"âŒ í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {', '.join(missing_columns)}\"\n",
        "\n",
        "        # ë°ì´í„° ê¸°ë³¸ ì •ë³´ ë¶„ì„\n",
        "        total_rows = len(df)\n",
        "\n",
        "        # ìƒíƒœë³„ ë¶„í¬ ë¶„ì„\n",
        "        status_dist = df['ìƒíƒœ'].value_counts().to_dict()\n",
        "        approval_count = df[df['ìƒíƒœ'] == 'ìŠ¹ì¸ì™„ë£Œ'].shape[0]\n",
        "        approval_rate = (approval_count / total_rows * 100) if total_rows > 0 else 0\n",
        "\n",
        "        # ë‹´ë‹¹ìë³„ ë¶„í¬ ë¶„ì„\n",
        "        manager_dist = df['ë‹´ë‹¹ì'].value_counts().head(10).to_dict()\n",
        "\n",
        "        # íŒë§¤ì²˜ë³„ ë¶„í¬ ë¶„ì„\n",
        "        channel_dist = {}\n",
        "        if 'íŒë§¤ì²˜' in df.columns:\n",
        "            channel_dist = df['íŒë§¤ì²˜'].value_counts().head(10).to_dict()\n",
        "\n",
        "        info_text = f\"\"\"âœ… ë°ì´í„° ë¡œë”© ì„±ê³µ!\n",
        "\n",
        "ğŸ“Š ë°ì´í„° ê°œìš”:\n",
        "- ì „ì²´ ë¦¬ë“œ ìˆ˜: {total_rows:,}ê°œ\n",
        "- ìŠ¹ì¸ì™„ë£Œ: {approval_count}ê±´ ({approval_rate:.1f}%)\n",
        "- ì»¬ëŸ¼ ìˆ˜: {len(df.columns)}ê°œ\n",
        "\n",
        "ğŸ“ˆ ìƒíƒœë³„ ë¶„í¬:\n",
        "{chr(10).join([f'- {status}: {count}ê±´' for status, count in list(status_dist.items())[:5]])}\n",
        "\n",
        "ğŸ‘¥ ìƒìœ„ ë‹´ë‹¹ì (ë¦¬ë“œ ìˆ˜):\n",
        "{chr(10).join([f'- {manager}: {count}ê±´' for manager, count in list(manager_dist.items())[:5]])}\n",
        "\n",
        "ğŸª ì£¼ìš” íŒë§¤ì²˜:\n",
        "{chr(10).join([f'- {channel}: {count}ê±´' for channel, count in list(channel_dist.items())[:3]])}\n",
        "\n",
        "âœ… ë°ì´í„° ë¡œë“œ ì™„ë£Œ! ì´ì œ [ì „ì²˜ë¦¬ ì‹¤í–‰] ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "        app_state.data = df\n",
        "        app_state.is_data_loaded = True\n",
        "        return df, info_text\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ ë°ì´í„° ë¡œë”© ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "\n",
        "def preprocess_for_prediction(df: pd.DataFrame = None) -> Tuple[pd.DataFrame, str]:\n",
        "    \"\"\"ë¦¬ë“œ ì „í™˜ ì˜ˆì¸¡ì„ ìœ„í•œ ê³ ê¸‰ ë°ì´í„° ì „ì²˜ë¦¬\"\"\"\n",
        "    try:\n",
        "        if df is None:\n",
        "            if app_state.data is None:\n",
        "                return None, \"âŒ ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•´ì£¼ì„¸ìš”.\"\n",
        "            df = app_state.data\n",
        "\n",
        "        data = df.copy()\n",
        "\n",
        "        # íƒ€ê²Ÿ ë³€ìˆ˜ ìƒì„±\n",
        "        data['is_approved'] = (data['ìƒíƒœ'] == 'ìŠ¹ì¸ì™„ë£Œ').astype(int)\n",
        "\n",
        "        # ë‹´ë‹¹ì ì •ë³´ ì •ì œ\n",
        "        data['ë‹´ë‹¹ì'] = data['ë‹´ë‹¹ì'].fillna('ë¯¸ë°°ì •')\n",
        "        data['ë‹´ë‹¹ìëª…'] = data['ë‹´ë‹¹ì'].str.extract(r'([^(]+)')[0].str.strip()\n",
        "        data['ë‹´ë‹¹ìëª…'] = data['ë‹´ë‹¹ìëª…'].fillna('ë¯¸ë°°ì •')\n",
        "\n",
        "        # ë‚ ì§œ ì²˜ë¦¬\n",
        "        if 'ë“±ë¡ì¼ì' in data.columns:\n",
        "            data['ë“±ë¡ì¼ì'] = pd.to_datetime(data['ë“±ë¡ì¼ì'], errors='coerce')\n",
        "            data['ë“±ë¡_ë…„'] = data['ë“±ë¡ì¼ì'].dt.year\n",
        "            data['ë“±ë¡_ì›”'] = data['ë“±ë¡ì¼ì'].dt.month\n",
        "            data['ë“±ë¡_ì¼'] = data['ë“±ë¡ì¼ì'].dt.day\n",
        "            data['ë“±ë¡_ìš”ì¼'] = data['ë“±ë¡ì¼ì'].dt.dayofweek\n",
        "            data['ë“±ë¡_ì‹œê°„'] = data['ë“±ë¡ì¼ì'].dt.hour\n",
        "        else:\n",
        "            # ê¸°ë³¸ê°’ ì„¤ì •\n",
        "            data['ë“±ë¡_ë…„'] = 2024\n",
        "            data['ë“±ë¡_ì›”'] = 1\n",
        "            data['ë“±ë¡_ì¼'] = 1\n",
        "            data['ë“±ë¡_ìš”ì¼'] = 0\n",
        "            data['ë“±ë¡_ì‹œê°„'] = 9\n",
        "\n",
        "        # ì ‘ì´‰ íšŸìˆ˜ ì¶”ì¶œ\n",
        "        data['ì ‘ì´‰íšŸìˆ˜'] = 0\n",
        "        contact_pattern = r'(\\d+)íšŒ ì ‘ì´‰'\n",
        "        contact_matches = data['ìƒíƒœ'].str.extract(contact_pattern)\n",
        "        data.loc[contact_matches[0].notna(), 'ì ‘ì´‰íšŸìˆ˜'] = contact_matches[0].fillna(0).astype(int)\n",
        "\n",
        "        # ë©”ëª¨ ê¸¸ì´ ê³„ì‚°\n",
        "        if 'ë©”ëª¨' in data.columns:\n",
        "            data['ë©”ëª¨_ê¸¸ì´'] = data['ë©”ëª¨'].fillna('').str.len()\n",
        "            data['ë©”ëª¨_ë‹¨ì–´ìˆ˜'] = data['ë©”ëª¨'].fillna('').str.split().str.len()\n",
        "        else:\n",
        "            data['ë©”ëª¨_ê¸¸ì´'] = 50\n",
        "            data['ë©”ëª¨_ë‹¨ì–´ìˆ˜'] = 10\n",
        "\n",
        "        # ë™ì˜ ì •ë³´ ìˆ˜ì¹˜í™”\n",
        "        consent_cols = ['ë§ˆì¼€íŒ…í™œìš©ë™ì˜', 'ì´ë©”ì¼ìˆ˜ì‹ ë™ì˜', 'ë¬¸ììˆ˜ì‹ ë™ì˜']\n",
        "        for col in consent_cols:\n",
        "            if col in data.columns:\n",
        "                data[f'{col}_num'] = (data[col] == 'ë™ì˜').astype(int)\n",
        "            else:\n",
        "                data[f'{col}_num'] = 1  # ê¸°ë³¸ê°’\n",
        "\n",
        "        # ê³ ê¸‰ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§ ì ìš©\n",
        "        data = advanced_feature_engineering(data)\n",
        "\n",
        "        # ë‹´ë‹¹ìë³„ ì„±ê³¼ í†µê³„ ê³„ì‚°\n",
        "        manager_stats = data[data['ë‹´ë‹¹ìëª…'] != 'ë¯¸ë°°ì •'].groupby('ë‹´ë‹¹ìëª…').agg({\n",
        "            'is_approved': ['count', 'sum', 'mean'],\n",
        "            'ì ‘ì´‰íšŸìˆ˜': 'mean'\n",
        "        }).round(3)\n",
        "\n",
        "        if len(manager_stats) > 0:\n",
        "            manager_stats.columns = ['ì´_ë¦¬ë“œìˆ˜', 'ìŠ¹ì¸ì™„ë£Œìˆ˜', 'ìŠ¹ì¸ì™„ë£Œìœ¨', 'í‰ê· _ì ‘ì´‰íšŸìˆ˜']\n",
        "            manager_stats = manager_stats.reset_index()\n",
        "            manager_stats = manager_stats.sort_values('ìŠ¹ì¸ì™„ë£Œìœ¨', ascending=False)\n",
        "        else:\n",
        "            manager_stats = pd.DataFrame()\n",
        "\n",
        "        # ì „ì²˜ë¦¬ ê²°ê³¼ ìš”ì•½\n",
        "        feature_count = len([col for col in data.columns if col not in df.columns])\n",
        "\n",
        "        result_text = f\"\"\"âœ… ê³ ê¸‰ ë°ì´í„° ì „ì²˜ë¦¬ ì™„ë£Œ!\n",
        "\n",
        "ğŸ“Š íƒ€ê²Ÿ ë³€ìˆ˜ ë¶„í¬:\n",
        "- ìŠ¹ì¸ì™„ë£Œ: {data['is_approved'].sum():,}ê±´ ({data['is_approved'].mean():.1%})\n",
        "- ë¯¸ìŠ¹ì¸: {(1-data['is_approved']).sum():,}ê±´\n",
        "\n",
        "ğŸ”§ í”¼ì²˜ ì—”ì§€ë‹ˆì–´ë§:\n",
        "- ìƒì„±ëœ ì‹ ê·œ í”¼ì²˜: {feature_count}ê°œ\n",
        "- ë‹´ë‹¹ìë³„ ì„±ê³¼ ì§€í‘œ ì¶”ê°€\n",
        "- ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ì¶”ì¶œ\n",
        "- ê³ ê° í”„ë¡œíŒŒì¼ ë¶„ì„\n",
        "- ìƒí˜¸ì‘ìš© í”¼ì²˜ ìƒì„±\n",
        "\n",
        "ğŸ‘¥ ë‹´ë‹¹ìë³„ ì„±ê³¼ (ìƒìœ„ 5ëª…):\n",
        "{manager_stats.head().to_string(index=False) if len(manager_stats) > 0 else 'ë‹´ë‹¹ì ë°ì´í„° ì—†ìŒ'}\n",
        "\n",
        "ğŸ“ˆ ì£¼ìš” í”¼ì²˜ ìƒì„±:\n",
        "- ë‹´ë‹¹ì ê²½í—˜ ë° íš¨ìœ¨ì„± ì§€í‘œ\n",
        "- ì‹œê°„ëŒ€ë³„ íŒ¨í„´ (ì£¼ë§, ì‹œê°„ëŒ€, ì›”ì´ˆ/ì›”ë§)\n",
        "- íŒë§¤ì²˜ë³„ ì„±ê³¼ ì§€í‘œ\n",
        "- ê³ ê° í”„ë¡œíŒŒì¼ë³„ ìŠ¹ì¸ìœ¨\n",
        "- ë©”ëª¨ í’ˆì§ˆ ì ìˆ˜\n",
        "- ì´ìƒì¹˜ íƒì§€ í”Œë˜ê·¸\n",
        "\n",
        "âœ… ì „ì²˜ë¦¬ ì™„ë£Œ! ì´ì œ ë‹¤ë¥¸ íƒ­ì—ì„œ ë¶„ì„ì„ ì§„í–‰í•˜ì„¸ìš”.\n",
        "\"\"\"\n",
        "\n",
        "        app_state.processed_data = data\n",
        "        app_state.manager_performance = manager_stats\n",
        "        app_state.is_preprocessed = True\n",
        "        return data, result_text\n",
        "\n",
        "    except Exception as e:\n",
        "        return None, f\"âŒ ì „ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\\n\\nìƒì„¸ ì˜¤ë¥˜:\\n{type(e).__name__}: {str(e)}\"\n",
        "\n",
        "# ================================================================================\n",
        "# 7. ë‹´ë‹¹ìë³„ ì„±ê³¼ ë¶„ì„ ë° ì‹œê°í™” (ê¸°ì¡´ ìœ ì§€)\n",
        "# ================================================================================\n",
        "\n",
        "def create_manager_performance_dashboard() -> Tuple[List[go.Figure], str]:\n",
        "    \"\"\"ë‹´ë‹¹ìë³„ ì„±ê³¼ ëŒ€ì‹œë³´ë“œ ìƒì„±\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_preprocessed or app_state.processed_data is None:\n",
        "            return [], \"âŒ ë¨¼ì € ë°ì´í„°ë¥¼ ë¡œë“œí•˜ê³  ì „ì²˜ë¦¬ë¥¼ ì‹¤í–‰í•´ì£¼ì„¸ìš”.\"\n",
        "\n",
        "        data = app_state.processed_data\n",
        "        plots = []\n",
        "\n",
        "        # 1. ë‹´ë‹¹ìë³„ ìŠ¹ì¸ì™„ë£Œìœ¨ ë° ì²˜ë¦¬ëŸ‰\n",
        "        manager_stats = data[data['ë‹´ë‹¹ìëª…'] != 'ë¯¸ë°°ì •'].groupby('ë‹´ë‹¹ìëª…').agg({\n",
        "            'is_approved': ['count', 'sum', 'mean']\n",
        "        }).round(3)\n",
        "\n",
        "        if len(manager_stats) == 0:\n",
        "            return [], \"âŒ ë‹´ë‹¹ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        manager_stats.columns = ['ì´_ë¦¬ë“œìˆ˜', 'ìŠ¹ì¸ì™„ë£Œìˆ˜', 'ìŠ¹ì¸ì™„ë£Œìœ¨']\n",
        "        manager_stats = manager_stats.reset_index()\n",
        "        manager_stats = manager_stats[manager_stats['ì´_ë¦¬ë“œìˆ˜'] >= 5]  # 5ê±´ ì´ìƒë§Œ í‘œì‹œ\n",
        "        manager_stats = manager_stats.sort_values('ìŠ¹ì¸ì™„ë£Œìœ¨', ascending=False)\n",
        "\n",
        "        # ê·¸ë˜í”„ 1: ë‹´ë‹¹ìë³„ ì„±ê³¼ ë§¤íŠ¸ë¦­ìŠ¤\n",
        "        fig1 = px.scatter(manager_stats,\n",
        "                         x='ì´_ë¦¬ë“œìˆ˜',\n",
        "                         y='ìŠ¹ì¸ì™„ë£Œìœ¨',\n",
        "                         size='ìŠ¹ì¸ì™„ë£Œìˆ˜',\n",
        "                         text='ë‹´ë‹¹ìëª…',\n",
        "                         color='ìŠ¹ì¸ì™„ë£Œìœ¨',\n",
        "                         title='ë‹´ë‹¹ìë³„ ì„±ê³¼ ë§¤íŠ¸ë¦­ìŠ¤ (ë¦¬ë“œ ì²˜ë¦¬ëŸ‰ vs ìŠ¹ì¸ì™„ë£Œìœ¨)',\n",
        "                         color_continuous_scale='RdYlGn')\n",
        "\n",
        "        fig1.update_traces(textposition='top center', textfont_size=10)\n",
        "        fig1.update_layout(\n",
        "            height=500,\n",
        "            xaxis_title='ì´ ë¦¬ë“œ ì²˜ë¦¬ìˆ˜',\n",
        "            yaxis_title='ìŠ¹ì¸ì™„ë£Œìœ¨',\n",
        "            yaxis_tickformat='.0%'\n",
        "        )\n",
        "\n",
        "        # í‰ê· ì„  ì¶”ê°€\n",
        "        avg_approval_rate = data['is_approved'].mean()\n",
        "        fig1.add_hline(y=avg_approval_rate, line_dash=\"dash\", line_color=\"gray\",\n",
        "                       annotation_text=f\"ì „ì²´ í‰ê· : {avg_approval_rate:.1%}\")\n",
        "\n",
        "        plots.append(fig1)\n",
        "\n",
        "        # ê·¸ë˜í”„ 2: ë‹´ë‹¹ìë³„ ìŠ¹ì¸ì™„ë£Œìœ¨ ìˆœìœ„\n",
        "        fig2 = go.Figure()\n",
        "\n",
        "        # ìƒìœ„ 10ëª…\n",
        "        top_managers = manager_stats.head(10)\n",
        "        fig2.add_trace(go.Bar(\n",
        "            x=top_managers['ë‹´ë‹¹ìëª…'],\n",
        "            y=top_managers['ìŠ¹ì¸ì™„ë£Œìœ¨'],\n",
        "            text=top_managers['ìŠ¹ì¸ì™„ë£Œìœ¨'].apply(lambda x: f'{x:.1%}'),\n",
        "            textposition='outside',\n",
        "            name='ìŠ¹ì¸ì™„ë£Œìœ¨',\n",
        "            marker_color='lightgreen'\n",
        "        ))\n",
        "\n",
        "        fig2.update_layout(\n",
        "            title='ë‹´ë‹¹ìë³„ ìŠ¹ì¸ì™„ë£Œìœ¨ TOP 10',\n",
        "            xaxis_title='ë‹´ë‹¹ì',\n",
        "            yaxis_title='ìŠ¹ì¸ì™„ë£Œìœ¨',\n",
        "            yaxis_tickformat='.0%',\n",
        "            height=400\n",
        "        )\n",
        "\n",
        "        plots.append(fig2)\n",
        "\n",
        "        # ê·¸ë˜í”„ 3: ë‹´ë‹¹ìë³„ ì¼ì¼ ì²˜ë¦¬ íŒ¨í„´\n",
        "        if 'ë“±ë¡ì¼ì' in data.columns and pd.api.types.is_datetime64_any_dtype(data['ë“±ë¡ì¼ì']):\n",
        "            daily_stats = data.groupby(['ë‹´ë‹¹ìëª…', pd.Grouper(key='ë“±ë¡ì¼ì', freq='D')]).agg({\n",
        "                'is_approved': ['count', 'mean']\n",
        "            }).reset_index()\n",
        "            daily_stats.columns = ['ë‹´ë‹¹ìëª…', 'ë‚ ì§œ', 'ì²˜ë¦¬ê±´ìˆ˜', 'ìŠ¹ì¸ì™„ë£Œìœ¨']\n",
        "\n",
        "            # ìƒìœ„ 5ëª… ë‹´ë‹¹ìë§Œ í‘œì‹œ\n",
        "            top_5_managers = manager_stats.head(5)['ë‹´ë‹¹ìëª…'].tolist()\n",
        "            daily_top = daily_stats[daily_stats['ë‹´ë‹¹ìëª…'].isin(top_5_managers)]\n",
        "\n",
        "            if len(daily_top) > 0:\n",
        "                fig3 = px.line(daily_top,\n",
        "                              x='ë‚ ì§œ',\n",
        "                              y='ìŠ¹ì¸ì™„ë£Œìœ¨',\n",
        "                              color='ë‹´ë‹¹ìëª…',\n",
        "                              title='ìƒìœ„ 5ëª… ë‹´ë‹¹ìì˜ ì¼ë³„ ìŠ¹ì¸ì™„ë£Œìœ¨ ì¶”ì´',\n",
        "                              markers=True)\n",
        "\n",
        "                fig3.update_layout(\n",
        "                    height=400,\n",
        "                    yaxis_tickformat='.0%',\n",
        "                    hovermode='x unified'\n",
        "                )\n",
        "\n",
        "                plots.append(fig3)\n",
        "\n",
        "        # ê·¸ë˜í”„ 4: ë‹´ë‹¹ìë³„ ì ‘ì´‰ íš¨ìœ¨ì„±\n",
        "        contact_stats = data[data['ë‹´ë‹¹ìëª…'] != 'ë¯¸ë°°ì •'].groupby('ë‹´ë‹¹ìëª…').agg({\n",
        "            'ì ‘ì´‰íšŸìˆ˜': 'mean',\n",
        "            'is_approved': 'mean'\n",
        "        }).reset_index()\n",
        "\n",
        "        contact_stats = contact_stats[contact_stats['ì ‘ì´‰íšŸìˆ˜'] > 0]\n",
        "\n",
        "        if len(contact_stats) > 0:\n",
        "            contact_stats['íš¨ìœ¨ì„±'] = contact_stats['is_approved'] / (contact_stats['ì ‘ì´‰íšŸìˆ˜'] + 1)  # +1 to avoid division by zero\n",
        "            contact_stats = contact_stats.sort_values('íš¨ìœ¨ì„±', ascending=False).head(15)\n",
        "\n",
        "            fig4 = go.Figure()\n",
        "            fig4.add_trace(go.Bar(\n",
        "                x=contact_stats['ë‹´ë‹¹ìëª…'],\n",
        "                y=contact_stats['íš¨ìœ¨ì„±'],\n",
        "                text=contact_stats['íš¨ìœ¨ì„±'].apply(lambda x: f'{x:.3f}'),\n",
        "                textposition='outside',\n",
        "                name='ì ‘ì´‰ íš¨ìœ¨ì„±',\n",
        "                marker_color='lightcoral'\n",
        "            ))\n",
        "\n",
        "            fig4.update_layout(\n",
        "                title='ë‹´ë‹¹ìë³„ ì ‘ì´‰ íš¨ìœ¨ì„± (ìŠ¹ì¸ìœ¨/í‰ê· ì ‘ì´‰íšŸìˆ˜)',\n",
        "                xaxis_title='ë‹´ë‹¹ì',\n",
        "                yaxis_title='íš¨ìœ¨ì„± ì§€ìˆ˜',\n",
        "                height=400\n",
        "            )\n",
        "\n",
        "            plots.append(fig4)\n",
        "\n",
        "        success_message = \"âœ… ì„±ê³¼ ë¶„ì„ ì™„ë£Œ!\"\n",
        "        return plots, success_message\n",
        "\n",
        "    except Exception as e:\n",
        "        return [], f\"âŒ ì„±ê³¼ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\"\n",
        "\n",
        "# ================================================================================\n",
        "# 8. í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”\n",
        "# ================================================================================\n",
        "\n",
        "def optimize_hyperparameters(X_train, y_train, model_type='xgboost'):\n",
        "    \"\"\"Optunaë¥¼ ì‚¬ìš©í•œ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” (ì˜¤ë¥˜ ì²˜ë¦¬ ê°•í™”)\"\"\"\n",
        "    if not OPTUNA_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        def objective(trial):\n",
        "            try:\n",
        "                if model_type == 'xgboost':\n",
        "                    params = {\n",
        "                        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "                        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "                        'subsample': trial.suggest_float('subsample', 0.7, 1.0),\n",
        "                        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.7, 1.0),\n",
        "                        'gamma': trial.suggest_float('gamma', 0, 3),\n",
        "                        'min_child_weight': trial.suggest_int('min_child_weight', 1, 5),\n",
        "                        'random_state': 42,\n",
        "                        'use_label_encoder': False,\n",
        "                        'eval_metric': 'logloss'\n",
        "                    }\n",
        "                    model = xgb.XGBClassifier(**params)\n",
        "\n",
        "                elif model_type == 'lightgbm':\n",
        "                    params = {\n",
        "                        'n_estimators': trial.suggest_int('n_estimators', 50, 200),\n",
        "                        'max_depth': trial.suggest_int('max_depth', 3, 8),\n",
        "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "                        'num_leaves': trial.suggest_int('num_leaves', 20, 150),\n",
        "                        'feature_fraction': trial.suggest_float('feature_fraction', 0.6, 1.0),\n",
        "                        'bagging_fraction': trial.suggest_float('bagging_fraction', 0.6, 1.0),\n",
        "                        'bagging_freq': trial.suggest_int('bagging_freq', 1, 5),\n",
        "                        'min_child_samples': trial.suggest_int('min_child_samples', 10, 50),\n",
        "                        'random_state': 42,\n",
        "                        'verbose': -1\n",
        "                    }\n",
        "                    model = lgb.LGBMClassifier(**params)\n",
        "\n",
        "                elif model_type == 'catboost':\n",
        "                    if not CATBOOST_AVAILABLE:\n",
        "                        return 0\n",
        "                    params = {\n",
        "                        'iterations': trial.suggest_int('iterations', 50, 150),\n",
        "                        'depth': trial.suggest_int('depth', 3, 8),\n",
        "                        'learning_rate': trial.suggest_float('learning_rate', 0.01, 0.2),\n",
        "                        'l2_leaf_reg': trial.suggest_float('l2_leaf_reg', 1, 5),\n",
        "                        'bagging_temperature': trial.suggest_float('bagging_temperature', 0, 0.5),\n",
        "                        'random_strength': trial.suggest_float('random_strength', 0, 0.5),\n",
        "                        'random_state': 42,\n",
        "                        'verbose': False\n",
        "                    }\n",
        "                    model = CatBoostClassifier(**params)\n",
        "\n",
        "                # ê°„ë‹¨í•œ êµì°¨ ê²€ì¦ (ì‹œê³„ì—´ ë¶„í•  ëŒ€ì‹  ì¼ë°˜ ë¶„í•  ì‚¬ìš©)\n",
        "                if len(X_train) < 100:\n",
        "                    # ë°ì´í„°ê°€ ì ì€ ê²½ìš° ë‹¨ìˆœ í•™ìŠµ/ê²€ì¦ ë¶„í• \n",
        "                    X_tr, X_val, y_tr, y_val = train_test_split(\n",
        "                        X_train, y_train, test_size=0.2, random_state=42\n",
        "                    )\n",
        "                    model.fit(X_tr, y_tr)\n",
        "                    y_pred_proba = model.predict_proba(X_val)[:, 1]\n",
        "                    score = roc_auc_score(y_val, y_pred_proba)\n",
        "                else:\n",
        "                    # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆëŠ” ê²½ìš° êµì°¨ ê²€ì¦\n",
        "                    cv = StratifiedKFold(n_splits=3, shuffle=True, random_state=42)\n",
        "                    scores = cross_val_score(model, X_train, y_train, cv=cv, scoring='roc_auc')\n",
        "                    score = scores.mean()\n",
        "\n",
        "                return score\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Trial ì‹¤íŒ¨: {str(e)}\")\n",
        "                return 0.0\n",
        "\n",
        "        # ìµœì í™” ìˆ˜í–‰ (ì‹œë„ íšŸìˆ˜ ì¤„ì„)\n",
        "        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=42))\n",
        "        study.optimize(objective, n_trials=10, show_progress_bar=False, catch=(Exception,))\n",
        "\n",
        "        # ì™„ë£Œëœ trialì´ ìˆëŠ”ì§€ í™•ì¸\n",
        "        if len(study.trials) == 0 or study.best_trial is None:\n",
        "            print(f\"{model_type} ìµœì í™” ì‹¤íŒ¨ - ê¸°ë³¸ íŒŒë¼ë¯¸í„° ì‚¬ìš©\")\n",
        "            return None\n",
        "\n",
        "        return study.best_params\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "# ================================================================================\n",
        "# 9. ê°œì„ ëœ ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ í•™ìŠµ\n",
        "# ================================================================================\n",
        "\n",
        "def handle_class_imbalance(X_train, y_train):\n",
        "    \"\"\"í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ (ì•ˆì „í•œ ë²„ì „)\"\"\"\n",
        "    if not IMBALANCED_AVAILABLE:\n",
        "        return X_train, y_train\n",
        "\n",
        "    try:\n",
        "        # í´ë˜ìŠ¤ ë¹„ìœ¨ í™•ì¸\n",
        "        unique, counts = np.unique(y_train, return_counts=True)\n",
        "        min_class_count = min(counts)\n",
        "\n",
        "        # ì†Œìˆ˜ í´ë˜ìŠ¤ê°€ ë„ˆë¬´ ì ìœ¼ë©´ SMOTE ì‚¬ìš© ë¶ˆê°€\n",
        "        if min_class_count < 6:\n",
        "            print(\"ì†Œìˆ˜ í´ë˜ìŠ¤ ìƒ˜í”Œì´ ë„ˆë¬´ ì ì–´ ë¶ˆê· í˜• ì²˜ë¦¬ë¥¼ ê±´ë„ˆëœë‹ˆë‹¤.\")\n",
        "            return X_train, y_train\n",
        "\n",
        "        # SMOTEë§Œ ì‚¬ìš© (SMOTEENNì€ ë•Œë•Œë¡œ ë¶ˆì•ˆì •í•¨)\n",
        "        smote = SMOTE(random_state=42, k_neighbors=min(5, min_class_count-1))\n",
        "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
        "\n",
        "        print(f\"í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ì™„ë£Œ: {len(X_train)} â†’ {len(X_resampled)}\")\n",
        "        return X_resampled, y_resampled\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
        "        # ì‹¤íŒ¨ ì‹œ ì›ë³¸ ë°˜í™˜\n",
        "        return X_train, y_train\n",
        "\n",
        "def select_best_features(X_train, y_train, X_test, feature_names, k=20):\n",
        "    \"\"\"ìµœì  í”¼ì²˜ ì„ íƒ (ì•ˆì „í•œ ë²„ì „)\"\"\"\n",
        "    try:\n",
        "        # í”¼ì²˜ ìˆ˜ê°€ kë³´ë‹¤ ì ìœ¼ë©´ ëª¨ë“  í”¼ì²˜ ì‚¬ìš©\n",
        "        if X_train.shape[1] <= k:\n",
        "            return X_train, X_test, feature_names, None\n",
        "\n",
        "        # ë¶„ì‚°ì´ 0ì¸ í”¼ì²˜ ì œê±°\n",
        "        var_selector = VarianceThreshold(threshold=0.01)\n",
        "        X_train_var = var_selector.fit_transform(X_train)\n",
        "        X_test_var = var_selector.transform(X_test)\n",
        "        selected_features_var = [feature_names[i] for i in var_selector.get_support(indices=True)]\n",
        "\n",
        "        # í”¼ì²˜ê°€ ë„ˆë¬´ ë§ì´ ì œê±°ë˜ì—ˆë‹¤ë©´ ì›ë³¸ ì‚¬ìš©\n",
        "        if len(selected_features_var) < 5:\n",
        "            return X_train, X_test, feature_names, None\n",
        "\n",
        "        # ìƒí˜¸ ì •ë³´ëŸ‰ ê¸°ë°˜ í”¼ì²˜ ì„ íƒ\n",
        "        selector = SelectKBest(score_func=mutual_info_classif, k=min(k, len(selected_features_var)))\n",
        "        selector.fit(X_train_var, y_train)\n",
        "\n",
        "        # ì„ íƒëœ í”¼ì²˜ ì¸ë±ìŠ¤\n",
        "        selected_indices = selector.get_support(indices=True)\n",
        "        final_features = [selected_features_var[i] for i in selected_indices]\n",
        "\n",
        "        # ë³€í™˜\n",
        "        X_train_selected = selector.transform(X_train_var)\n",
        "        X_test_selected = selector.transform(X_test_var)\n",
        "\n",
        "        print(f\"í”¼ì²˜ ì„ íƒ ì™„ë£Œ: {X_train.shape[1]} â†’ {X_train_selected.shape[1]}\")\n",
        "\n",
        "        return X_train_selected, X_test_selected, final_features, selector\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"í”¼ì²˜ ì„ íƒ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
        "        return X_train, X_test, feature_names, None\n",
        "\n",
        "def build_advanced_lstm_model(input_shape: Tuple[int, int]) -> keras.Model:\n",
        "    \"\"\"ê°œì„ ëœ LSTM ëª¨ë¸ êµ¬ì¶•\"\"\"\n",
        "    if not TENSORFLOW_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    model = keras.Sequential([\n",
        "        layers.LSTM(128, return_sequences=True, input_shape=input_shape),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.LSTM(64, return_sequences=True),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.3),\n",
        "        layers.LSTM(32, return_sequences=False),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(16, activation='relu'),\n",
        "        layers.BatchNormalization(),\n",
        "        layers.Dropout(0.2),\n",
        "        layers.Dense(1, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
        "        loss='binary_crossentropy',\n",
        "        metrics=['accuracy', 'AUC', keras.metrics.Precision(), keras.metrics.Recall()]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "def train_prophet_for_manager(manager_data: pd.DataFrame) -> Any:\n",
        "    \"\"\"Prophet ëª¨ë¸ í•™ìŠµ\"\"\"\n",
        "    if not PROPHET_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # Prophet í˜•ì‹ìœ¼ë¡œ ë°ì´í„° ì¤€ë¹„\n",
        "        prophet_data = manager_data[['ë‚ ì§œ', 'ìŠ¹ì¸ìœ¨']].rename(\n",
        "            columns={'ë‚ ì§œ': 'ds', 'ìŠ¹ì¸ìœ¨': 'y'}\n",
        "        )\n",
        "\n",
        "        # ëª¨ë¸ í•™ìŠµ\n",
        "        model = Prophet(\n",
        "            changepoint_prior_scale=0.05,\n",
        "            seasonality_prior_scale=10,\n",
        "            holidays_prior_scale=10,\n",
        "            daily_seasonality=False,\n",
        "            weekly_seasonality=True,\n",
        "            yearly_seasonality=False\n",
        "        )\n",
        "\n",
        "        model.fit(prophet_data)\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Prophet í•™ìŠµ ì˜¤ë¥˜: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def train_prediction_model_with_data(filtered_data: pd.DataFrame = None) -> Tuple[Dict, str]:\n",
        "    \"\"\"ê°œì„ ëœ ë¦¬ë“œ ì „í™˜ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ\"\"\"\n",
        "    try:\n",
        "        if filtered_data is None:\n",
        "            filtered_data = app_state.processed_data\n",
        "\n",
        "        if filtered_data is None or len(filtered_data) == 0:\n",
        "            return {}, \"âŒ í•™ìŠµí•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        data = filtered_data\n",
        "\n",
        "        # íƒ€ê²Ÿ ë³€ìˆ˜ í™•ì¸\n",
        "        if 'is_approved' not in data.columns:\n",
        "            return {}, \"âŒ íƒ€ê²Ÿ ë³€ìˆ˜(is_approved)ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        # í”¼ì²˜ ì¤€ë¹„\n",
        "        feature_cols = []\n",
        "\n",
        "        # ìˆ˜ì¹˜í˜• í”¼ì²˜ (í™•ì¥ëœ ë²„ì „)\n",
        "        numerical_features = [\n",
        "            'ì ‘ì´‰íšŸìˆ˜', 'ë©”ëª¨_ê¸¸ì´', 'ë©”ëª¨_ë‹¨ì–´ìˆ˜',\n",
        "            'ë“±ë¡_ì›”', 'ë“±ë¡_ì¼', 'ë“±ë¡_ìš”ì¼', 'ë“±ë¡_ì‹œê°„',\n",
        "            'ë‹´ë‹¹ì_ìŠ¹ì¸ìœ¨', 'ë‹´ë‹¹ì_ì´ìŠ¹ì¸ìˆ˜', 'ë‹´ë‹¹ì_ì´ë¦¬ë“œìˆ˜',\n",
        "            'ë‹´ë‹¹ì_í‰ê· ì ‘ì´‰', 'ë‹´ë‹¹ì_ê²½í—˜ì§€ìˆ˜', 'ë‹´ë‹¹ì_íš¨ìœ¨ì„±',\n",
        "            'íŒë§¤ì²˜_í‰ê· ìŠ¹ì¸ìœ¨', 'íŒë§¤ì²˜_ë¹ˆë„', 'í”„ë¡œíŒŒì¼_ìŠ¹ì¸ìœ¨',\n",
        "            'ë™ì˜ì ìˆ˜', 'ì™„ì „ë™ì˜', 'ë©”ëª¨_í’ˆì§ˆì ìˆ˜',\n",
        "            'ë‹´ë‹¹ìXíŒë§¤ì²˜_ì‹œë„ˆì§€', 'ì ‘ì´‰Xë©”ëª¨_ìƒí˜¸ì‘ìš©'\n",
        "        ]\n",
        "\n",
        "        # ë²”ì£¼í˜• í”¼ì²˜\n",
        "        categorical_features = ['ë‹´ë‹¹ìëª…', 'íŒë§¤ì²˜', 'ì„±ë³„', 'ìœ í˜•', 'ì‹œê°„ëŒ€', 'ê³ ê°í”„ë¡œíŒŒì¼']\n",
        "\n",
        "        # ë™ì˜ ê´€ë ¨ í”¼ì²˜\n",
        "        consent_features = ['ë§ˆì¼€íŒ…í™œìš©ë™ì˜_num', 'ì´ë©”ì¼ìˆ˜ì‹ ë™ì˜_num', 'ë¬¸ììˆ˜ì‹ ë™ì˜_num']\n",
        "\n",
        "        # í‚¤ì›Œë“œ í”¼ì²˜\n",
        "        keyword_features = [col for col in data.columns if col.startswith('ë©”ëª¨_') and col.endswith('_í¬í•¨')]\n",
        "\n",
        "        # ì´ìƒì¹˜ í”¼ì²˜\n",
        "        outlier_features = [col for col in data.columns if col.endswith('_ì´ìƒì¹˜')]\n",
        "\n",
        "        # ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ë§Œ ì„ íƒ\n",
        "        all_features = numerical_features + consent_features + keyword_features + outlier_features\n",
        "        for col in all_features:\n",
        "            if col in data.columns:\n",
        "                feature_cols.append(col)\n",
        "\n",
        "        if len(feature_cols) == 0:\n",
        "            return {}, \"âŒ ì‚¬ìš© ê°€ëŠ¥í•œ í”¼ì²˜ê°€ ì—†ìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        # ë²”ì£¼í˜• ë³€ìˆ˜ ì¸ì½”ë”©\n",
        "        encoded_data = data.copy()\n",
        "        encoders = {}\n",
        "\n",
        "        for col in categorical_features:\n",
        "            if col in data.columns:\n",
        "                try:\n",
        "                    encoded_data[col] = encoded_data[col].fillna('Unknown')\n",
        "                    le = LabelEncoder()\n",
        "                    encoded_data[f'{col}_encoded'] = le.fit_transform(encoded_data[col].astype(str))\n",
        "                    encoders[col] = le\n",
        "                    feature_cols.append(f'{col}_encoded')\n",
        "                except Exception as e:\n",
        "                    print(f\"âš ï¸ {col} ì¸ì½”ë”© ì‹¤íŒ¨: {str(e)}\")\n",
        "\n",
        "        # í›ˆë ¨ ë°ì´í„° ì¤€ë¹„\n",
        "        X = encoded_data[feature_cols].fillna(0)\n",
        "        y = encoded_data['is_approved']\n",
        "\n",
        "        # ë°ì´í„° ê²€ì¦\n",
        "        if len(X) < 50:\n",
        "            return {}, f\"âŒ í•™ìŠµ ë°ì´í„°ê°€ ë„ˆë¬´ ì ìŠµë‹ˆë‹¤. (í˜„ì¬: {len(X)}ê±´, ìµœì†Œ: 50ê±´)\"\n",
        "\n",
        "        # ìŠ¤ì¼€ì¼ë§\n",
        "        scaler = RobustScaler()  # ì´ìƒì¹˜ì— ê°•í•œ ìŠ¤ì¼€ì¼ëŸ¬\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "        app_state.scaler = scaler\n",
        "\n",
        "        # ë°ì´í„° ë¶„í• \n",
        "        try:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_scaled, y, test_size=0.2, random_state=42, stratify=y\n",
        "            )\n",
        "        except:\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X_scaled, y, test_size=0.2, random_state=42\n",
        "            )\n",
        "\n",
        "        # í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬\n",
        "        X_train_balanced, y_train_balanced = handle_class_imbalance(X_train, y_train)\n",
        "\n",
        "        # í”¼ì²˜ ì„ íƒ\n",
        "        X_train_selected, X_test_selected, selected_features, feature_selector = select_best_features(\n",
        "            X_train_balanced, y_train_balanced, X_test, feature_cols\n",
        "        )\n",
        "        app_state.feature_selector = feature_selector\n",
        "\n",
        "        # ëª¨ë¸ ì •ì˜\n",
        "        models = {\n",
        "            'Random Forest': RandomForestClassifier(\n",
        "                n_estimators=100, random_state=42, max_depth=10,\n",
        "                min_samples_split=5, min_samples_leaf=2,\n",
        "                class_weight='balanced'\n",
        "            ),\n",
        "            'Gradient Boosting': GradientBoostingClassifier(\n",
        "                n_estimators=100, random_state=42, max_depth=5,\n",
        "                learning_rate=0.1, subsample=0.8\n",
        "            )\n",
        "        }\n",
        "\n",
        "        # í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œë„ (ì„ íƒì )\n",
        "        optimization_attempted = False\n",
        "        if OPTUNA_AVAILABLE and len(X_train_selected) >= 100:  # ì¶©ë¶„í•œ ë°ì´í„°ê°€ ìˆì„ ë•Œë§Œ\n",
        "            try:\n",
        "                print(\"í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™” ì‹œë„ ì¤‘...\")\n",
        "\n",
        "                # XGBoost ìµœì í™”\n",
        "                xgb_params = optimize_hyperparameters(X_train_selected, y_train_balanced, 'xgboost')\n",
        "                if xgb_params:\n",
        "                    models['XGBoost (Optimized)'] = xgb.XGBClassifier(**xgb_params)\n",
        "                    optimization_attempted = True\n",
        "\n",
        "                # LightGBM ìµœì í™”\n",
        "                lgb_params = optimize_hyperparameters(X_train_selected, y_train_balanced, 'lightgbm')\n",
        "                if lgb_params:\n",
        "                    models['LightGBM (Optimized)'] = lgb.LGBMClassifier(**lgb_params)\n",
        "                    optimization_attempted = True\n",
        "\n",
        "                # CatBoost ìµœì í™”\n",
        "                if CATBOOST_AVAILABLE:\n",
        "                    cat_params = optimize_hyperparameters(X_train_selected, y_train_balanced, 'catboost')\n",
        "                    if cat_params:\n",
        "                        models['CatBoost (Optimized)'] = CatBoostClassifier(**cat_params)\n",
        "                        optimization_attempted = True\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"ìµœì í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\")\n",
        "                optimization_attempted = False\n",
        "\n",
        "        # ê¸°ë³¸ ëª¨ë¸ ì¶”ê°€ (ìµœì í™” ì‹¤íŒ¨ ì‹œ ë˜ëŠ” í•­ìƒ í¬í•¨)\n",
        "        if not optimization_attempted or True:  # í•­ìƒ ê¸°ë³¸ ëª¨ë¸ë„ í¬í•¨\n",
        "            models['XGBoost'] = xgb.XGBClassifier(\n",
        "                n_estimators=100, random_state=42, max_depth=6,\n",
        "                learning_rate=0.1, use_label_encoder=False, eval_metric='logloss'\n",
        "            )\n",
        "            models['LightGBM'] = lgb.LGBMClassifier(\n",
        "                n_estimators=100, random_state=42, max_depth=6,\n",
        "                learning_rate=0.1, verbose=-1\n",
        "            )\n",
        "            if CATBOOST_AVAILABLE:\n",
        "                models['CatBoost'] = CatBoostClassifier(\n",
        "                    iterations=100, random_state=42, depth=6,\n",
        "                    learning_rate=0.1, verbose=False\n",
        "                )\n",
        "\n",
        "        # ì‹œê³„ì—´ ëª¨ë¸ ì¶”ê°€ (ì„ íƒì  - ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ë§Œ)\n",
        "        time_series_models = {}\n",
        "        time_series_attempted = 0\n",
        "\n",
        "        # ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„\n",
        "        if 'ë“±ë¡ì¼ì' in data.columns:\n",
        "            ts_data = prepare_time_series_data(data)\n",
        "\n",
        "            if len(ts_data) > 0:\n",
        "                # ë‹´ë‹¹ìë³„ ì‹œê³„ì—´ ëª¨ë¸ í•™ìŠµ\n",
        "                for manager in ts_data['ë‹´ë‹¹ì'].unique()[:5]:  # ìƒìœ„ 5ëª…ë§Œ\n",
        "                    manager_ts = ts_data[ts_data['ë‹´ë‹¹ì'] == manager]\n",
        "\n",
        "                    # LSTM ëª¨ë¸ (TensorFlow í•„ìš”)\n",
        "                    if TENSORFLOW_AVAILABLE and len(manager_ts) >= 30:\n",
        "                        try:\n",
        "                            lstm_model, lstm_scaler = train_lstm_for_manager(manager_ts)\n",
        "                            if lstm_model:\n",
        "                                time_series_models[f'LSTM_{manager}'] = {\n",
        "                                    'model': lstm_model,\n",
        "                                    'scaler': lstm_scaler,\n",
        "                                    'type': 'lstm'\n",
        "                                }\n",
        "                                time_series_attempted += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"LSTM ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ ({manager}): {str(e)}\")\n",
        "\n",
        "                    # ARIMA ëª¨ë¸ (statsmodels í•„ìš”)\n",
        "                    if STATSMODELS_AVAILABLE and len(manager_ts) >= 30:\n",
        "                        try:\n",
        "                            arima_model = train_arima_for_manager(manager_ts)\n",
        "                            if arima_model:\n",
        "                                time_series_models[f'ARIMA_{manager}'] = {\n",
        "                                    'model': arima_model,\n",
        "                                    'type': 'arima'\n",
        "                                }\n",
        "                                time_series_attempted += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"ARIMA ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ ({manager}): {str(e)}\")\n",
        "\n",
        "                    # Prophet ëª¨ë¸ (prophet í•„ìš”)\n",
        "                    if PROPHET_AVAILABLE and len(manager_ts) >= 30:\n",
        "                        try:\n",
        "                            prophet_model = train_prophet_for_manager(manager_ts)\n",
        "                            if prophet_model:\n",
        "                                time_series_models[f'Prophet_{manager}'] = {\n",
        "                                    'model': prophet_model,\n",
        "                                    'type': 'prophet'\n",
        "                                }\n",
        "                                time_series_attempted += 1\n",
        "                        except Exception as e:\n",
        "                            print(f\"Prophet ëª¨ë¸ í•™ìŠµ ì‹¤íŒ¨ ({manager}): {str(e)}\")\n",
        "\n",
        "        results = {}\n",
        "        best_score = -1\n",
        "        best_model = None\n",
        "        best_model_name = None\n",
        "        ensemble_models = []\n",
        "\n",
        "        result_text = f\"ğŸ¤– ê³ ê¸‰ ëª¨ë¸ í•™ìŠµ ê²°ê³¼ (í•™ìŠµ ë°ì´í„°: {len(X)}ê±´):\\n\" + \"=\"*50 + \"\\n\\n\"\n",
        "\n",
        "        # ëª¨ë¸ í•™ìŠµ ë° í‰ê°€\n",
        "        result_text += \"ğŸ“Š ë¨¸ì‹ ëŸ¬ë‹ ëª¨ë¸ ì„±ëŠ¥:\\n\"\n",
        "        for name, model in models.items():\n",
        "            try:\n",
        "                model.fit(X_train_selected, y_train_balanced)\n",
        "                y_pred = model.predict(X_test_selected)\n",
        "                y_pred_proba = model.predict_proba(X_test_selected)[:, 1]\n",
        "\n",
        "                # ë‹¤ì–‘í•œ ë©”íŠ¸ë¦­ ê³„ì‚°\n",
        "                roc_auc = roc_auc_score(y_test, y_pred_proba)\n",
        "                f1 = f1_score(y_test, y_pred)\n",
        "                precision = precision_score(y_test, y_pred)\n",
        "                recall = recall_score(y_test, y_pred)\n",
        "\n",
        "                results[name] = {\n",
        "                    'model': model,\n",
        "                    'roc_auc': roc_auc,\n",
        "                    'f1_score': f1,\n",
        "                    'precision': precision,\n",
        "                    'recall': recall,\n",
        "                    'predictions': y_pred_proba,\n",
        "                    'y_test': y_test,\n",
        "                    'type': 'ml'\n",
        "                }\n",
        "\n",
        "                result_text += f\"  - {name}:\\n\"\n",
        "                result_text += f\"    â€¢ ROC-AUC: {roc_auc:.4f}\\n\"\n",
        "                result_text += f\"    â€¢ F1-Score: {f1:.4f}\\n\"\n",
        "                result_text += f\"    â€¢ Precision: {precision:.4f}\\n\"\n",
        "                result_text += f\"    â€¢ Recall: {recall:.4f}\\n\"\n",
        "\n",
        "                if roc_auc > best_score:\n",
        "                    best_score = roc_auc\n",
        "                    best_model = model\n",
        "                    best_model_name = name\n",
        "\n",
        "                # ì•™ìƒë¸”ì— í¬í•¨í•  ëª¨ë¸ ì„ íƒ (ROC-AUC > 0.6)\n",
        "                if roc_auc > 0.6:\n",
        "                    ensemble_models.append((name, model))\n",
        "\n",
        "            except Exception as e:\n",
        "                result_text += f\"  âŒ {name} í•™ìŠµ ì‹¤íŒ¨: {str(e)}\\n\"\n",
        "\n",
        "        # ì•™ìƒë¸” ëª¨ë¸ ìƒì„± (3ê°œ ì´ìƒì˜ ëª¨ë¸ì´ ì„±ê³µí•œ ê²½ìš°)\n",
        "        if len(ensemble_models) >= 2:  # ê¸°ì¤€ì„ 3ê°œì—ì„œ 2ê°œë¡œ ë‚®ì¶¤\n",
        "            try:\n",
        "                voting_clf = VotingClassifier(\n",
        "                    estimators=ensemble_models,\n",
        "                    voting='soft'\n",
        "                )\n",
        "                voting_clf.fit(X_train_selected, y_train_balanced)\n",
        "                y_pred_ensemble = voting_clf.predict_proba(X_test_selected)[:, 1]\n",
        "                ensemble_auc = roc_auc_score(y_test, y_pred_ensemble)\n",
        "\n",
        "                results['Ensemble'] = {\n",
        "                    'model': voting_clf,\n",
        "                    'roc_auc': ensemble_auc,\n",
        "                    'predictions': y_pred_ensemble,\n",
        "                    'y_test': y_test,\n",
        "                    'type': 'ensemble'\n",
        "                }\n",
        "\n",
        "                result_text += f\"\\nğŸ¯ ì•™ìƒë¸” ëª¨ë¸ (ìƒìœ„ {len(ensemble_models)}ê°œ ê²°í•©):\\n\"\n",
        "                result_text += f\"  - ROC-AUC: {ensemble_auc:.4f}\\n\"\n",
        "\n",
        "                if ensemble_auc > best_score:\n",
        "                    best_score = ensemble_auc\n",
        "                    best_model = voting_clf\n",
        "                    best_model_name = 'Ensemble'\n",
        "                    app_state.ensemble_model = voting_clf\n",
        "\n",
        "            except Exception as e:\n",
        "                result_text += f\"\\nâš ï¸ ì•™ìƒë¸” ìƒì„± ì‹¤íŒ¨: {str(e)}\\n\"\n",
        "\n",
        "        # ì‹œê³„ì—´ ëª¨ë¸ ê²°ê³¼ ì¶”ê°€\n",
        "        if time_series_models:\n",
        "            result_text += \"\\nğŸ“ˆ ì‹œê³„ì—´ ì „ë¬¸ ëª¨ë¸:\\n\"\n",
        "            for name, model_info in time_series_models.items():\n",
        "                result_text += f\"  - {name}: í•™ìŠµ ì™„ë£Œ\\n\"\n",
        "                results[name] = model_info\n",
        "\n",
        "        if best_model is None:\n",
        "            return {}, \"âŒ ëª¨ë“  ëª¨ë¸ í•™ìŠµì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.\"\n",
        "\n",
        "        result_text += f\"\\nğŸ† ìµœê³  ì„±ëŠ¥ ëª¨ë¸: {best_model_name} (ROC-AUC: {best_score:.4f})\\n\"\n",
        "\n",
        "        # í”¼ì²˜ ì¤‘ìš”ë„\n",
        "        if hasattr(best_model, 'feature_importances_'):\n",
        "            feature_importance = pd.DataFrame({\n",
        "                'feature': selected_features,\n",
        "                'importance': best_model.feature_importances_\n",
        "            }).sort_values('importance', ascending=False).head(10)\n",
        "\n",
        "            result_text += \"\\nğŸ“Š ìƒìœ„ 10ê°œ ì¤‘ìš” í”¼ì²˜:\\n\"\n",
        "            for _, row in feature_importance.iterrows():\n",
        "                result_text += f\"  - {row['feature']}: {row['importance']:.4f}\\n\"\n",
        "\n",
        "        # ì‹œê³„ì—´ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€\n",
        "        if time_series_models:\n",
        "            result_text += f\"\\nğŸ”® ì‹œê³„ì—´ ëª¨ë¸ {len(time_series_models)}ê°œ ì¶”ê°€ í•™ìŠµ ì™„ë£Œ!\"\n",
        "            result_text += \"\\n   (ì‚¬ìš© ê°€ëŠ¥: \"\n",
        "            model_types = set([info['type'] for info in time_series_models.values()])\n",
        "            result_text += \", \".join([t.upper() for t in model_types]) + \")\"\n",
        "        else:\n",
        "            result_text += \"\\nğŸ“Š ì‹œê³„ì—´ ëª¨ë¸ì€ ì‚¬ìš©í•  ìˆ˜ ì—†ì§€ë§Œ, ML ëª¨ë¸ë¡œ ì¶©ë¶„í•œ ì˜ˆì¸¡ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.\"\n",
        "\n",
        "        result_text += \"\\n\\nâœ… ê³ ê¸‰ ëª¨ë¸ í•™ìŠµ ì™„ë£Œ!\"\n",
        "\n",
        "        # ìƒíƒœ ì €ì¥\n",
        "        app_state.best_model = best_model\n",
        "        app_state.best_model_name = best_model_name\n",
        "        app_state.feature_names = selected_features\n",
        "        app_state.encoders = encoders\n",
        "        app_state.model_results = results\n",
        "        app_state.time_series_models = time_series_models if time_series_models else {}\n",
        "        app_state.is_model_trained = True\n",
        "\n",
        "        # ë‹´ë‹¹ìë³„ ì„±ê³¼ ì¬ê³„ì‚° (í•„í„°ë§ëœ ë°ì´í„° ê¸°ì¤€)\n",
        "        manager_stats = data[data['ë‹´ë‹¹ìëª…'] != 'ë¯¸ë°°ì •'].groupby('ë‹´ë‹¹ìëª…').agg({\n",
        "            'is_approved': ['count', 'sum', 'mean'],\n",
        "            'ì ‘ì´‰íšŸìˆ˜': 'mean'\n",
        "        }).round(3)\n",
        "\n",
        "        if len(manager_stats) > 0:\n",
        "            manager_stats.columns = ['ì´_ë¦¬ë“œìˆ˜', 'ìŠ¹ì¸ì™„ë£Œìˆ˜', 'ìŠ¹ì¸ì™„ë£Œìœ¨', 'í‰ê· _ì ‘ì´‰íšŸìˆ˜']\n",
        "            manager_stats = manager_stats.reset_index()\n",
        "            app_state.manager_performance = manager_stats\n",
        "\n",
        "        return results, result_text\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        error_message = f\"âŒ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\\n{str(e)}\\n\\n\"\n",
        "\n",
        "        # ë” ìì„¸í•œ ì˜¤ë¥˜ ì •ë³´ ì œê³µ\n",
        "        if \"No trials are completed\" in str(e):\n",
        "            error_message += \"ğŸ’¡ í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. ê¸°ë³¸ ëª¨ë¸ë¡œ ì¬ì‹œë„ ì¤‘...\\n\"\n",
        "\n",
        "            # ê¸°ë³¸ ëª¨ë¸ë¡œ ì¬ì‹œë„\n",
        "            try:\n",
        "                # ê°„ë‹¨í•œ ëª¨ë¸ë¡œ ì¬ì‹œë„\n",
        "                simple_model = RandomForestClassifier(n_estimators=50, random_state=42, max_depth=5)\n",
        "                simple_model.fit(X_train[:, :min(10, X_train.shape[1])], y_train)  # í”¼ì²˜ ìˆ˜ ì œí•œ\n",
        "\n",
        "                app_state.best_model = simple_model\n",
        "                app_state.best_model_name = \"Random Forest (Basic)\"\n",
        "                app_state.is_model_trained = True\n",
        "\n",
        "                return {\"Random Forest (Basic)\": {'model': simple_model}}, \"âœ… ê¸°ë³¸ ëª¨ë¸ë¡œ í•™ìŠµ ì™„ë£Œ!\"\n",
        "\n",
        "            except Exception as e2:\n",
        "                error_message += f\"\\nê¸°ë³¸ ëª¨ë¸ í•™ìŠµë„ ì‹¤íŒ¨: {str(e2)}\"\n",
        "\n",
        "        return {}, error_message\n",
        "\n",
        "# ================================================================================\n",
        "# 10. ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ (ê¸°ì¡´ ì½”ë“œ ì¬ì‚¬ìš©)\n",
        "# ================================================================================\n",
        "\n",
        "# ê¸°ì¡´ ì½”ë“œì˜ ë‚˜ë¨¸ì§€ í•¨ìˆ˜ë“¤ì„ ê·¸ëŒ€ë¡œ í¬í•¨\n",
        "# - prepare_time_series_data\n",
        "# - build_lstm_model (advanced ë²„ì „ìœ¼ë¡œ ëŒ€ì²´ë¨)\n",
        "# - train_lstm_for_manager\n",
        "# - train_arima_for_manager\n",
        "# - filter_data_by_date\n",
        "# - create_time_series_prediction\n",
        "# - train_prediction_model\n",
        "# - predict_manager_performance\n",
        "# - optimize_lead_assignment\n",
        "# - create_gradio_interface\n",
        "\n",
        "def prepare_time_series_data(data: pd.DataFrame) -> pd.DataFrame:\n",
        "    \"\"\"ì‹œê³„ì—´ ëª¨ë¸ì„ ìœ„í•œ ë°ì´í„° ì¤€ë¹„\"\"\"\n",
        "    try:\n",
        "        if 'ë“±ë¡ì¼ì' not in data.columns:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # ì¼ë³„ ìŠ¹ì¸ìœ¨ ì§‘ê³„\n",
        "        daily_stats = data.groupby([pd.Grouper(key='ë“±ë¡ì¼ì', freq='D'), 'ë‹´ë‹¹ìëª…']).agg({\n",
        "            'is_approved': ['count', 'sum', 'mean']\n",
        "        }).reset_index()\n",
        "\n",
        "        daily_stats.columns = ['ë‚ ì§œ', 'ë‹´ë‹¹ì', 'ë¦¬ë“œìˆ˜', 'ìŠ¹ì¸ìˆ˜', 'ìŠ¹ì¸ìœ¨']\n",
        "        daily_stats = daily_stats[daily_stats['ë¦¬ë“œìˆ˜'] > 0]  # ë¦¬ë“œê°€ ìˆëŠ” ë‚ ë§Œ\n",
        "\n",
        "        # ì‹œê³„ì—´ í”¼ì²˜ ì¶”ê°€\n",
        "        daily_stats['ìš”ì¼'] = daily_stats['ë‚ ì§œ'].dt.dayofweek\n",
        "        daily_stats['ì›”'] = daily_stats['ë‚ ì§œ'].dt.month\n",
        "        daily_stats['ë¶„ê¸°'] = daily_stats['ë‚ ì§œ'].dt.quarter\n",
        "\n",
        "        return daily_stats\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„ ì˜¤ë¥˜: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "def train_lstm_for_manager(manager_data: pd.DataFrame, sequence_length: int = 7) -> Tuple[keras.Model, StandardScaler]:\n",
        "    \"\"\"ë‹´ë‹¹ìë³„ LSTM ëª¨ë¸ í•™ìŠµ (ê°œì„ ëœ ë²„ì „)\"\"\"\n",
        "    if not TENSORFLOW_AVAILABLE:\n",
        "        return None, None\n",
        "\n",
        "    try:\n",
        "        # ë°ì´í„° ì¤€ë¹„\n",
        "        data = manager_data.sort_values('ë‚ ì§œ')\n",
        "\n",
        "        # íŠ¹ì„±ê³¼ íƒ€ê²Ÿ ë¶„ë¦¬\n",
        "        features = ['ë¦¬ë“œìˆ˜', 'ìŠ¹ì¸ìˆ˜', 'ìš”ì¼', 'ì›”']\n",
        "        X = data[features].values\n",
        "        y = data['ìŠ¹ì¸ìœ¨'].values\n",
        "\n",
        "        # ì •ê·œí™”\n",
        "        scaler = StandardScaler()\n",
        "        X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "        # ì‹œí€€ìŠ¤ ìƒì„±\n",
        "        X_seq, y_seq = [], []\n",
        "        for i in range(len(X_scaled) - sequence_length):\n",
        "            X_seq.append(X_scaled[i:i+sequence_length])\n",
        "            y_seq.append(y[i+sequence_length])\n",
        "\n",
        "        X_seq = np.array(X_seq)\n",
        "        y_seq = np.array(y_seq)\n",
        "\n",
        "        if len(X_seq) < 10:  # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ í•™ìŠµ ë¶ˆê°€\n",
        "            return None, None\n",
        "\n",
        "        # ëª¨ë¸ êµ¬ì¶• ë° í•™ìŠµ\n",
        "        model = build_advanced_lstm_model((sequence_length, len(features)))\n",
        "\n",
        "        # ì½œë°± ì„¤ì •\n",
        "        early_stop = EarlyStopping(\n",
        "            monitor='loss',\n",
        "            patience=20,\n",
        "            restore_best_weights=True\n",
        "        )\n",
        "\n",
        "        reduce_lr = ReduceLROnPlateau(\n",
        "            monitor='loss',\n",
        "            factor=0.5,\n",
        "            patience=10,\n",
        "            min_lr=0.0001\n",
        "        )\n",
        "\n",
        "        # í•™ìŠµ\n",
        "        model.fit(\n",
        "            X_seq, y_seq,\n",
        "            epochs=100,\n",
        "            batch_size=16,\n",
        "            verbose=0,\n",
        "            callbacks=[early_stop, reduce_lr],\n",
        "            validation_split=0.2\n",
        "        )\n",
        "\n",
        "        return model, scaler\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"LSTM í•™ìŠµ ì˜¤ë¥˜: {str(e)}\")\n",
        "        return None, None\n",
        "\n",
        "def train_arima_for_manager(manager_data: pd.DataFrame) -> Any:\n",
        "    \"\"\"ë‹´ë‹¹ìë³„ ARIMA ëª¨ë¸ í•™ìŠµ\"\"\"\n",
        "    if not STATSMODELS_AVAILABLE:\n",
        "        return None\n",
        "\n",
        "    try:\n",
        "        # ì‹œê³„ì—´ ë°ì´í„° ì¤€ë¹„\n",
        "        ts_data = manager_data.set_index('ë‚ ì§œ')['ìŠ¹ì¸ìœ¨']\n",
        "        ts_data = ts_data.asfreq('D').ffill()  # ì¼ë³„ ì£¼ê¸°ë¡œ ë³€í™˜\n",
        "\n",
        "        if len(ts_data) < 30:  # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ í•™ìŠµ ë¶ˆê°€\n",
        "            return None\n",
        "\n",
        "        # Auto ARIMAë¡œ ìµœì  íŒŒë¼ë¯¸í„° ì°¾ê¸°\n",
        "        try:\n",
        "            model = pm.auto_arima(\n",
        "                ts_data,\n",
        "                seasonal=True,\n",
        "                m=7,  # ì£¼ê°„ ê³„ì ˆì„±\n",
        "                stepwise=True,\n",
        "                suppress_warnings=True,\n",
        "                error_action='ignore',\n",
        "                max_p=3,\n",
        "                max_q=3,\n",
        "                max_order=5,\n",
        "                trace=False,  # ì§„í–‰ ìƒí™© ì¶œë ¥ ì•ˆí•¨\n",
        "                n_jobs=1  # ë‹¨ì¼ ìŠ¤ë ˆë“œ ì‚¬ìš©\n",
        "            )\n",
        "        except:\n",
        "            # Auto ARIMA ì‹¤íŒ¨ ì‹œ ë‹¨ìˆœ ARIMA ì‹œë„\n",
        "            from statsmodels.tsa.arima.model import ARIMA\n",
        "            model = ARIMA(ts_data, order=(1,1,1))\n",
        "            model = model.fit()\n",
        "\n",
        "        return model\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ARIMA í•™ìŠµ ì˜¤ë¥˜ ({manager_data['ë‹´ë‹¹ì'].iloc[0] if len(manager_data) > 0 else 'ì•Œ ìˆ˜ ì—†ìŒ'}): {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def filter_data_by_date(start_date: pd.Timestamp, end_date: pd.Timestamp) -> pd.DataFrame:\n",
        "    \"\"\"ì§€ì •ëœ ë‚ ì§œ ë²”ìœ„ì˜ ë°ì´í„°ë§Œ í•„í„°ë§\"\"\"\n",
        "    try:\n",
        "        if app_state.processed_data is None:\n",
        "            return None\n",
        "\n",
        "        data = app_state.processed_data.copy()\n",
        "\n",
        "        # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆëŠ” ê²½ìš°ë§Œ í•„í„°ë§\n",
        "        if 'ë“±ë¡ì¼ì' in data.columns:\n",
        "            # ë‚ ì§œ í˜•ì‹ í™•ì¸ ë° ë³€í™˜\n",
        "            if not pd.api.types.is_datetime64_any_dtype(data['ë“±ë¡ì¼ì']):\n",
        "                data['ë“±ë¡ì¼ì'] = pd.to_datetime(data['ë“±ë¡ì¼ì'], errors='coerce')\n",
        "\n",
        "            # ë‚ ì§œ ë²”ìœ„ë¡œ í•„í„°ë§\n",
        "            mask = (data['ë“±ë¡ì¼ì'] >= start_date) & (data['ë“±ë¡ì¼ì'] <= end_date)\n",
        "            filtered_data = data[mask]\n",
        "\n",
        "            print(f\"ë‚ ì§œ í•„í„°ë§: {start_date.date()} ~ {end_date.date()}\")\n",
        "            print(f\"í•„í„°ë§ ì „: {len(data)}ê±´ â†’ í•„í„°ë§ í›„: {len(filtered_data)}ê±´\")\n",
        "\n",
        "            return filtered_data\n",
        "        else:\n",
        "            # ë‚ ì§œ ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì „ì²´ ë°ì´í„° ë°˜í™˜\n",
        "            return data\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ë‚ ì§œ í•„í„°ë§ ì˜¤ë¥˜: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def create_time_series_prediction(start_date: pd.Timestamp, days: int) -> go.Figure:\n",
        "    \"\"\"ì‹œê³„ì—´ ì˜ˆì¸¡ ê·¸ë˜í”„ ìƒì„± (ê°œì„ ëœ ë²„ì „)\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_model_trained or app_state.manager_performance is None:\n",
        "            return None\n",
        "\n",
        "        # ì˜ˆì¸¡ ë‚ ì§œ ë²”ìœ„ ìƒì„±\n",
        "        date_range = pd.date_range(start=start_date, periods=days, freq='D')\n",
        "\n",
        "        # ë‹´ë‹¹ìë³„ ì˜ˆì¸¡ ë°ì´í„° ìƒì„±\n",
        "        predictions_by_date = []\n",
        "\n",
        "        # ê° ë‹´ë‹¹ìì˜ ì¼ì¼ í‰ê·  ë¦¬ë“œ ìˆ˜ ê³„ì‚°\n",
        "        manager_daily_leads = {}\n",
        "        for _, manager_row in app_state.manager_performance.head(5).iterrows():\n",
        "            manager = manager_row['ë‹´ë‹¹ìëª…']\n",
        "            daily_avg = manager_row['ì´_ë¦¬ë“œìˆ˜'] / 30\n",
        "            manager_daily_leads[manager] = daily_avg\n",
        "\n",
        "        # ì‹œê³„ì—´ ëª¨ë¸ ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸\n",
        "        use_time_series = len(app_state.time_series_models) > 0\n",
        "\n",
        "        for date in date_range:\n",
        "            for _, manager_row in app_state.manager_performance.head(5).iterrows():\n",
        "                manager = manager_row['ë‹´ë‹¹ìëª…']\n",
        "\n",
        "                # ì‹œê³„ì—´ ëª¨ë¸ ìš°ì„  ì‚¬ìš©\n",
        "                pred_proba = None\n",
        "                model_used = \"ML\"\n",
        "                confidence = 0.8  # ê¸°ë³¸ ì‹ ë¢°ë„\n",
        "\n",
        "                # Prophet ëª¨ë¸ í™•ì¸ (ìµœìš°ì„ )\n",
        "                prophet_key = f'Prophet_{manager}'\n",
        "                if use_time_series and prophet_key in app_state.time_series_models:\n",
        "                    try:\n",
        "                        prophet_model = app_state.time_series_models[prophet_key]['model']\n",
        "                        future = prophet_model.make_future_dataframe(periods=1)\n",
        "                        forecast = prophet_model.predict(future)\n",
        "                        pred_proba = forecast['yhat'].iloc[-1]\n",
        "                        pred_proba = max(0, min(1, pred_proba))\n",
        "                        model_used = \"Prophet\"\n",
        "                        confidence = 0.9\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # LSTM ëª¨ë¸ í™•ì¸\n",
        "                lstm_key = f'LSTM_{manager}'\n",
        "                if pred_proba is None and use_time_series and lstm_key in app_state.time_series_models:\n",
        "                    try:\n",
        "                        lstm_info = app_state.time_series_models[lstm_key]\n",
        "                        lstm_model = lstm_info['model']\n",
        "                        lstm_scaler = lstm_info['scaler']\n",
        "\n",
        "                        # ìµœê·¼ 7ì¼ ë°ì´í„° ì¤€ë¹„ (ì‹œë®¬ë ˆì´ì…˜)\n",
        "                        recent_features = np.array([\n",
        "                            [manager_daily_leads[manager],\n",
        "                             manager_daily_leads[manager] * manager_row['ìŠ¹ì¸ì™„ë£Œìœ¨'],\n",
        "                             date.dayofweek,\n",
        "                             date.month]\n",
        "                        ])\n",
        "\n",
        "                        recent_scaled = lstm_scaler.transform(recent_features)\n",
        "                        sequence = np.tile(recent_scaled, (7, 1)).reshape(1, 7, -1)\n",
        "\n",
        "                        pred_proba = lstm_model.predict(sequence)[0, 0]\n",
        "                        model_used = \"LSTM\"\n",
        "                        confidence = 0.85\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # ARIMA ëª¨ë¸ í™•ì¸\n",
        "                arima_key = f'ARIMA_{manager}'\n",
        "                if pred_proba is None and use_time_series and arima_key in app_state.time_series_models:\n",
        "                    try:\n",
        "                        arima_model = app_state.time_series_models[arima_key]['model']\n",
        "                        # ARIMA ì˜ˆì¸¡ (1ì¼ ì•)\n",
        "                        forecast = arima_model.forecast(steps=1)\n",
        "                        pred_proba = forecast[0]\n",
        "                        pred_proba = max(0, min(1, pred_proba))  # 0-1 ë²”ìœ„ë¡œ ì œí•œ\n",
        "                        model_used = \"ARIMA\"\n",
        "                        confidence = 0.8\n",
        "                    except:\n",
        "                        pass\n",
        "\n",
        "                # ê¸°ë³¸ ML ëª¨ë¸ ì‚¬ìš©\n",
        "                if pred_proba is None:\n",
        "                    # ë” ë§ì€ í”¼ì²˜ ì‚¬ìš©\n",
        "                    sample_data = app_state.processed_data[\n",
        "                        app_state.processed_data['ë‹´ë‹¹ìëª…'] == manager\n",
        "                    ].mean(numeric_only=True).to_dict()\n",
        "\n",
        "                    # ë‚ ì§œ ê´€ë ¨ í”¼ì²˜ ì—…ë°ì´íŠ¸\n",
        "                    sample_data.update({\n",
        "                        'ë“±ë¡_ì›”': date.month,\n",
        "                        'ë“±ë¡_ì¼': date.day,\n",
        "                        'ë“±ë¡_ìš”ì¼': date.dayofweek,\n",
        "                        'ë“±ë¡_ì‹œê°„': 14,\n",
        "                        'ë‹´ë‹¹ìëª…': manager\n",
        "                    })\n",
        "\n",
        "                    sample_df = pd.DataFrame([sample_data])\n",
        "\n",
        "                    # ì¸ì½”ë”©\n",
        "                    for col, encoder in app_state.encoders.items():\n",
        "                        if col in sample_df.columns:\n",
        "                            try:\n",
        "                                sample_df[f'{col}_encoded'] = encoder.transform(sample_df[col])\n",
        "                            except:\n",
        "                                sample_df[f'{col}_encoded'] = 0\n",
        "\n",
        "                    # í”¼ì²˜ ì„ íƒ ë° ìŠ¤ì¼€ì¼ë§\n",
        "                    try:\n",
        "                        X_pred = sample_df[app_state.feature_names].fillna(0)\n",
        "                        if app_state.scaler:\n",
        "                            X_pred = app_state.scaler.transform(X_pred)\n",
        "                        if app_state.feature_selector:\n",
        "                            X_pred = app_state.feature_selector.transform(X_pred)\n",
        "\n",
        "                        pred_proba = app_state.best_model.predict_proba(X_pred)[0, 1]\n",
        "                        confidence = 0.7\n",
        "                    except:\n",
        "                        pred_proba = manager_row['ìŠ¹ì¸ì™„ë£Œìœ¨']\n",
        "                        confidence = 0.6\n",
        "\n",
        "                # ì˜ˆìƒ ìŠ¹ì¸ìˆ˜ ê³„ì‚°\n",
        "                daily_leads = manager_daily_leads[manager]\n",
        "                expected_approvals = daily_leads * pred_proba\n",
        "\n",
        "                # ì‹ ë¢° êµ¬ê°„ ê³„ì‚°\n",
        "                std_dev = expected_approvals * 0.1 * (1 - confidence)\n",
        "                lower_bound = max(0, expected_approvals - 1.96 * std_dev)\n",
        "                upper_bound = expected_approvals + 1.96 * std_dev\n",
        "\n",
        "                predictions_by_date.append({\n",
        "                    'ë‚ ì§œ': date,\n",
        "                    'ë‹´ë‹¹ì': manager,\n",
        "                    'ì˜ˆìƒ_ìŠ¹ì¸ìˆ˜': expected_approvals,\n",
        "                    'ì˜ˆìƒ_ìŠ¹ì¸ìœ¨': pred_proba,\n",
        "                    'ì˜ˆìƒ_ë¦¬ë“œìˆ˜': daily_leads,\n",
        "                    'ëª¨ë¸': model_used,\n",
        "                    'ì‹ ë¢°ë„': confidence,\n",
        "                    'í•˜í•œ': lower_bound,\n",
        "                    'ìƒí•œ': upper_bound\n",
        "                })\n",
        "\n",
        "        # DataFrame ë³€í™˜\n",
        "        pred_df = pd.DataFrame(predictions_by_date)\n",
        "\n",
        "        # ì‹œê³„ì—´ ê·¸ë˜í”„ ìƒì„±\n",
        "        fig = make_subplots(\n",
        "            rows=4, cols=1,\n",
        "            subplot_titles=(\n",
        "                f'{days}ì¼ê°„ ë‹´ë‹¹ìë³„ ì˜ˆìƒ ìŠ¹ì¸ìˆ˜ (95% ì‹ ë¢°êµ¬ê°„)',\n",
        "                'ì¼ë³„ ì „ì²´ ì˜ˆìƒ ìŠ¹ì¸ìˆ˜',\n",
        "                'ëª¨ë¸ë³„ ì˜ˆì¸¡ ê¸°ì—¬ë„',\n",
        "                'ì˜ˆì¸¡ ì‹ ë¢°ë„ ë¶„í¬'\n",
        "            ),\n",
        "            row_heights=[0.4, 0.25, 0.15, 0.2],\n",
        "            vertical_spacing=0.12\n",
        "        )\n",
        "\n",
        "        # 1. ë‹´ë‹¹ìë³„ ì˜ˆìƒ ìŠ¹ì¸ìˆ˜ ì¶”ì´ (ì‹ ë¢°êµ¬ê°„ í¬í•¨)\n",
        "        for manager in pred_df['ë‹´ë‹¹ì'].unique():\n",
        "            manager_data = pred_df[pred_df['ë‹´ë‹¹ì'] == manager]\n",
        "\n",
        "            # ì£¼ ì¶”ì„¸ì„ \n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=manager_data['ë‚ ì§œ'],\n",
        "                    y=manager_data['ì˜ˆìƒ_ìŠ¹ì¸ìˆ˜'],\n",
        "                    name=f\"{manager}\",\n",
        "                    mode='lines+markers',\n",
        "                    hovertemplate='%{y:.1f}ê±´<br>ìŠ¹ì¸ìœ¨: %{customdata:.1%}',\n",
        "                    customdata=manager_data['ì˜ˆìƒ_ìŠ¹ì¸ìœ¨']\n",
        "                ),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "            # ì‹ ë¢°êµ¬ê°„\n",
        "            fig.add_trace(\n",
        "                go.Scatter(\n",
        "                    x=manager_data['ë‚ ì§œ'].tolist() + manager_data['ë‚ ì§œ'].tolist()[::-1],\n",
        "                    y=manager_data['ìƒí•œ'].tolist() + manager_data['í•˜í•œ'].tolist()[::-1],\n",
        "                    fill='toself',\n",
        "                    fillcolor=f'rgba(0,100,200,0.1)',\n",
        "                    line=dict(color='rgba(255,255,255,0)'),\n",
        "                    hoverinfo=\"skip\",\n",
        "                    showlegend=False,\n",
        "                    name=f'{manager}_ì‹ ë¢°êµ¬ê°„'\n",
        "                ),\n",
        "                row=1, col=1\n",
        "            )\n",
        "\n",
        "        # 2. ì „ì²´ ì˜ˆìƒ ìŠ¹ì¸ìˆ˜\n",
        "        daily_total = pred_df.groupby('ë‚ ì§œ').agg({\n",
        "            'ì˜ˆìƒ_ìŠ¹ì¸ìˆ˜': 'sum',\n",
        "            'í•˜í•œ': 'sum',\n",
        "            'ìƒí•œ': 'sum'\n",
        "        }).reset_index()\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=daily_total['ë‚ ì§œ'],\n",
        "                y=daily_total['ì˜ˆìƒ_ìŠ¹ì¸ìˆ˜'],\n",
        "                name='ì „ì²´ ìŠ¹ì¸ìˆ˜',\n",
        "                marker_color='lightblue',\n",
        "                hovertemplate='%{y:.0f}ê±´',\n",
        "                error_y=dict(\n",
        "                    type='data',\n",
        "                    symmetric=False,\n",
        "                    array=daily_total['ìƒí•œ'] - daily_total['ì˜ˆìƒ_ìŠ¹ì¸ìˆ˜'],\n",
        "                    arrayminus=daily_total['ì˜ˆìƒ_ìŠ¹ì¸ìˆ˜'] - daily_total['í•˜í•œ']\n",
        "                ),\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # 3. ëª¨ë¸ë³„ ì‚¬ìš© ë¹„ìœ¨\n",
        "        model_counts = pred_df['ëª¨ë¸'].value_counts()\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=model_counts.index,\n",
        "                y=model_counts.values,\n",
        "                name='ëª¨ë¸ ì‚¬ìš© íšŸìˆ˜',\n",
        "                marker_color=['darkgreen' if 'Prophet' in x else\n",
        "                             'green' if 'LSTM' in x else\n",
        "                             'orange' if 'ARIMA' in x else\n",
        "                             'blue'\n",
        "                             for x in model_counts.index],\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=3, col=1\n",
        "        )\n",
        "\n",
        "        # 4. ì‹ ë¢°ë„ ë¶„í¬\n",
        "        confidence_by_model = pred_df.groupby('ëª¨ë¸')['ì‹ ë¢°ë„'].mean().sort_values(ascending=False)\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=confidence_by_model.index,\n",
        "                y=confidence_by_model.values,\n",
        "                name='í‰ê·  ì‹ ë¢°ë„',\n",
        "                marker_color='lightcoral',\n",
        "                text=confidence_by_model.values.round(2),\n",
        "                textposition='outside',\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=4, col=1\n",
        "        )\n",
        "\n",
        "        # ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
        "        fig.update_layout(\n",
        "            height=1000,\n",
        "            showlegend=True,\n",
        "            legend=dict(\n",
        "                orientation=\"h\",\n",
        "                yanchor=\"bottom\",\n",
        "                y=1.02,\n",
        "                xanchor=\"right\",\n",
        "                x=1\n",
        "            ),\n",
        "            title_text=f\"ê³ ê¸‰ AI ì‹œê³„ì—´ ì˜ˆì¸¡ ê²°ê³¼ (Prophet/LSTM/ARIMA/ML ì•™ìƒë¸”)\"\n",
        "        )\n",
        "\n",
        "        # Yì¶• ì„¤ì •\n",
        "        fig.update_yaxes(title_text=\"ì˜ˆìƒ ìŠ¹ì¸ìˆ˜ (ê±´)\", row=1, col=1)\n",
        "        fig.update_yaxes(title_text=\"ì „ì²´ ìŠ¹ì¸ìˆ˜ (ê±´)\", row=2, col=1)\n",
        "        fig.update_yaxes(title_text=\"ì˜ˆì¸¡ íšŸìˆ˜\", row=3, col=1)\n",
        "        fig.update_yaxes(title_text=\"ì‹ ë¢°ë„\", row=4, col=1)\n",
        "        fig.update_xaxes(title_text=\"ë‚ ì§œ\", row=2, col=1)\n",
        "\n",
        "        # ì£¼ë§ êµ¬ë¶„ì„  ì¶”ê°€\n",
        "        for date in date_range:\n",
        "            if date.dayofweek in [5, 6]:\n",
        "                for row in [1, 2]:\n",
        "                    fig.add_vrect(\n",
        "                        x0=date,\n",
        "                        x1=date + pd.Timedelta(days=1),\n",
        "                        fillcolor=\"LightGray\",\n",
        "                        opacity=0.2,\n",
        "                        layer=\"below\",\n",
        "                        line_width=0,\n",
        "                        row=row, col=1\n",
        "                    )\n",
        "\n",
        "        # í‰ê· ì„  ì¶”ê°€\n",
        "        avg_total = daily_total['ì˜ˆìƒ_ìŠ¹ì¸ìˆ˜'].mean()\n",
        "        fig.add_hline(\n",
        "            y=avg_total,\n",
        "            line_dash=\"dash\",\n",
        "            line_color=\"red\",\n",
        "            annotation_text=f\"ì¼ í‰ê· : {avg_total:.0f}ê±´\",\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # ì˜ˆì¸¡ ìš”ì•½ ì •ë³´\n",
        "        total_expected = daily_total['ì˜ˆìƒ_ìŠ¹ì¸ìˆ˜'].sum()\n",
        "        model_usage = \", \".join([f\"{model}: {count}íšŒ\" for model, count in model_counts.items()])\n",
        "        avg_confidence = pred_df['ì‹ ë¢°ë„'].mean()\n",
        "\n",
        "        fig.add_annotation(\n",
        "            text=f\"<b>ì˜ˆì¸¡ ê¸°ê°„ ì´ ì˜ˆìƒ ìŠ¹ì¸ìˆ˜: {total_expected:,.0f}ê±´</b><br>\" +\n",
        "                 f\"ëª¨ë¸ ì‚¬ìš©: {model_usage}<br>\" +\n",
        "                 f\"í‰ê·  ì˜ˆì¸¡ ì‹ ë¢°ë„: {avg_confidence:.1%}\",\n",
        "            xref=\"paper\", yref=\"paper\",\n",
        "            x=0.5, y=-0.15,\n",
        "            showarrow=False,\n",
        "            font=dict(size=14)\n",
        "        )\n",
        "\n",
        "        return fig\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ì‹œê³„ì—´ ì˜ˆì¸¡ ê·¸ë˜í”„ ìƒì„± ì˜¤ë¥˜: {str(e)}\")\n",
        "        return None\n",
        "\n",
        "def train_prediction_model() -> Tuple[Dict, str]:\n",
        "    \"\"\"ë¦¬ë“œ ì „í™˜ ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ (ì‹œê³„ì—´ ëª¨ë¸ í¬í•¨)\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_preprocessed or app_state.processed_data is None:\n",
        "            return {}, \"âŒ ë¨¼ì € ë°ì´í„°ë¥¼ ì „ì²˜ë¦¬í•´ì£¼ì„¸ìš”.\"\n",
        "\n",
        "        # train_prediction_model_with_data í•¨ìˆ˜ í˜¸ì¶œ\n",
        "        return train_prediction_model_with_data(app_state.processed_data)\n",
        "\n",
        "    except Exception as e:\n",
        "        import traceback\n",
        "        error_details = traceback.format_exc()\n",
        "        return {}, f\"âŒ ëª¨ë¸ í•™ìŠµ ì¤‘ ì˜¤ë¥˜ ë°œìƒ:\\n{str(e)}\\n\\nìƒì„¸ ì˜¤ë¥˜:\\n{error_details}\"\n",
        "\n",
        "def predict_manager_performance(prediction_date: pd.Timestamp = None, prediction_days: int = 30) -> pd.DataFrame:\n",
        "    \"\"\"ë‹´ë‹¹ìë³„ ì˜ˆìƒ ìŠ¹ì¸ìœ¨ ì˜ˆì¸¡ (ë‚ ì§œ ê¸°ë°˜)\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_model_trained or app_state.best_model is None:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        if app_state.manager_performance is None or len(app_state.manager_performance) == 0:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # ì˜ˆì¸¡ ë‚ ì§œ ì„¤ì •\n",
        "        if prediction_date is None:\n",
        "            prediction_date = pd.Timestamp.now()\n",
        "\n",
        "        predictions = []\n",
        "\n",
        "        # ê° ë‹´ë‹¹ìë³„ë¡œ ì˜ˆì¸¡\n",
        "        for _, manager_row in app_state.manager_performance.iterrows():\n",
        "            manager = manager_row['ë‹´ë‹¹ìëª…']\n",
        "\n",
        "            if manager == 'ë¯¸ë°°ì •':\n",
        "                continue\n",
        "\n",
        "            # ë‹´ë‹¹ìì˜ í‰ê·  íŠ¹ì„± ì‚¬ìš©\n",
        "            manager_data = app_state.processed_data[app_state.processed_data['ë‹´ë‹¹ìëª…'] == manager]\n",
        "\n",
        "            if len(manager_data) == 0:\n",
        "                continue\n",
        "\n",
        "            # ì˜ˆì¸¡ ê¸°ê°„ ë™ì•ˆì˜ í‰ê·  ìŠ¹ì¸ìœ¨ ê³„ì‚°\n",
        "            daily_predictions = []\n",
        "\n",
        "            for days_ahead in range(0, prediction_days, 7):  # ì£¼ ë‹¨ìœ„ë¡œ ìƒ˜í”Œë§\n",
        "                future_date = prediction_date + pd.Timedelta(days=days_ahead)\n",
        "\n",
        "                # ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„ (ë” ë§ì€ í”¼ì²˜ ì‚¬ìš©)\n",
        "                sample_data = manager_data.mean(numeric_only=True).to_dict()\n",
        "\n",
        "                # ë‚ ì§œ ê´€ë ¨ í”¼ì²˜ ì—…ë°ì´íŠ¸\n",
        "                sample_data.update({\n",
        "                    'ë“±ë¡_ì›”': future_date.month,\n",
        "                    'ë“±ë¡_ì¼': future_date.day,\n",
        "                    'ë“±ë¡_ìš”ì¼': future_date.dayofweek,\n",
        "                    'ë“±ë¡_ì‹œê°„': 14,\n",
        "                    'ë‹´ë‹¹ìëª…': manager\n",
        "                })\n",
        "\n",
        "                # DataFrameìœ¼ë¡œ ë³€í™˜\n",
        "                sample_df = pd.DataFrame([sample_data])\n",
        "\n",
        "                # ì¸ì½”ë”©\n",
        "                for col, encoder in app_state.encoders.items():\n",
        "                    if col in sample_df.columns:\n",
        "                        try:\n",
        "                            sample_df[f'{col}_encoded'] = encoder.transform(sample_df[col])\n",
        "                        except:\n",
        "                            sample_df[f'{col}_encoded'] = 0\n",
        "\n",
        "                # í”¼ì²˜ ì„ íƒ ë° ìŠ¤ì¼€ì¼ë§\n",
        "                try:\n",
        "                    X_pred = sample_df[app_state.feature_names].fillna(0)\n",
        "                    if app_state.scaler:\n",
        "                        X_pred = app_state.scaler.transform(X_pred)\n",
        "                    if app_state.feature_selector:\n",
        "                        X_pred = app_state.feature_selector.transform(X_pred)\n",
        "\n",
        "                    pred_proba = app_state.best_model.predict_proba(X_pred)[0, 1]\n",
        "                    daily_predictions.append(pred_proba)\n",
        "                except:\n",
        "                    daily_predictions.append(0.5)\n",
        "\n",
        "            # í‰ê·  ì˜ˆì¸¡ ìŠ¹ì¸ìœ¨ ê³„ì‚°\n",
        "            avg_pred_proba = np.mean(daily_predictions) if daily_predictions else 0.5\n",
        "\n",
        "            # í˜„ì¬ ìŠ¹ì¸ê±´ìˆ˜ ê³„ì‚°\n",
        "            current_approval_count = int(manager_row['ìŠ¹ì¸ì™„ë£Œìˆ˜'])\n",
        "            total_leads = int(manager_row['ì´_ë¦¬ë“œìˆ˜'])\n",
        "\n",
        "            # ì˜ˆì¸¡ ê¸°ê°„ ë™ì•ˆì˜ ì˜ˆìƒ ë¦¬ë“œìˆ˜ (ì¼ì¼ í‰ê·  * ì˜ˆì¸¡ ì¼ìˆ˜)\n",
        "            daily_avg_leads = total_leads / 30  # í•œ ë‹¬ ê¸°ì¤€\n",
        "            expected_leads = int(daily_avg_leads * prediction_days)\n",
        "\n",
        "            # ì˜ˆì¸¡ ìŠ¹ì¸ê±´ìˆ˜ ê³„ì‚°\n",
        "            predicted_approval_count = int(avg_pred_proba * expected_leads)\n",
        "\n",
        "            predictions.append({\n",
        "                'ë‹´ë‹¹ì': manager,\n",
        "                'ì´ë¦¬ë“œìˆ˜': total_leads,\n",
        "                'í‰ê· ì ‘ì´‰íšŸìˆ˜': round(manager_row['í‰ê· _ì ‘ì´‰íšŸìˆ˜'], 1),\n",
        "                'í˜„ì¬ ìŠ¹ì¸ê±´': current_approval_count,\n",
        "                'í˜„ì¬ ìŠ¹ì¸ìœ¨': f\"{manager_row['ìŠ¹ì¸ì™„ë£Œìœ¨']:.1%}\",\n",
        "                'ì˜ˆì¸¡ ìŠ¹ì¸ê±´': predicted_approval_count,\n",
        "                'ì˜ˆì¸¡ ìŠ¹ì¸ìœ¨': f\"{avg_pred_proba:.1%}\",\n",
        "                'ì˜ˆì¸¡ ì •í™•ë„': f\"{(1 - abs(avg_pred_proba - manager_row['ìŠ¹ì¸ì™„ë£Œìœ¨'])):.1%}\"\n",
        "            })\n",
        "\n",
        "        if len(predictions) == 0:\n",
        "            return pd.DataFrame()\n",
        "\n",
        "        # ê²°ê³¼ ì •ë¦¬\n",
        "        result_df = pd.DataFrame(predictions)\n",
        "\n",
        "        # ì˜ˆì¸¡ ìŠ¹ì¸ìœ¨ ê¸°ì¤€ìœ¼ë¡œ ì •ë ¬\n",
        "        result_df['sort_key'] = result_df['ì˜ˆì¸¡ ìŠ¹ì¸ìœ¨'].str.rstrip('%').astype(float)\n",
        "        result_df = result_df.sort_values('sort_key', ascending=False).drop('sort_key', axis=1)\n",
        "\n",
        "        # ì˜ˆì¸¡ ê¸°ê°„ ì •ë³´ ì¶”ê°€ (ì²« í–‰ì—ë§Œ í‘œì‹œ)\n",
        "        if len(result_df) > 0:\n",
        "            result_df.loc[result_df.index[0], 'ì˜ˆì¸¡ê¸°ê°„'] = f\"{prediction_date.strftime('%Y-%m-%d')} ~ {(prediction_date + pd.Timedelta(days=prediction_days)).strftime('%Y-%m-%d')}\"\n",
        "            # ë‚˜ë¨¸ì§€ í–‰ì€ ë¹ˆ ë¬¸ìì—´\n",
        "            result_df.loc[result_df.index[1:], 'ì˜ˆì¸¡ê¸°ê°„'] = ''\n",
        "\n",
        "        return result_df\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜: {str(e)}\")\n",
        "        return pd.DataFrame()\n",
        "\n",
        "# ================================================================================\n",
        "# 11. ë¦¬ë“œ ë°°ì • ìµœì í™” (ê°œì„ ëœ ë²„ì „)\n",
        "# ================================================================================\n",
        "\n",
        "def optimize_lead_assignment(channel, gender, type_, memo_len, marketing, email, sms) -> Tuple[str, str, go.Figure]:\n",
        "    \"\"\"ì‹ ê·œ ë¦¬ë“œì— ëŒ€í•œ ìµœì  ë‹´ë‹¹ì ì¶”ì²œ (ê°œì„ ëœ ë²„ì „)\"\"\"\n",
        "    try:\n",
        "        if not app_state.is_model_trained or app_state.best_model is None:\n",
        "            return \"\", \"âŒ ë¨¼ì € ëª¨ë¸ì„ í•™ìŠµì‹œì¼œì£¼ì„¸ìš”.\", None\n",
        "\n",
        "        if app_state.manager_performance is None or len(app_state.manager_performance) == 0:\n",
        "            return \"\", \"âŒ ë‹´ë‹¹ì ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\", None\n",
        "\n",
        "        # ì‹ ê·œ ë¦¬ë“œ ì •ë³´ (í™•ì¥ëœ í”¼ì²˜)\n",
        "        current_datetime = datetime.now()\n",
        "\n",
        "        # ê¸°ë³¸ í”¼ì²˜\n",
        "        new_lead = {\n",
        "            'íŒë§¤ì²˜': channel,\n",
        "            'ì„±ë³„': gender,\n",
        "            'ìœ í˜•': type_,\n",
        "            'ë©”ëª¨_ê¸¸ì´': memo_len,\n",
        "            'ë©”ëª¨_ë‹¨ì–´ìˆ˜': memo_len // 5,\n",
        "            'ë§ˆì¼€íŒ…í™œìš©ë™ì˜_num': int(marketing),\n",
        "            'ì´ë©”ì¼ìˆ˜ì‹ ë™ì˜_num': int(email),\n",
        "            'ë¬¸ììˆ˜ì‹ ë™ì˜_num': int(sms),\n",
        "            'ì ‘ì´‰íšŸìˆ˜': 0,\n",
        "            'ë“±ë¡_ì›”': current_datetime.month,\n",
        "            'ë“±ë¡_ì¼': current_datetime.day,\n",
        "            'ë“±ë¡_ìš”ì¼': current_datetime.weekday(),\n",
        "            'ë“±ë¡_ì‹œê°„': current_datetime.hour,\n",
        "            'ë™ì˜ì ìˆ˜': int(marketing) + int(email) + int(sms),\n",
        "            'ì™„ì „ë™ì˜': int(marketing and email and sms),\n",
        "            'ì£¼ë§ì—¬ë¶€': int(current_datetime.weekday() >= 5),\n",
        "            'ì›”ì´ˆ': int(current_datetime.day <= 10),\n",
        "            'ì›”ë§': int(current_datetime.day >= 21),\n",
        "            'ë¶„ê¸°': (current_datetime.month - 1) // 3 + 1\n",
        "        }\n",
        "\n",
        "        # ë©”ëª¨ í’ˆì§ˆ ì ìˆ˜ ê³„ì‚°\n",
        "        new_lead['ë©”ëª¨_í’ˆì§ˆì ìˆ˜'] = (\n",
        "            new_lead['ë©”ëª¨_ê¸¸ì´'] / 500 * 0.3 +  # ìµœëŒ€ 500ì ê¸°ì¤€\n",
        "            new_lead['ë©”ëª¨_ë‹¨ì–´ìˆ˜'] / 100 * 0.3 +  # ìµœëŒ€ 100ë‹¨ì–´ ê¸°ì¤€\n",
        "            0.4  # í‚¤ì›Œë“œ í¬í•¨ ì—¬ë¶€ (ê°€ì •)\n",
        "        )\n",
        "\n",
        "        # ê³ ê° í”„ë¡œíŒŒì¼\n",
        "        new_lead['ê³ ê°í”„ë¡œíŒŒì¼'] = f\"{gender}_{type_}\"\n",
        "\n",
        "        # ê° ë‹´ë‹¹ìë³„ ì˜ˆìƒ ìŠ¹ì¸í™•ë¥  ê³„ì‚°\n",
        "        predictions = []\n",
        "\n",
        "        for _, manager_row in app_state.manager_performance.head(10).iterrows():\n",
        "            manager = manager_row['ë‹´ë‹¹ìëª…']\n",
        "\n",
        "            if manager == 'ë¯¸ë°°ì •':\n",
        "                continue\n",
        "\n",
        "            # ì˜ˆì¸¡ ë°ì´í„° ì¤€ë¹„\n",
        "            pred_data = new_lead.copy()\n",
        "            pred_data['ë‹´ë‹¹ìëª…'] = manager\n",
        "\n",
        "            # ë‹´ë‹¹ì ê´€ë ¨ í”¼ì²˜ ì¶”ê°€\n",
        "            pred_data['ë‹´ë‹¹ì_ìŠ¹ì¸ìœ¨'] = manager_row['ìŠ¹ì¸ì™„ë£Œìœ¨']\n",
        "            pred_data['ë‹´ë‹¹ì_ì´ìŠ¹ì¸ìˆ˜'] = manager_row['ìŠ¹ì¸ì™„ë£Œìˆ˜']\n",
        "            pred_data['ë‹´ë‹¹ì_ì´ë¦¬ë“œìˆ˜'] = manager_row['ì´_ë¦¬ë“œìˆ˜']\n",
        "            pred_data['ë‹´ë‹¹ì_í‰ê· ì ‘ì´‰'] = manager_row['í‰ê· _ì ‘ì´‰íšŸìˆ˜']\n",
        "            pred_data['ë‹´ë‹¹ì_ê²½í—˜ì§€ìˆ˜'] = manager_row['ì´_ë¦¬ë“œìˆ˜'] / app_state.manager_performance['ì´_ë¦¬ë“œìˆ˜'].max()\n",
        "            pred_data['ë‹´ë‹¹ì_íš¨ìœ¨ì„±'] = manager_row['ìŠ¹ì¸ì™„ë£Œìœ¨'] / (manager_row['í‰ê· _ì ‘ì´‰íšŸìˆ˜'] + 1)\n",
        "\n",
        "            # íŒë§¤ì²˜ ê´€ë ¨ í”¼ì²˜ (ì „ì²´ í‰ê·  ì‚¬ìš©)\n",
        "            channel_stats = app_state.processed_data.groupby('íŒë§¤ì²˜')['is_approved'].mean()\n",
        "            pred_data['íŒë§¤ì²˜_í‰ê· ìŠ¹ì¸ìœ¨'] = channel_stats.get(channel, channel_stats.mean())\n",
        "\n",
        "            # ìƒí˜¸ì‘ìš© í”¼ì²˜\n",
        "            pred_data['ë‹´ë‹¹ìXíŒë§¤ì²˜_ì‹œë„ˆì§€'] = pred_data['ë‹´ë‹¹ì_ìŠ¹ì¸ìœ¨'] * pred_data['íŒë§¤ì²˜_í‰ê· ìŠ¹ì¸ìœ¨']\n",
        "\n",
        "            # DataFrameìœ¼ë¡œ ë³€í™˜\n",
        "            pred_df = pd.DataFrame([pred_data])\n",
        "\n",
        "            # ì¸ì½”ë”©\n",
        "            for col, encoder in app_state.encoders.items():\n",
        "                if col in pred_df.columns:\n",
        "                    try:\n",
        "                        pred_df[f'{col}_encoded'] = encoder.transform(pred_df[col])\n",
        "                    except:\n",
        "                        pred_df[f'{col}_encoded'] = 0\n",
        "\n",
        "            # ì˜ˆì¸¡\n",
        "            try:\n",
        "                X_pred = pred_df[app_state.feature_names].fillna(0)\n",
        "\n",
        "                # ìŠ¤ì¼€ì¼ë§\n",
        "                if app_state.scaler:\n",
        "                    X_pred = app_state.scaler.transform(X_pred)\n",
        "\n",
        "                # í”¼ì²˜ ì„ íƒ\n",
        "                if app_state.feature_selector:\n",
        "                    X_pred = app_state.feature_selector.transform(X_pred)\n",
        "\n",
        "                # ì˜ˆì¸¡\n",
        "                if app_state.ensemble_model:\n",
        "                    # ì•™ìƒë¸” ëª¨ë¸ ìš°ì„  ì‚¬ìš©\n",
        "                    pred_proba = app_state.ensemble_model.predict_proba(X_pred)[0, 1]\n",
        "                else:\n",
        "                    pred_proba = app_state.best_model.predict_proba(X_pred)[0, 1]\n",
        "\n",
        "            except:\n",
        "                pred_proba = 0.5\n",
        "\n",
        "            # ì›Œí¬ë¡œë“œ ê³ ë ¤ (í˜„ì¬ ë¦¬ë“œìˆ˜ê°€ ë§ì€ ë‹´ë‹¹ìëŠ” í˜ë„í‹°)\n",
        "            workload_penalty = 1 - (manager_row['ì´_ë¦¬ë“œìˆ˜'] / app_state.manager_performance['ì´_ë¦¬ë“œìˆ˜'].max()) * 0.1\n",
        "            adjusted_proba = pred_proba * workload_penalty\n",
        "\n",
        "            predictions.append({\n",
        "                'ë‹´ë‹¹ì': manager,\n",
        "                'ì˜ˆìƒ_ìŠ¹ì¸í™•ë¥ ': pred_proba,\n",
        "                'ì¡°ì •_ìŠ¹ì¸í™•ë¥ ': adjusted_proba,\n",
        "                'ê³¼ê±°_ìŠ¹ì¸ìœ¨': manager_row['ìŠ¹ì¸ì™„ë£Œìœ¨'],\n",
        "                'í˜„ì¬_ë¦¬ë“œìˆ˜': manager_row['ì´_ë¦¬ë“œìˆ˜'],\n",
        "                'í‰ê· _ì ‘ì´‰íšŸìˆ˜': manager_row['í‰ê· _ì ‘ì´‰íšŸìˆ˜'],\n",
        "                'ë‹´ë‹¹ì_íš¨ìœ¨ì„±': pred_data['ë‹´ë‹¹ì_íš¨ìœ¨ì„±'],\n",
        "                'ì¢…í•©ì ìˆ˜': adjusted_proba * 0.6 + manager_row['ìŠ¹ì¸ì™„ë£Œìœ¨'] * 0.3 + pred_data['ë‹´ë‹¹ì_íš¨ìœ¨ì„±'] * 0.1\n",
        "            })\n",
        "\n",
        "        if len(predictions) == 0:\n",
        "            return \"\", \"âŒ ì˜ˆì¸¡í•  ìˆ˜ ìˆëŠ” ë‹´ë‹¹ìê°€ ì—†ìŠµë‹ˆë‹¤.\", None\n",
        "\n",
        "        # ê²°ê³¼ ì •ë ¬\n",
        "        pred_df = pd.DataFrame(predictions).sort_values('ì¢…í•©ì ìˆ˜', ascending=False)\n",
        "\n",
        "        # ìµœì  ë‹´ë‹¹ì ì„ íƒ\n",
        "        best_manager = pred_df.iloc[0]['ë‹´ë‹¹ì']\n",
        "        best_prob = pred_df.iloc[0]['ì˜ˆìƒ_ìŠ¹ì¸í™•ë¥ ']\n",
        "        best_adjusted_prob = pred_df.iloc[0]['ì¡°ì •_ìŠ¹ì¸í™•ë¥ ']\n",
        "\n",
        "        # ì‹œê°í™” (ê°œì„ ëœ ë²„ì „)\n",
        "        fig = make_subplots(\n",
        "            rows=2, cols=2,\n",
        "            subplot_titles=(\n",
        "                'ë‹´ë‹¹ìë³„ ì˜ˆìƒ ìŠ¹ì¸í™•ë¥ ',\n",
        "                'ì¢…í•© ì ìˆ˜ (ì›Œí¬ë¡œë“œ ê³ ë ¤)',\n",
        "                'ë‹´ë‹¹ì íš¨ìœ¨ì„± ì§€í‘œ',\n",
        "                'ì¶”ì²œ ê·¼ê±° ë¶„ì„'\n",
        "            ),\n",
        "            specs=[[{\"type\": \"bar\"}, {\"type\": \"bar\"}],\n",
        "                   [{\"type\": \"scatter\"}, {\"type\": \"bar\"}]]\n",
        "        )\n",
        "\n",
        "        # ìƒìœ„ 5ëª…ë§Œ í‘œì‹œ\n",
        "        top_5 = pred_df.head(5)\n",
        "\n",
        "        # 1. ì˜ˆìƒ ìŠ¹ì¸í™•ë¥ \n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=top_5['ë‹´ë‹¹ì'],\n",
        "                y=top_5['ì˜ˆìƒ_ìŠ¹ì¸í™•ë¥ '],\n",
        "                name='ì˜ˆìƒ ìŠ¹ì¸í™•ë¥ ',\n",
        "                marker_color='lightblue',\n",
        "                text=top_5['ì˜ˆìƒ_ìŠ¹ì¸í™•ë¥ '].apply(lambda x: f'{x:.1%}'),\n",
        "                textposition='outside'\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # ê³¼ê±° ìŠ¹ì¸ìœ¨ ì¶”ê°€\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=top_5['ë‹´ë‹¹ì'],\n",
        "                y=top_5['ê³¼ê±°_ìŠ¹ì¸ìœ¨'],\n",
        "                name='ê³¼ê±° í‰ê· ',\n",
        "                marker_color='lightgreen',\n",
        "                text=top_5['ê³¼ê±°_ìŠ¹ì¸ìœ¨'].apply(lambda x: f'{x:.1%}'),\n",
        "                textposition='outside'\n",
        "            ),\n",
        "            row=1, col=1\n",
        "        )\n",
        "\n",
        "        # 2. ì¢…í•© ì ìˆ˜\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=top_5['ë‹´ë‹¹ì'],\n",
        "                y=top_5['ì¢…í•©ì ìˆ˜'],\n",
        "                name='ì¢…í•© ì ìˆ˜',\n",
        "                marker_color='orange',\n",
        "                text=top_5['ì¢…í•©ì ìˆ˜'].apply(lambda x: f'{x:.3f}'),\n",
        "                textposition='outside',\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=1, col=2\n",
        "        )\n",
        "\n",
        "        # 3. íš¨ìœ¨ì„± vs ì›Œí¬ë¡œë“œ\n",
        "        fig.add_trace(\n",
        "            go.Scatter(\n",
        "                x=top_5['í˜„ì¬_ë¦¬ë“œìˆ˜'],\n",
        "                y=top_5['ë‹´ë‹¹ì_íš¨ìœ¨ì„±'],\n",
        "                mode='markers+text',\n",
        "                marker=dict(\n",
        "                    size=top_5['ì˜ˆìƒ_ìŠ¹ì¸í™•ë¥ '] * 50,\n",
        "                    color=top_5['ì¢…í•©ì ìˆ˜'],\n",
        "                    colorscale='RdYlGn',\n",
        "                    showscale=True\n",
        "                ),\n",
        "                text=top_5['ë‹´ë‹¹ì'],\n",
        "                textposition='top center',\n",
        "                name='íš¨ìœ¨ì„±',\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=2, col=1\n",
        "        )\n",
        "\n",
        "        # 4. ì¶”ì²œ ê·¼ê±° ìš”ì•½\n",
        "        factors = ['ì˜ˆìƒ ìŠ¹ì¸ë¥ ', 'ê³¼ê±° ì„±ê³¼', 'íš¨ìœ¨ì„±', 'ì›Œí¬ë¡œë“œ']\n",
        "        best_factors = [\n",
        "            pred_df.iloc[0]['ì˜ˆìƒ_ìŠ¹ì¸í™•ë¥ '],\n",
        "            pred_df.iloc[0]['ê³¼ê±°_ìŠ¹ì¸ìœ¨'],\n",
        "            pred_df.iloc[0]['ë‹´ë‹¹ì_íš¨ìœ¨ì„±'],\n",
        "            1 - pred_df.iloc[0]['í˜„ì¬_ë¦¬ë“œìˆ˜'] / pred_df['í˜„ì¬_ë¦¬ë“œìˆ˜'].max()\n",
        "        ]\n",
        "\n",
        "        fig.add_trace(\n",
        "            go.Bar(\n",
        "                x=factors,\n",
        "                y=best_factors,\n",
        "                name='í‰ê°€ ì§€í‘œ',\n",
        "                marker_color=['blue', 'green', 'orange', 'red'],\n",
        "                text=[f'{v:.2f}' for v in best_factors],\n",
        "                textposition='outside',\n",
        "                showlegend=False\n",
        "            ),\n",
        "            row=2, col=2\n",
        "        )\n",
        "\n",
        "        # ë ˆì´ì•„ì›ƒ ì„¤ì •\n",
        "        fig.update_layout(\n",
        "            height=800,\n",
        "            showlegend=True,\n",
        "            title_text=f'AI ê¸°ë°˜ ìµœì  ë‹´ë‹¹ì ì¶”ì²œ: {best_manager}'\n",
        "        )\n",
        "\n",
        "        fig.update_xaxes(title_text=\"ë‹´ë‹¹ì\", row=1, col=1)\n",
        "        fig.update_xaxes(title_text=\"ë‹´ë‹¹ì\", row=1, col=2)\n",
        "        fig.update_xaxes(title_text=\"í˜„ì¬ ë¦¬ë“œìˆ˜\", row=2, col=1)\n",
        "        fig.update_xaxes(title_text=\"í‰ê°€ ìš”ì†Œ\", row=2, col=2)\n",
        "\n",
        "        fig.update_yaxes(title_text=\"í™•ë¥ \", row=1, col=1)\n",
        "        fig.update_yaxes(title_text=\"ì ìˆ˜\", row=1, col=2)\n",
        "        fig.update_yaxes(title_text=\"íš¨ìœ¨ì„± ì§€ìˆ˜\", row=2, col=1)\n",
        "        fig.update_yaxes(title_text=\"ì§€í‘œê°’\", row=2, col=2)\n",
        "\n",
        "        # ì¶”ì²œ ì´ìœ  ìƒì„± (ë” ìƒì„¸í•œ ë²„ì „)\n",
        "        recommendation_text = f\"\"\"ğŸ¯ ìµœì  ë‹´ë‹¹ì ì¶”ì²œ: {best_manager}\n",
        "\n",
        "ğŸ“Š ì¶”ì²œ ê·¼ê±°:\n",
        "- ì˜ˆìƒ ìŠ¹ì¸ í™•ë¥ : {best_prob:.1%} (ì¡°ì • í›„: {best_adjusted_prob:.1%})\n",
        "- ê³¼ê±° í‰ê·  ìŠ¹ì¸ìœ¨: {pred_df.iloc[0]['ê³¼ê±°_ìŠ¹ì¸ìœ¨']:.1%}\n",
        "- í˜„ì¬ ì²˜ë¦¬ ì¤‘ì¸ ë¦¬ë“œ: {int(pred_df.iloc[0]['í˜„ì¬_ë¦¬ë“œìˆ˜'])}ê±´\n",
        "- í‰ê·  ì ‘ì´‰ íšŸìˆ˜: {pred_df.iloc[0]['í‰ê· _ì ‘ì´‰íšŸìˆ˜']:.1f}íšŒ\n",
        "- ë‹´ë‹¹ì íš¨ìœ¨ì„±: {pred_df.iloc[0]['ë‹´ë‹¹ì_íš¨ìœ¨ì„±']:.3f}\n",
        "\n",
        "ğŸ’¡ ì¶”ì²œ ì´ìœ :\n",
        "1. ì´ ë‹´ë‹¹ìëŠ” ìœ ì‚¬í•œ í”„ë¡œíŒŒì¼ì˜ ë¦¬ë“œì—ì„œ ë†’ì€ ì„±ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.\n",
        "2. í˜„ì¬ ì›Œí¬ë¡œë“œê°€ ì ì ˆí•œ ìˆ˜ì¤€ìœ¼ë¡œ ì¶”ê°€ ë¦¬ë“œ ì²˜ë¦¬ê°€ ê°€ëŠ¥í•©ë‹ˆë‹¤.\n",
        "3. íš¨ìœ¨ì„± ì§€í‘œê°€ ìš°ìˆ˜í•˜ì—¬ ì ì€ ì ‘ì´‰ìœ¼ë¡œë„ ë†’ì€ ì „í™˜ìœ¨ì„ ë‹¬ì„±í•©ë‹ˆë‹¤.\n",
        "4. AI ëª¨ë¸ì´ ì´ ë¦¬ë“œì˜ íŠ¹ì„±ê³¼ ë‹´ë‹¹ìì˜ ê°•ì ì´ ë§¤ì¹˜ëœë‹¤ê³  ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
        "\n",
        "ğŸ“ˆ ëŒ€ì•ˆ ë‹´ë‹¹ì:\n",
        "\"\"\"\n",
        "\n",
        "        for i in range(1, min(3, len(pred_df))):\n",
        "            alt = pred_df.iloc[i]\n",
        "            recommendation_text += f\"\\n{i+1}. {alt['ë‹´ë‹¹ì']} (ì˜ˆìƒ: {alt['ì˜ˆìƒ_ìŠ¹ì¸í™•ë¥ ']:.1%}, ì¢…í•©: {alt['ì¢…í•©ì ìˆ˜']:.3f})\"\n",
        "\n",
        "        # ë¦¬ë“œ íŠ¹ì„± ìš”ì•½\n",
        "        recommendation_text += f\"\"\"\n",
        "\n",
        "ğŸ“‹ ë¦¬ë“œ íŠ¹ì„± ìš”ì•½:\n",
        "- íŒë§¤ì²˜: {channel}\n",
        "- ê³ ê° í”„ë¡œíŒŒì¼: {gender} / {type_}\n",
        "- ë™ì˜ ì ìˆ˜: {new_lead['ë™ì˜ì ìˆ˜']}/3\n",
        "- ì˜ˆìƒ ë©”ëª¨ í’ˆì§ˆ: {new_lead['ë©”ëª¨_í’ˆì§ˆì ìˆ˜']:.2f}\n",
        "- ì‹œê°„ëŒ€ íŠ¹ì„±: {'ì£¼ë§' if new_lead['ì£¼ë§ì—¬ë¶€'] else 'í‰ì¼'}, {current_datetime.hour}ì‹œ\n",
        "\"\"\"\n",
        "\n",
        "        return best_manager, recommendation_text, fig\n",
        "\n",
        "    except Exception as e:\n",
        "        return \"\", f\"âŒ ì˜ˆì¸¡ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", None\n",
        "\n",
        "# ================================================================================\n",
        "# 12. Gradio ì¸í„°í˜ì´ìŠ¤ êµ¬ì„± (ê¸°ì¡´ ìœ ì§€)\n",
        "# ================================================================================\n",
        "\n",
        "def create_gradio_interface():\n",
        "    \"\"\"Gradio ì¸í„°í˜ì´ìŠ¤ ìƒì„±\"\"\"\n",
        "\n",
        "    # CSS ìŠ¤íƒ€ì¼\n",
        "    custom_css = \"\"\"\n",
        "    .gradio-container {\n",
        "        font-family: 'Noto Sans KR', -apple-system, BlinkMacSystemFont, sans-serif !important;\n",
        "    }\n",
        "    .gr-button-primary {\n",
        "        background-color: #2563eb !important;\n",
        "        color: white !important;\n",
        "    }\n",
        "    .gr-button-primary:hover {\n",
        "        background-color: #1d4ed8 !important;\n",
        "    }\n",
        "    .error-text {\n",
        "        color: #dc2626 !important;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    .success-text {\n",
        "        color: #16a34a !important;\n",
        "        font-weight: bold;\n",
        "    }\n",
        "    \"\"\"\n",
        "\n",
        "    with gr.Blocks(title=\"ë‹´ë‹¹ìë³„ ë¦¬ë“œ ì „í™˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ\", theme=gr.themes.Soft(), css=custom_css) as app:\n",
        "\n",
        "        # í—¤ë”\n",
        "        gr.Markdown(\"\"\"\n",
        "        # ğŸ¯ ë‹´ë‹¹ìë³„ ë¦¬ë“œ ì „í™˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ\n",
        "\n",
        "        ### ğŸ“Š AI ê¸°ë°˜ ë¦¬ë“œ ë°°ì • ìµœì í™” ë° ì„±ê³¼ ì˜ˆì¸¡ í”Œë«í¼\n",
        "\n",
        "        ---\n",
        "        \"\"\")\n",
        "\n",
        "        # ë©”ì¸ íƒ­\n",
        "        with gr.Tabs():\n",
        "\n",
        "            # 1. ë°ì´í„° ì—…ë¡œë“œ ë° ì „ì²˜ë¦¬\n",
        "            with gr.Tab(\"ğŸ“ ë°ì´í„° ê´€ë¦¬\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        file_input = gr.File(\n",
        "                            label=\"ì—‘ì…€ íŒŒì¼ ì—…ë¡œë“œ (tst_atalk.xlsx)\",\n",
        "                            file_types=[\".xlsx\", \".xls\", \".csv\"],\n",
        "                            type=\"filepath\"\n",
        "                        )\n",
        "\n",
        "                        with gr.Row():\n",
        "                            upload_btn = gr.Button(\"ğŸ“¤ ë°ì´í„° ë¡œë“œ\", variant=\"primary\")\n",
        "                            sample_btn = gr.Button(\"ğŸ² ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©\", variant=\"secondary\")\n",
        "\n",
        "                        preprocess_btn = gr.Button(\"ğŸ”§ ì „ì²˜ë¦¬ ì‹¤í–‰\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        data_info = gr.Textbox(\n",
        "                            label=\"ë°ì´í„° ë¶„ì„ ê²°ê³¼\",\n",
        "                            lines=20,\n",
        "                            interactive=False\n",
        "                        )\n",
        "\n",
        "                # ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬\n",
        "                upload_btn.click(\n",
        "                    fn=load_data,\n",
        "                    inputs=[file_input],\n",
        "                    outputs=[gr.State(), data_info]\n",
        "                )\n",
        "\n",
        "                sample_btn.click(\n",
        "                    fn=lambda: load_data(None),\n",
        "                    outputs=[gr.State(), data_info]\n",
        "                )\n",
        "\n",
        "                preprocess_btn.click(\n",
        "                    fn=preprocess_for_prediction,\n",
        "                    outputs=[gr.State(), data_info]\n",
        "                )\n",
        "\n",
        "            # 2. ë‹´ë‹¹ì ì„±ê³¼ ë¶„ì„\n",
        "            with gr.Tab(\"ğŸ‘¥ ë‹´ë‹¹ì ì„±ê³¼ ë¶„ì„\"):\n",
        "                analyze_btn = gr.Button(\"ğŸ“Š ì„±ê³¼ ë¶„ì„ ì‹¤í–‰\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                status_text = gr.Textbox(label=\"ìƒíƒœ\", interactive=False, visible=True)\n",
        "\n",
        "                with gr.Row():\n",
        "                    perf_plot1 = gr.Plot(label=\"ì„±ê³¼ ë§¤íŠ¸ë¦­ìŠ¤\")\n",
        "                    perf_plot2 = gr.Plot(label=\"ìŠ¹ì¸ìœ¨ ìˆœìœ„\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    perf_plot3 = gr.Plot(label=\"ì¼ë³„ ì¶”ì´\")\n",
        "                    perf_plot4 = gr.Plot(label=\"ì ‘ì´‰ íš¨ìœ¨ì„±\")\n",
        "\n",
        "                def analyze_performance():\n",
        "                    plots, message = create_manager_performance_dashboard()\n",
        "                    if len(plots) >= 4:\n",
        "                        return message, plots[0], plots[1], plots[2], plots[3]\n",
        "                    elif len(plots) == 3:\n",
        "                        return message, plots[0], plots[1], plots[2], None\n",
        "                    elif len(plots) == 2:\n",
        "                        return message, plots[0], plots[1], None, None\n",
        "                    elif len(plots) == 1:\n",
        "                        return message, plots[0], None, None, None\n",
        "                    else:\n",
        "                        return message, None, None, None, None\n",
        "\n",
        "                analyze_btn.click(\n",
        "                    fn=analyze_performance,\n",
        "                    outputs=[status_text, perf_plot1, perf_plot2, perf_plot3, perf_plot4]\n",
        "                )\n",
        "\n",
        "            # 3. ì˜ˆì¸¡ ëª¨ë¸ í•™ìŠµ\n",
        "            with gr.Tab(\"ğŸ¤– AI ëª¨ë¸ í•™ìŠµ\"):\n",
        "                with gr.Row():\n",
        "                    with gr.Column(scale=1):\n",
        "                        gr.Markdown(\"### ğŸ“… í•™ìŠµ ê¸°ê°„ ì„¤ì •\")\n",
        "\n",
        "                        # ë‚ ì§œ ì„ íƒ ì»´í¬ë„ŒíŠ¸\n",
        "                        with gr.Row():\n",
        "                            train_start_date = gr.Textbox(\n",
        "                                label=\"í•™ìŠµ ì‹œì‘ì¼\",\n",
        "                                value=\"2024-01-01\",\n",
        "                                info=\"YYYY-MM-DD í˜•ì‹\"\n",
        "                            )\n",
        "                            train_end_date = gr.Textbox(\n",
        "                                label=\"í•™ìŠµ ì¢…ë£Œì¼\",\n",
        "                                value=datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "                                info=\"YYYY-MM-DD í˜•ì‹\"\n",
        "                            )\n",
        "\n",
        "                        gr.Markdown(\"### ğŸ”® ì˜ˆì¸¡ ê¸°ê°„ ì„¤ì •\")\n",
        "\n",
        "                        with gr.Row():\n",
        "                            predict_start_date = gr.Textbox(\n",
        "                                label=\"ì˜ˆì¸¡ ì‹œì‘ì¼\",\n",
        "                                value=datetime.now().strftime(\"%Y-%m-%d\"),\n",
        "                                info=\"YYYY-MM-DD í˜•ì‹\"\n",
        "                            )\n",
        "                            predict_days = gr.Slider(\n",
        "                                label=\"ì˜ˆì¸¡ ì¼ìˆ˜\",\n",
        "                                minimum=1,\n",
        "                                maximum=90,\n",
        "                                value=30,\n",
        "                                step=1,\n",
        "                                info=\"ë©°ì¹  í›„ê¹Œì§€ ì˜ˆì¸¡í• ì§€ ì„¤ì •\"\n",
        "                            )\n",
        "\n",
        "                        train_btn = gr.Button(\"ğŸš€ ëª¨ë¸ í•™ìŠµ ë° ì˜ˆì¸¡ ì‹œì‘\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                        model_info = gr.Textbox(\n",
        "                            label=\"ëª¨ë¸ í•™ìŠµ ê²°ê³¼\",\n",
        "                            lines=15,\n",
        "                            interactive=False\n",
        "                        )\n",
        "\n",
        "                    with gr.Column(scale=2):\n",
        "                        with gr.Tabs():\n",
        "                            with gr.Tab(\"ğŸ“ˆ ë‹´ë‹¹ìë³„ ì˜ˆìƒ ì„±ê³¼\"):\n",
        "                                prediction_table = gr.Dataframe(\n",
        "                                    label=\"ë‹´ë‹¹ìë³„ ì˜ˆì¸¡ ê²°ê³¼\",\n",
        "                                    interactive=False\n",
        "                                )\n",
        "\n",
        "                            with gr.Tab(\"ğŸ“Š ì‹œê³„ì—´ ì˜ˆì¸¡\"):\n",
        "                                time_series_plot = gr.Plot(\n",
        "                                    label=\"ê¸°ê°„ë³„ ì˜ˆì¸¡ ì¶”ì´\"\n",
        "                                )\n",
        "\n",
        "                def train_and_predict_with_dates(start_date, end_date, pred_start, pred_days):\n",
        "                    try:\n",
        "                        # ë‚ ì§œ í˜•ì‹ ê²€ì¦\n",
        "                        start = pd.to_datetime(start_date)\n",
        "                        end = pd.to_datetime(end_date)\n",
        "                        pred_start_dt = pd.to_datetime(pred_start)\n",
        "\n",
        "                        if start > end:\n",
        "                            return \"âŒ ì‹œì‘ì¼ì´ ì¢…ë£Œì¼ë³´ë‹¤ ëŠ¦ìŠµë‹ˆë‹¤.\", pd.DataFrame(), None\n",
        "\n",
        "                        # ì§€ì •ëœ ê¸°ê°„ì˜ ë°ì´í„°ë§Œ í•„í„°ë§\n",
        "                        filtered_data = filter_data_by_date(start, end)\n",
        "\n",
        "                        if filtered_data is None or len(filtered_data) == 0:\n",
        "                            return \"âŒ ì„ íƒí•œ ê¸°ê°„ì— ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.\", pd.DataFrame(), None\n",
        "\n",
        "                        # ëª¨ë¸ í•™ìŠµ\n",
        "                        results, text = train_prediction_model_with_data(filtered_data)\n",
        "\n",
        "                        if app_state.is_model_trained:\n",
        "                            # ì§€ì •ëœ ë‚ ì§œ ê¸°ì¤€ìœ¼ë¡œ ì„±ê³¼ ì˜ˆì¸¡\n",
        "                            pred_df = predict_manager_performance(pred_start_dt, pred_days)\n",
        "\n",
        "                            # ì‹œê³„ì—´ ì˜ˆì¸¡\n",
        "                            time_series_fig = create_time_series_prediction(pred_start_dt, pred_days)\n",
        "\n",
        "                            # í•™ìŠµ ì •ë³´ ì¶”ê°€\n",
        "                            text += f\"\\n\\nğŸ“… í•™ìŠµ ê¸°ê°„: {start.date()} ~ {end.date()}\"\n",
        "                            text += f\"\\nğŸ”® ì˜ˆì¸¡ ê¸°ê°„: {pred_start_dt.date()} ~ {(pred_start_dt + pd.Timedelta(days=pred_days)).date()}\"\n",
        "                            text += f\"\\nğŸ“Š ì˜ˆì¸¡ ì¼ìˆ˜: {pred_days}ì¼\"\n",
        "\n",
        "                            return text, pred_df, time_series_fig\n",
        "\n",
        "                        return text, pd.DataFrame(), None\n",
        "\n",
        "                    except Exception as e:\n",
        "                        return f\"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}\", pd.DataFrame(), None\n",
        "\n",
        "                train_btn.click(\n",
        "                    fn=train_and_predict_with_dates,\n",
        "                    inputs=[train_start_date, train_end_date, predict_start_date, predict_days],\n",
        "                    outputs=[model_info, prediction_table, time_series_plot]\n",
        "                )\n",
        "\n",
        "            # 4. ë¦¬ë“œ ë°°ì • ìµœì í™”\n",
        "            with gr.Tab(\"ğŸ¯ ë¦¬ë“œ ë°°ì • ìµœì í™”\"):\n",
        "                gr.Markdown(\"### ì‹ ê·œ ë¦¬ë“œ ì •ë³´ ì…ë ¥\")\n",
        "\n",
        "                with gr.Row():\n",
        "                    with gr.Column():\n",
        "                        channel_input = gr.Dropdown(\n",
        "                            label=\"íŒë§¤ì²˜\",\n",
        "                            choices=['Gë§ˆì¼“', 'CJëª°', '11ë²ˆê°€', 'SSG', 'ì˜¥ì…˜', 'ë„¤ì´ë²„', 'ì¿ íŒ¡', 'ê¸°íƒ€'],\n",
        "                            value=\"Gë§ˆì¼“\"\n",
        "                        )\n",
        "                        gender_input = gr.Radio(\n",
        "                            label=\"ì„±ë³„\",\n",
        "                            choices=[\"ë‚¨ì\", \"ì—¬ì\"],\n",
        "                            value=\"ì—¬ì\"\n",
        "                        )\n",
        "                        type_input = gr.Radio(\n",
        "                            label=\"ìœ í˜•\",\n",
        "                            choices=[\"ê°œì¸\", \"ë²•ì¸\"],\n",
        "                            value=\"ê°œì¸\"\n",
        "                        )\n",
        "                        memo_length = gr.Slider(\n",
        "                            label=\"ë©”ëª¨ ê¸¸ì´\",\n",
        "                            minimum=0,\n",
        "                            maximum=500,\n",
        "                            value=100,\n",
        "                            step=10\n",
        "                        )\n",
        "                        marketing_consent = gr.Checkbox(label=\"ë§ˆì¼€íŒ… ë™ì˜\", value=True)\n",
        "                        email_consent = gr.Checkbox(label=\"ì´ë©”ì¼ ìˆ˜ì‹  ë™ì˜\", value=True)\n",
        "                        sms_consent = gr.Checkbox(label=\"ë¬¸ì ìˆ˜ì‹  ë™ì˜\", value=True)\n",
        "\n",
        "                        assign_btn = gr.Button(\"ğŸ¯ ìµœì  ë‹´ë‹¹ì ì°¾ê¸°\", variant=\"primary\", size=\"lg\")\n",
        "\n",
        "                    with gr.Column():\n",
        "                        best_manager = gr.Textbox(\n",
        "                            label=\"ì¶”ì²œ ë‹´ë‹¹ì\",\n",
        "                            interactive=False\n",
        "                        )\n",
        "                        recommendation = gr.Textbox(\n",
        "                            label=\"ì¶”ì²œ ìƒì„¸ ì •ë³´\",\n",
        "                            lines=15,\n",
        "                            interactive=False\n",
        "                        )\n",
        "                        comparison_plot = gr.Plot(label=\"ë‹´ë‹¹ìë³„ ì˜ˆìƒ ì„±ê³¼\")\n",
        "\n",
        "                assign_btn.click(\n",
        "                    fn=optimize_lead_assignment,\n",
        "                    inputs=[channel_input, gender_input, type_input, memo_length,\n",
        "                           marketing_consent, email_consent, sms_consent],\n",
        "                    outputs=[best_manager, recommendation, comparison_plot]\n",
        "                )\n",
        "\n",
        "        # í‘¸í„°\n",
        "        gr.Markdown(\"\"\"\n",
        "        ---\n",
        "\n",
        "        ### ğŸ’¡ ì‚¬ìš© ê°€ì´ë“œ\n",
        "\n",
        "        1. **ë°ì´í„° ì—…ë¡œë“œ**: tst_atalk.xlsx íŒŒì¼ì„ ì—…ë¡œë“œí•˜ê±°ë‚˜ ìƒ˜í”Œ ë°ì´í„°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.\n",
        "        2. **ì „ì²˜ë¦¬ ì‹¤í–‰**: ë°ì´í„°ë¥¼ ë¶„ì„ì— ì í•©í•œ í˜•íƒœë¡œ ë³€í™˜í•©ë‹ˆë‹¤.\n",
        "        3. **ì„±ê³¼ ë¶„ì„**: ë‹´ë‹¹ìë³„ í˜„ì¬ ì„±ê³¼ë¥¼ ë‹¤ê°ë„ë¡œ ë¶„ì„í•©ë‹ˆë‹¤.\n",
        "        4. **ëª¨ë¸ í•™ìŠµ**: AI ëª¨ë¸ì„ í•™ìŠµì‹œì¼œ ë‹´ë‹¹ìë³„ ì˜ˆìƒ ì„±ê³¼ë¥¼ ì˜ˆì¸¡í•©ë‹ˆë‹¤.\n",
        "        5. **ë¦¬ë“œ ë°°ì •**: ì‹ ê·œ ë¦¬ë“œì— ëŒ€í•´ ìµœì ì˜ ë‹´ë‹¹ìë¥¼ ì¶”ì²œë°›ìŠµë‹ˆë‹¤.\n",
        "\n",
        "        ---\n",
        "\n",
        "        Â© 2024 Lead Conversion Prediction System. All rights reserved.\n",
        "        \"\"\")\n",
        "\n",
        "    return app\n",
        "\n",
        "# ================================================================================\n",
        "# 13. ë©”ì¸ ì‹¤í–‰\n",
        "# ================================================================================\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    print(\"ğŸš€ ë‹´ë‹¹ìë³„ ë¦¬ë“œ ì „í™˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘ ì¤‘...\")\n",
        "    print(\"ğŸ“Œ ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¹ ë¥´ê²Œ ì‹œì‘í•˜ë ¤ë©´ [ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©] ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!\")\n",
        "\n",
        "    # ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸ í™•ì¸\n",
        "    print(\"\\nğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:\")\n",
        "    print(f\"- ê¸°ë³¸ ML ëª¨ë¸: âœ… (Random Forest, XGBoost, LightGBM ë“±)\")\n",
        "    print(f\"- LSTM (ì‹œê³„ì—´): {'âœ…' if TENSORFLOW_AVAILABLE else 'âŒ (TensorFlow í•„ìš”)'}\")\n",
        "    print(f\"- ARIMA (ì‹œê³„ì—´): {'âœ…' if STATSMODELS_AVAILABLE else 'âŒ (statsmodels/pmdarima í•„ìš”)'}\")\n",
        "    print(f\"- Prophet (ì‹œê³„ì—´): {'âœ…' if PROPHET_AVAILABLE else 'âŒ (prophet í•„ìš”)'}\")\n",
        "    print(f\"- CatBoost: {'âœ…' if CATBOOST_AVAILABLE else 'âŒ (catboost í•„ìš”)'}\")\n",
        "    print(f\"- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”: {'âœ…' if OPTUNA_AVAILABLE else 'âŒ (optuna í•„ìš”)'}\")\n",
        "    print(f\"- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬: {'âœ…' if IMBALANCED_AVAILABLE else 'âŒ (imbalanced-learn í•„ìš”)'}\")\n",
        "\n",
        "    print(\"\\nğŸ’¡ ì‹œê³„ì—´ ëª¨ë¸ì´ ì—†ì–´ë„ ê¸°ë³¸ ML ëª¨ë¸ë§Œìœ¼ë¡œ ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\")\n",
        "\n",
        "    # Gradio ì•± ìƒì„± ë° ì‹¤í–‰\n",
        "    app = create_gradio_interface()\n",
        "\n",
        "    # ì‹¤í–‰\n",
        "    app.launch(\n",
        "        share=True,  # ê³µìœ  ë§í¬ ìƒì„±\n",
        "        debug=False,\n",
        "        quiet=False\n",
        "    )\n",
        "\n",
        "    print(\"âœ… ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "KqBIyIvlp1F6",
        "outputId": "c0d13567-cc66-4dd3-a463-9a12427f42d0"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\n",
            "âœ… gradio>=5.0.0 ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… pandas ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… numpy ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… scikit-learn>=1.0.0 ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… lightgbm ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… xgboost ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… catboost ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… optuna>=3.0.0 ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… plotly ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… seaborn ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… matplotlib ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… openpyxl ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… japanize-matplotlib ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… tensorflow ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… imbalanced-learn>=0.9.0 ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… feature-engine ì„¤ì¹˜ ì™„ë£Œ\n",
            "\n",
            "ğŸ“ˆ ì‹œê³„ì—´ ë¶„ì„ íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì¤‘...\n",
            "âœ… statsmodels ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… pmdarima ì„¤ì¹˜ ì™„ë£Œ\n",
            "âœ… prophet ì„¤ì¹˜ ì™„ë£Œ\n",
            "\n",
            "ğŸ¨ í•œê¸€ í°íŠ¸ ì„¤ì¹˜ ì¤‘...\n",
            "\n",
            "âœ… íŒ¨í‚¤ì§€ ì„¤ì¹˜ ì™„ë£Œ!\n",
            "ğŸ’¡ ì¼ë¶€ ì‹œê³„ì—´ íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•„ë„ ê¸°ë³¸ ML ëª¨ë¸ì€ ì •ìƒ ì‘ë™í•©ë‹ˆë‹¤.\n",
            "âœ… TensorFlow ë¡œë“œ ì„±ê³µ\n",
            "âš ï¸ Statsmodels ë¡œë“œ ì¤‘ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: numpy.dtype size changed, may indicate binary incompatibility. Expected 96 from C header, got 88 from PyObject\n",
            "âœ… Prophet ë¡œë“œ ì„±ê³µ\n",
            "ğŸš€ ë‹´ë‹¹ìë³„ ë¦¬ë“œ ì „í™˜ ì˜ˆì¸¡ ì‹œìŠ¤í…œ ì‹œì‘ ì¤‘...\n",
            "ğŸ“Œ ìƒ˜í”Œ ë°ì´í„°ë¡œ ë¹ ë¥´ê²Œ ì‹œì‘í•˜ë ¤ë©´ [ìƒ˜í”Œ ë°ì´í„° ì‚¬ìš©] ë²„íŠ¼ì„ í´ë¦­í•˜ì„¸ìš”!\n",
            "\n",
            "ğŸ“Š ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸:\n",
            "- ê¸°ë³¸ ML ëª¨ë¸: âœ… (Random Forest, XGBoost, LightGBM ë“±)\n",
            "- LSTM (ì‹œê³„ì—´): âœ…\n",
            "- ARIMA (ì‹œê³„ì—´): âŒ (statsmodels/pmdarima í•„ìš”)\n",
            "- Prophet (ì‹œê³„ì—´): âœ…\n",
            "- CatBoost: âœ…\n",
            "- í•˜ì´í¼íŒŒë¼ë¯¸í„° ìµœì í™”: âœ…\n",
            "- í´ë˜ìŠ¤ ë¶ˆê· í˜• ì²˜ë¦¬: âœ…\n",
            "\n",
            "ğŸ’¡ ì‹œê³„ì—´ ëª¨ë¸ì´ ì—†ì–´ë„ ê¸°ë³¸ ML ëª¨ë¸ë§Œìœ¼ë¡œ ì¶©ë¶„í•œ ì„±ëŠ¥ì„ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
            "Colab notebook detected. To show errors in colab notebook, set debug=True in launch()\n",
            "* Running on public URL: https://4867b283602f7d2d86.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://4867b283602f7d2d86.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "âœ… ì‹œìŠ¤í…œì´ ì„±ê³µì ìœ¼ë¡œ ì‹œì‘ë˜ì—ˆìŠµë‹ˆë‹¤!\n"
          ]
        }
      ]
    }
  ]
}